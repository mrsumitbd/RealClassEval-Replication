
import duckdb
import os
import math
import pandas as pd
from typing import List


class _TPCDataGenerator:
    '''
    Base class for TPC data generation. PLEASE DO NOT INSTANTIATE THIS CLASS DIRECTLY. Use the TPCHDataGenerator and TPCDSDataGenerator
    subclasses instead.
    '''

    def __init__(self, scale_factor: int, target_mount_folder_path: str = None, target_row_group_size_mb: int = 128):
        '''
        Initialize the TPC data generator with a scale factor.
        :param scale_factor: The scale factor for the data generation.
        '''
        self.scale_factor = scale_factor
        self.target_mount_folder_path = target_mount_folder_path
        self.target_row_group_size_mb = target_row_group_size_mb
        self.con = duckdb.connect(database=':memory:')

    def _estimate_row_size_mb(self, table_name: str, sample_size: int = 10000) -> float:
        '''
        Estimate the average row size in MB by sampling the table.
        '''
        query = f"SELECT * FROM {table_name} USING SAMPLE {sample_size}"
        sample_df = self.con.execute(query).fetchdf()
        sample_size_bytes = sample_df.memory_usage(deep=True).sum()
        row_size_bytes = sample_size_bytes / len(sample_df)
        return row_size_bytes / (1024 * 1024)

    def _write_table_to_parquet(self, table_name: str, target_folder: str) -> None:
        '''
        Write the specified table to Parquet files with optimized row group sizes.
        '''
        row_size_mb = self._estimate_row_size_mb(table_name)
        row_group_size_rows = math.ceil(
            self.target_row_group_size_mb / row_size_mb)
        query = f"COPY {table_name} TO '{target_folder}/{table_name}.parquet' (FORMAT 'parquet', ROW_GROUP_SIZE {row_group_size_rows})"
        self.con.execute(query)

    def run(self):
        '''
        This method uses DuckDB to generate in-memory tables based on the specified 
        scale factor and writes them to Parquet files. It estimates the average row 
        size in MB using a sample of the data since DuckDB only supports specifying 
        the number of rows per row group. The generated tables are written to the 
        specified target folder with optimized row group sizes.
        Parameters
        ----------
        None
        Notes
        -----
        - The method creates a sample Parquet file for each table to estimate row sizes.
        - The full table is then written as Parquet files with optimized row group sizes.
        - Temporary files and in-memory tables are cleaned up after processing.
        '''
        if not os.path.exists(self.target_mount_folder_path):
            os.makedirs(self.target_mount_folder_path)

        self._generate_data()

        for table_name in self._get_table_names():
            self._write_table_to_parquet(
                table_name, self.target_mount_folder_path)

        self.con.close()

    def _generate_data(self) -> None:
        '''
        Generate the TPC data in DuckDB. This method should be implemented by subclasses.
        '''
        raise NotImplementedError("Subclasses must implement _generate_data")

    def _get_table_names(self) -> List[str]:
        '''
        Get the list of table names generated by the TPC data generator. This method should be implemented by subclasses.
        '''
        raise NotImplementedError("Subclasses must implement _get_table_names")
