[
  {
    "role": "assistant",
    "content": "You are an expert Python programmer who can correctly implement complete Python classes based on the provided class skeleton."
  },
  {
    "role": "user",
    "content": "For your understanding, following are some (skeleton, code) examples:\n\nExample skeleton:\n\n\nclass ScatterPlot(PluginInterface):\n    '''A Scatter Plot Plugin for Feature Sets.'''\n\n    def __init__(self, show_axes: bool=True):\n        '''Initialize the Scatter Plot Plugin\n        Args:\n            show_axes (bool): Whether to show the axes and grid. Default is True.\n        '''\n        pass\n\n    def create_component(self, component_id: str) -> html.Div:\n        '''Create a Dash Graph Component without any data.\n        Args:\n            component_id (str): The ID of the web component.\n        Returns:\n            html.Div: A Dash Div Component containing the graph and dropdowns.\n        '''\n        pass\n\n    def update_properties(self, input_data: pd.DataFrame, **kwargs) -> list:\n        '''Update the property values for the plugin component.\n        Args:\n            input_data (pd.DataFrame): The input data object.\n            **kwargs: Additional keyword arguments (plugins can define their own arguments).\n                      Note: The current kwargs processed are:\n                            - x: The default x-axis column\n                            - y: The default y-axis column\n                            - color: The default color column\n                            - dropdown_columns: The columns to use for the x and y options\n                            - hover_columns: The columns to show when hovering over a point\n                            - suppress_hover_display: Suppress hover display (default: False)\n                            - custom_data: Custom data that get passed to hoverData callbacks\n        Returns:\n            list: A list of updated property values (figure, x options, y options, color options,\n                                                    label options, x default, y default,\n                                                    color default).\n        '''\n        pass\n\n    def create_scatter_plot(self, df: pd.DataFrame, x_col: str, y_col: str, color_col: str, label_col: str, regression_line: bool=False, marker_size: int=15) -> go.Figure:\n        '''Create a Plotly Scatter Plot figure.\n        Args:\n            df (pd.DataFrame): The dataframe containing the data.\n            x_col (str): The column to use for the x-axis.\n            y_col (str): The column to use for the y-axis.\n            color_col (str): The column to use for the color scale.\n            label_col (str): The column to use for point labels.\n            regression_line (bool): Whether to include a regression line.\n            marker_size (int): Size of the markers. Default is 15.\n        Returns:\n            go.Figure: A Plotly Figure object.\n        '''\n        pass\n\n        def generate_hover_text(row):\n                pass\n\n    def register_internal_callbacks(self):\n        '''Register any internal callbacks for the plugin.'''\n        pass\n        @callback(Output(f'{self.component_id}-graph', 'figure', allow_duplicate=True), [Input(f'{self.component_id}-x-dropdown', 'value'), Input(f'{self.component_id}-y-dropdown', 'value'), Input(f'{self.component_id}-color-dropdown', 'value'), Input(f'{self.component_id}-label-dropdown', 'value'), Input(f'{self.component_id}-regression-line', 'value')], prevent_initial_call=True)\n        def _update_scatter_plot(x_value, y_value, color_value, label_value, regression_line):\n                '''Update the Scatter Plot Graph based on the dropdown values.'''\n                pass\n        @callback(Output(f'{self.component_id}-overlay', 'show'), Output(f'{self.component_id}-overlay', 'bbox'), Output(f'{self.component_id}-overlay', 'children'), Input(f'{self.component_id}-graph', 'hoverData'))\n        def _scatter_overlay(hover_data):\n                pass\nCorresponding class implementation:\n\nfrom workbench.utils.theme_manager import ThemeManager\nfrom dash import dcc, html, callback, Input, Output, no_update\nimport plotly.express as px\nimport base64\nimport pandas as pd\nfrom dash.exceptions import PreventUpdate\nfrom workbench.utils.plot_utils import prediction_intervals\nimport plotly.graph_objects as go\nfrom workbench.web_interface.components.plugin_interface import PluginInterface, PluginPage, PluginInputType\n\nclass ScatterPlot(PluginInterface):\n    \"\"\"A Scatter Plot Plugin for Feature Sets.\"\"\"\n    auto_load_page = PluginPage.NONE\n    plugin_input_type = PluginInputType.DATAFRAME\n\n    def __init__(self, show_axes: bool=True):\n        \"\"\"Initialize the Scatter Plot Plugin\n\n        Args:\n            show_axes (bool): Whether to show the axes and grid. Default is True.\n        \"\"\"\n        self.component_id = None\n        self.hover_columns = []\n        self.df = None\n        self.show_axes = show_axes\n        self.theme_manager = ThemeManager()\n        self.colorscale = self.theme_manager.colorscale()\n        super().__init__()\n\n    def create_component(self, component_id: str) -> html.Div:\n        \"\"\"Create a Dash Graph Component without any data.\n\n        Args:\n            component_id (str): The ID of the web component.\n\n        Returns:\n            html.Div: A Dash Div Component containing the graph and dropdowns.\n        \"\"\"\n        self.component_id = component_id\n        self.properties = [(f'{component_id}-graph', 'figure'), (f'{component_id}-x-dropdown', 'options'), (f'{component_id}-y-dropdown', 'options'), (f'{component_id}-color-dropdown', 'options'), (f'{component_id}-label-dropdown', 'options'), (f'{component_id}-x-dropdown', 'value'), (f'{component_id}-y-dropdown', 'value'), (f'{component_id}-color-dropdown', 'value')]\n        self.signals = [(f'{component_id}-graph', 'hoverData'), (f'{component_id}-graph', 'clickData')]\n        return html.Div(children=[dcc.Graph(id=f'{component_id}-graph', figure=self.display_text('Waiting for Data...'), config={'scrollZoom': True}, style={'height': '100%'}, clear_on_unhover=True), html.Div([html.Label('X', style={'marginLeft': '40px', 'marginRight': '5px', 'fontWeight': 'bold'}), dcc.Dropdown(id=f'{component_id}-x-dropdown', className='dropdown', style={'min-width': '50px', 'flex': 1}, clearable=False), html.Label('Y', style={'marginLeft': '30px', 'marginRight': '5px', 'fontWeight': 'bold'}), dcc.Dropdown(id=f'{component_id}-y-dropdown', className='dropdown', style={'min-width': '50px', 'flex': 1}, clearable=False), html.Label('Color', style={'marginLeft': '30px', 'marginRight': '5px', 'fontWeight': 'bold'}), dcc.Dropdown(id=f'{component_id}-color-dropdown', className='dropdown', style={'min-width': '50px', 'flex': 1}, clearable=False), html.Label('Label', style={'marginLeft': '30px', 'marginRight': '5px', 'fontWeight': 'bold'}), dcc.Dropdown(id=f'{component_id}-label-dropdown', className='dropdown', style={'min-width': '50px', 'flex': 1}, options=[{'label': 'None', 'value': 'none'}], value='none', clearable=False), dcc.Checklist(id=f'{component_id}-regression-line', options=[{'label': ' Diagonal', 'value': 'show'}], value=[], style={'margin': '10px'})], style={'padding': '0px 0px 10px 0px', 'display': 'flex', 'gap': '10px'}), dcc.Tooltip(id=f'{component_id}-overlay', background_color='rgba(0,0,0,0)', border_color='rgba(0,0,0,0)', direction='bottom', loading_text='')], style={'height': '100%', 'display': 'flex', 'flexDirection': 'column'})\n\n    def update_properties(self, input_data: pd.DataFrame, **kwargs) -> list:\n        \"\"\"Update the property values for the plugin component.\n\n        Args:\n            input_data (pd.DataFrame): The input data object.\n            **kwargs: Additional keyword arguments (plugins can define their own arguments).\n                      Note: The current kwargs processed are:\n                            - x: The default x-axis column\n                            - y: The default y-axis column\n                            - color: The default color column\n                            - dropdown_columns: The columns to use for the x and y options\n                            - hover_columns: The columns to show when hovering over a point\n                            - suppress_hover_display: Suppress hover display (default: False)\n                            - custom_data: Custom data that get passed to hoverData callbacks\n\n        Returns:\n            list: A list of updated property values (figure, x options, y options, color options,\n                                                    label options, x default, y default,\n                                                    color default).\n        \"\"\"\n        limit = kwargs.get('limit', 20000)\n        if isinstance(input_data, pd.DataFrame):\n            self.df = input_data.sample(n=limit) if len(input_data) > limit else input_data\n        else:\n            raise ValueError('The input data must be a Pandas DataFrame.')\n        aws_cols = ['write_time', 'api_invocation_time', 'is_deleted', 'event_time']\n        self.df = self.df.drop(columns=aws_cols, errors='ignore')\n        self.hover_columns = kwargs.get('hover_columns', self.df.columns.tolist()[:10])\n        self.suppress_hover_display = kwargs.get('suppress_hover_display', False)\n        self.custom_data = kwargs.get('custom_data', [])\n        numeric_columns = self.df.select_dtypes(include='number').columns.tolist()\n        if len(numeric_columns) < 3:\n            raise ValueError('At least three numeric columns are required for x, y, and color.')\n        x_default = kwargs.get('x', numeric_columns[0])\n        y_default = kwargs.get('y', numeric_columns[1])\n        color_default = kwargs.get('color', numeric_columns[2])\n        regression_line = kwargs.get('regression_line', False)\n        figure = self.create_scatter_plot(self.df, x_default, y_default, color_default, 'none', regression_line)\n        dropdown_columns = kwargs.get('dropdown_columns', numeric_columns)\n        x_options = [{'label': col, 'value': col} for col in dropdown_columns]\n        y_options = x_options.copy()\n        cat_columns = self.df.select_dtypes(include=['object', 'string', 'category']).columns.tolist()\n        cat_columns = [col for col in cat_columns if self.df[col].astype(str).nunique() < 20]\n        color_columns = numeric_columns + cat_columns\n        color_options = [{'label': col, 'value': col} for col in color_columns]\n        label_options = [{'label': 'None', 'value': 'none'}]\n        label_options.extend([{'label': col, 'value': col} for col in self.df.columns])\n        return [figure, x_options, y_options, color_options, label_options, x_default, y_default, color_default]\n\n    def create_scatter_plot(self, df: pd.DataFrame, x_col: str, y_col: str, color_col: str, label_col: str, regression_line: bool=False, marker_size: int=15) -> go.Figure:\n        \"\"\"Create a Plotly Scatter Plot figure.\n\n        Args:\n            df (pd.DataFrame): The dataframe containing the data.\n            x_col (str): The column to use for the x-axis.\n            y_col (str): The column to use for the y-axis.\n            color_col (str): The column to use for the color scale.\n            label_col (str): The column to use for point labels.\n            regression_line (bool): Whether to include a regression line.\n            marker_size (int): Size of the markers. Default is 15.\n\n        Returns:\n            go.Figure: A Plotly Figure object.\n        \"\"\"\n        show_labels = label_col != 'none' and len(df) < 1000\n\n        def generate_hover_text(row):\n            return '<br>'.join([f'{col}: {row[col]}' for col in self.hover_columns])\n        hovertext = df.apply(generate_hover_text, axis=1)\n        hovertemplate = '%{hovertext}<extra></extra>'\n        hoverinfo = 'none' if self.suppress_hover_display else None\n        if pd.api.types.is_numeric_dtype(df[color_col]):\n            marker_color = df[color_col]\n            colorbar = dict(title=color_col, thickness=10)\n            data = [go.Scattergl(x=df[x_col], y=df[y_col], mode='markers', text=df[label_col].astype(str) if show_labels else None, textposition='top center', hoverinfo=hoverinfo, hovertext=hovertext, hovertemplate=hovertemplate, customdata=df[self.custom_data], marker=dict(size=marker_size, color=marker_color, colorscale=self.colorscale, colorbar=colorbar, opacity=0.8, line=dict(color='rgba(0,0,0,0.25)', width=1)))]\n            showlegend = False\n        else:\n            categories = sorted(df[color_col].astype(str).unique())\n            discrete_colors = px.colors.qualitative.Plotly\n            data = []\n            for i, cat in enumerate(categories):\n                sub_df = df[df[color_col] == cat]\n                sub_hovertext = hovertext.loc[sub_df.index]\n                trace = go.Scattergl(x=sub_df[x_col], y=sub_df[y_col], mode='markers', text=sub_df[label_col] if show_labels else None, textposition='top center', name=cat, hoverinfo=hoverinfo, hovertext=sub_hovertext, hovertemplate=hovertemplate, customdata=sub_df[self.custom_data], marker=dict(size=marker_size, color=discrete_colors[i % len(discrete_colors)], opacity=0.8, line=dict(color='rgba(0,0,0,0.25)', width=1)))\n                data.append(trace)\n            showlegend = True\n        figure = go.Figure()\n        if y_col == 'prediction' or x_col == 'prediction':\n            figure = prediction_intervals(df, figure, x_col)\n        if regression_line:\n            axis_min = min(df[x_col].min(), df[y_col].min())\n            axis_max = max(df[x_col].max(), df[y_col].max())\n            figure.add_shape(type='line', line=dict(width=4, color='rgba(128, 128, 128, 1.0)'), x0=axis_min, x1=axis_max, y0=axis_min, y1=axis_max)\n        figure.add_traces(data)\n        if self.show_axes:\n            xaxis = dict(title=dict(text=x_col, font=dict(size=16), standoff=15), tickformat='.2f', tickfont=dict(size=10))\n            yaxis = dict(title=dict(text=y_col, font=dict(size=16), standoff=25), tickformat='.2f', tickfont=dict(size=10))\n        else:\n            xaxis = dict(visible=False)\n            yaxis = dict(visible=False)\n        figure.update_layout(margin={'t': 20, 'b': 55, 'r': 0, 'l': 35, 'pad': 0}, xaxis=xaxis, yaxis=yaxis, showlegend=showlegend, dragmode='pan', modebar={'bgcolor': 'rgba(0, 0, 0, 0)'}, uirevision='constant')\n        return figure\n\n    def register_internal_callbacks(self):\n        \"\"\"Register any internal callbacks for the plugin.\"\"\"\n\n        @callback(Output(f'{self.component_id}-graph', 'figure', allow_duplicate=True), [Input(f'{self.component_id}-x-dropdown', 'value'), Input(f'{self.component_id}-y-dropdown', 'value'), Input(f'{self.component_id}-color-dropdown', 'value'), Input(f'{self.component_id}-label-dropdown', 'value'), Input(f'{self.component_id}-regression-line', 'value')], prevent_initial_call=True)\n        def _update_scatter_plot(x_value, y_value, color_value, label_value, regression_line):\n            \"\"\"Update the Scatter Plot Graph based on the dropdown values.\"\"\"\n            if not self.df.empty and x_value and y_value and color_value:\n                figure = self.create_scatter_plot(self.df, x_value, y_value, color_value, label_value, regression_line)\n                return figure\n            raise PreventUpdate\n\n        @callback(Output(f'{self.component_id}-overlay', 'show'), Output(f'{self.component_id}-overlay', 'bbox'), Output(f'{self.component_id}-overlay', 'children'), Input(f'{self.component_id}-graph', 'hoverData'))\n        def _scatter_overlay(hover_data):\n            if hover_data is None:\n                return (False, no_update, no_update)\n            bbox = hover_data['points'][0]['bbox']\n            svg = '\\n            <svg xmlns=\"http://www.w3.org/2000/svg\" width=\"100\" height=\"100\" style=\"overflow: visible;\">\\n                <!-- Circle for the node -->\\n                <circle cx=\"50\" cy=\"50\" r=\"10\" stroke=\"rgba(255, 255, 255, 1)\" stroke-width=\"3\" fill=\"none\" />\\n            </svg>\\n            '\n            encoded_svg = base64.b64encode(svg.encode('utf-8')).decode('utf-8')\n            data_uri = f'data:image/svg+xml;base64,{encoded_svg}'\n            svg_image = html.Img(src=data_uri, style={'width': '100px', 'height': '100px'})\n            center_x = (bbox['x0'] + bbox['x1']) / 2\n            center_y = (bbox['y0'] + bbox['y1']) / 2\n            adjusted_bbox = {'x0': center_x - 50, 'x1': center_x + 50, 'y0': center_y - 162, 'y1': center_y - 62}\n            return (True, adjusted_bbox, [svg_image])\n\nExample skeleton:\n\n\nclass AWSELBTextPlugin(interface.TextPlugin):\n    '''Text parser plugin for AWS ELB access log files.'''\n\n    def _GetValueFromGroup(self, structure, name, key_name):\n        '''Retrieves a value from a Pyparsing.Group structure.\n        Args:\n          structure (pyparsing.ParseResults): tokens from a parsed log line.\n          name (str): name of the token.\n          key_name (str): key name to retrieve the value of.\n        Returns:\n          object: value for the specified key or None if not available.\n        '''\n        pass\n\n    def _ParseRecord(self, parser_mediator, key, structure):\n        '''Parses a pyparsing structure.\n        Args:\n          parser_mediator (ParserMediator): mediates interactions between parsers\n              and other components, such as storage and dfVFS.\n          key (str): name of the parsed structure.\n          structure (pyparsing.ParseResults): tokens from a parsed log line.\n        Raises:\n          ParseError: if the structure cannot be parsed.\n        '''\n        pass\n\n    def _ParseTimeElements(self, time_elements_structure):\n        '''Parses date and time elements of a log line.\n        Args:\n          time_elements_structure (pyparsing.ParseResults): date and time elements\n              of a log line.\n        Returns:\n          dfdatetime.TimeElements: date and time value.\n        Raises:\n          ParseError: if a valid date and time value cannot be derived from\n              the time elements.\n        '''\n        pass\n\n    def CheckRequiredFormat(self, parser_mediator, text_reader):\n        '''Check if the log record has the minimal structure required by the plugin.\n        Args:\n          parser_mediator (ParserMediator): mediates interactions between parsers\n              and other components, such as storage and dfVFS.\n          text_reader (EncodedTextReader): text reader.\n        Returns:\n          bool: True if this is the correct plugin, False otherwise.\n        '''\n        pass\nCorresponding class implementation:\n\nimport pyparsing\nfrom plaso.parsers.text_plugins import interface\nfrom plaso.lib import errors\nfrom dfdatetime import time_elements as dfdatetime_time_elements\n\nclass AWSELBTextPlugin(interface.TextPlugin):\n    \"\"\"Text parser plugin for AWS ELB access log files.\"\"\"\n    NAME = 'aws_elb_access'\n    DATA_FORMAT = 'AWS ELB Access log file'\n    ENCODING = 'utf-8'\n    _BLANK = pyparsing.Literal('\"-\"') | pyparsing.Literal('-')\n    _WORD = pyparsing.Word(pyparsing.printables) | _BLANK\n    _INTEGER = pyparsing.Word(pyparsing.nums).set_parse_action(lambda tokens: int(tokens[0], 10))\n    _UNSIGNED_INTEGER = _INTEGER | _BLANK\n    _SIGNED_INTEGER = pyparsing.Word('-', pyparsing.nums) | _UNSIGNED_INTEGER\n    _FLOATING_POINT = pyparsing.Word(pyparsing.nums + '.') | pyparsing.Literal('-1')\n    _IP_ADDRESS = pyparsing.pyparsing_common.ipv4_address | pyparsing.pyparsing_common.ipv6_address\n    _PORT = pyparsing.Word(pyparsing.nums, max=6).set_parse_action(lambda tokens: int(tokens[0], 10)) | _BLANK\n    _SOURCE_IP_ADDRESS_AND_PORT = pyparsing.Group(_IP_ADDRESS.set_results_name('source_ip_address') + pyparsing.Suppress(':') + _PORT.set_results_name('source_port') | _BLANK)\n    _DESTINATION_IP_ADDRESS_AND_PORT = pyparsing.Group(_IP_ADDRESS.set_results_name('destination_ip_address') + pyparsing.Suppress(':') + _PORT.set_results_name('destination_port') | _BLANK)\n    _DATE_TIME_ISOFORMAT_STRING = pyparsing.Regex('([0-9]{4}-[0-9]{2}-[0-9]{2}T[0-9]{2}:[0-9]{2}:[0-9]{2}.[0-9]{6})Z')\n    _DATE_TIME_ISOFORMAT_STRING_WITHOUT_TIMEZONE = pyparsing.Regex('([0-9]{4}-[0-9]{2}-[0-9]{2}T[0-9]{2}:[0-9]{2}:[0-9]{2})')\n    _REQUEST = pyparsing.quotedString.set_results_name('request').set_parse_action(pyparsing.removeQuotes)\n    _USER_AGENT = pyparsing.quotedString.set_results_name('user_agent').set_parse_action(pyparsing.removeQuotes)\n    _ALPN_CLIENT_PREFERENCE_LIST = pyparsing.quotedString.set_results_name('alpn_client_preference_list').set_parse_action(pyparsing.removeQuotes)\n    _END_OF_LINE = pyparsing.Suppress(pyparsing.LineEnd())\n    _APPLICATION_LOG_LINE = _WORD.set_results_name('request_type') + _DATE_TIME_ISOFORMAT_STRING.set_results_name('response_time') + _WORD.set_results_name('resource_identifier') + _SOURCE_IP_ADDRESS_AND_PORT.set_results_name('source_ip_port') + _DESTINATION_IP_ADDRESS_AND_PORT.set_results_name('destination_ip_port') + _FLOATING_POINT.set_results_name('request_processing_duration') + _FLOATING_POINT.set_results_name('destination_processing_duration') + _FLOATING_POINT.set_results_name('response_processing_duration') + _UNSIGNED_INTEGER.set_results_name('elb_status_code') + _UNSIGNED_INTEGER.set_results_name('destination_status_code') + _UNSIGNED_INTEGER.set_results_name('received_bytes') + _UNSIGNED_INTEGER.set_results_name('sent_bytes') + _REQUEST + _USER_AGENT + _WORD.set_results_name('ssl_cipher') + _WORD.set_results_name('ssl_protocol') + _WORD.set_results_name('destination_group_arn') + pyparsing.quotedString.set_results_name('trace_identifier').set_parse_action(pyparsing.removeQuotes) + pyparsing.quotedString.set_results_name('domain_name').set_parse_action(pyparsing.removeQuotes) + pyparsing.quotedString.set_results_name('chosen_cert_arn').set_parse_action(pyparsing.removeQuotes) + _SIGNED_INTEGER.set_results_name('matched_rule_priority') + _DATE_TIME_ISOFORMAT_STRING.set_results_name('request_time') + pyparsing.quotedString.set_results_name('actions_executed').set_parse_action(pyparsing.removeQuotes) + pyparsing.quotedString.set_results_name('redirect_url').set_parse_action(pyparsing.removeQuotes) + pyparsing.quotedString.set_results_name('error_reason').set_parse_action(pyparsing.removeQuotes) + pyparsing.quotedString.set_results_name('destination_list').set_parse_action(pyparsing.removeQuotes) + pyparsing.quotedString.set_results_name('destination_status_code_list').set_parse_action(pyparsing.removeQuotes) + pyparsing.quotedString.set_results_name('classification').set_parse_action(pyparsing.removeQuotes) + pyparsing.quotedString.set_results_name('classification_reason').set_parse_action(pyparsing.removeQuotes) + _END_OF_LINE\n    _NETWORK_LOG_LINE = _WORD.set_results_name('request_type') + _WORD.set_results_name('version') + _DATE_TIME_ISOFORMAT_STRING_WITHOUT_TIMEZONE.set_results_name('response_time') + _WORD.set_results_name('resource_identifier') + _WORD.set_results_name('listener') + _SOURCE_IP_ADDRESS_AND_PORT.set_results_name('source_ip_port') + _DESTINATION_IP_ADDRESS_AND_PORT.set_results_name('destination_ip_port') + _UNSIGNED_INTEGER.set_results_name('connection_duration') + _UNSIGNED_INTEGER.set_results_name('handshake_duration') + _UNSIGNED_INTEGER.set_results_name('received_bytes') + _UNSIGNED_INTEGER.set_results_name('sent_bytes') + _WORD.set_results_name('incoming_tls_alert') + _WORD.set_results_name('chosen_cert_arn') + _WORD.set_results_name('chosen_cert_serial') + _WORD.set_results_name('tls_cipher') + _WORD.set_results_name('tls_protocol_version') + _WORD.set_results_name('tls_named_group') + _WORD.set_results_name('domain_name') + _WORD.set_results_name('alpn_front_end_protocol') + _WORD.set_results_name('alpn_back_end_protocol') + (_ALPN_CLIENT_PREFERENCE_LIST | pyparsing.Literal('-')) + _END_OF_LINE\n    _CLASSIC_LOG_LINE = _DATE_TIME_ISOFORMAT_STRING.set_results_name('response_time') + _WORD.set_results_name('resource_identifier') + _SOURCE_IP_ADDRESS_AND_PORT.set_results_name('source_ip_port') + _DESTINATION_IP_ADDRESS_AND_PORT.set_results_name('destination_ip_port') + _FLOATING_POINT.set_results_name('request_processing_duration') + _FLOATING_POINT.set_results_name('destination_processing_duration') + _FLOATING_POINT.set_results_name('response_processing_duration') + _UNSIGNED_INTEGER.set_results_name('elb_status_code') + _UNSIGNED_INTEGER.set_results_name('destination_status_code') + _SIGNED_INTEGER.set_results_name('received_bytes') + _SIGNED_INTEGER.set_results_name('sent_bytes') + _REQUEST + _USER_AGENT + _WORD.set_results_name('ssl_cipher') + _WORD.set_results_name('ssl_protocol') + _END_OF_LINE\n    _LINE_STRUCTURES = [('elb_application_accesslog', _APPLICATION_LOG_LINE), ('elb_classic_accesslog', _CLASSIC_LOG_LINE), ('elb_network_accesslog', _NETWORK_LOG_LINE)]\n    VERIFICATION_GRAMMAR = _APPLICATION_LOG_LINE ^ _CLASSIC_LOG_LINE ^ _NETWORK_LOG_LINE\n\n    def _GetValueFromGroup(self, structure, name, key_name):\n        \"\"\"Retrieves a value from a Pyparsing.Group structure.\n\n        Args:\n          structure (pyparsing.ParseResults): tokens from a parsed log line.\n          name (str): name of the token.\n          key_name (str): key name to retrieve the value of.\n\n        Returns:\n          object: value for the specified key or None if not available.\n        \"\"\"\n        structure_value = self._GetValueFromStructure(structure, name)\n        if structure_value is None:\n            return None\n        return structure_value.get(key_name)\n\n    def _ParseRecord(self, parser_mediator, key, structure):\n        \"\"\"Parses a pyparsing structure.\n\n        Args:\n          parser_mediator (ParserMediator): mediates interactions between parsers\n              and other components, such as storage and dfVFS.\n          key (str): name of the parsed structure.\n          structure (pyparsing.ParseResults): tokens from a parsed log line.\n\n        Raises:\n          ParseError: if the structure cannot be parsed.\n        \"\"\"\n        destination_list = self._GetValueFromStructure(structure, 'destination_list')\n        if destination_list:\n            destination_list = destination_list.split()\n        chosen_cert_serial = self._GetValueFromStructure(structure, 'chosen_cert_serial')\n        if chosen_cert_serial == '-':\n            chosen_cert_serial = None\n        classification = self._GetValueFromStructure(structure, 'classification')\n        if classification == '-':\n            classification = None\n        classification_reason = self._GetValueFromStructure(structure, 'classification_reason')\n        if classification_reason == '-':\n            classification_reason = None\n        destination_status_code = self._GetValueFromStructure(structure, 'destination_status_code')\n        if destination_status_code == '-':\n            destination_status_code = None\n        elb_status_code = self._GetValueFromStructure(structure, 'elb_status_code')\n        if elb_status_code == '-':\n            elb_status_code = None\n        error_reason = self._GetValueFromStructure(structure, 'error_reason')\n        if error_reason == '-':\n            error_reason = None\n        incoming_tls_alert = self._GetValueFromStructure(structure, 'incoming_tls_alert')\n        if incoming_tls_alert == '-':\n            incoming_tls_alert = None\n        redirect_url = self._GetValueFromStructure(structure, 'redirect_url')\n        if redirect_url == '-':\n            redirect_url = None\n        ssl_cipher = self._GetValueFromStructure(structure, 'ssl_cipher')\n        if ssl_cipher == '-':\n            ssl_cipher = None\n        ssl_protocol = self._GetValueFromStructure(structure, 'ssl_protocol')\n        if ssl_protocol == '-':\n            ssl_protocol = None\n        tls_named_group = self._GetValueFromStructure(structure, 'tls_named_group')\n        if tls_named_group == '-':\n            tls_named_group = None\n        user_agent = self._GetValueFromStructure(structure, 'user_agent')\n        if user_agent == '-':\n            user_agent = None\n        event_data = AWSELBEventData()\n        event_data.request_type = self._GetValueFromStructure(structure, 'request_type')\n        event_data.resource_identifier = self._GetValueFromStructure(structure, 'resource_identifier')\n        event_data.source_ip_address = self._GetValueFromGroup(structure, 'source_ip_port', 'source_ip_address')\n        event_data.source_port = self._GetValueFromGroup(structure, 'source_ip_port', 'source_port')\n        event_data.destination_ip_address = self._GetValueFromGroup(structure, 'destination_ip_port', 'destination_ip_address')\n        event_data.destination_port = self._GetValueFromGroup(structure, 'destination_ip_port', 'destination_port')\n        event_data.request_processing_duration = self._GetValueFromStructure(structure, 'request_processing_duration')\n        event_data.destination_processing_duration = self._GetValueFromStructure(structure, 'destination_processing_duration')\n        event_data.response_processing_duration = self._GetValueFromStructure(structure, 'response_processing_duration')\n        event_data.elb_status_code = elb_status_code\n        event_data.destination_status_code = destination_status_code\n        event_data.received_bytes = self._GetValueFromStructure(structure, 'received_bytes')\n        event_data.sent_bytes = self._GetValueFromStructure(structure, 'sent_bytes')\n        event_data.request = self._GetValueFromStructure(structure, 'request')\n        event_data.user_agent = user_agent\n        event_data.ssl_cipher = ssl_cipher\n        event_data.ssl_protocol = ssl_protocol\n        event_data.destination_group_arn = self._GetValueFromStructure(structure, 'destination_group_arn')\n        event_data.trace_identifier = self._GetValueFromStructure(structure, 'trace_identifier')\n        event_data.domain_name = self._GetValueFromStructure(structure, 'domain_name')\n        event_data.chosen_cert_arn = self._GetValueFromStructure(structure, 'chosen_cert_arn')\n        event_data.matched_rule_priority = self._GetValueFromStructure(structure, 'matched_rule_priority')\n        event_data.actions_executed = self._GetValueFromStructure(structure, 'actions_executed')\n        event_data.redirect_url = redirect_url\n        event_data.error_reason = error_reason\n        event_data.destination_status_code_list = self._GetValueFromStructure(structure, 'destination_status_code_list')\n        event_data.classification = classification\n        event_data.classification_reason = classification_reason\n        event_data.destination_list = destination_list\n        event_data.version = self._GetValueFromStructure(structure, 'version')\n        event_data.listener = self._GetValueFromStructure(structure, 'listener')\n        event_data.connection_duration = self._GetValueFromStructure(structure, 'connection_duration')\n        event_data.handshake_duration = self._GetValueFromStructure(structure, 'handshake_duration')\n        event_data.incoming_tls_alert = incoming_tls_alert\n        event_data.chosen_cert_serial = chosen_cert_serial\n        event_data.tls_named_group = tls_named_group\n        event_data.tls_cipher = self._GetValueFromStructure(structure, 'tls_cipher')\n        event_data.tls_protocol_version = self._GetValueFromStructure(structure, 'tls_protocol_version')\n        event_data.alpn_front_end_protocol = self._GetValueFromStructure(structure, 'alpn_front_end_protocol')\n        event_data.alpn_back_end_protocol = self._GetValueFromStructure(structure, 'alpn_back_end_protocol')\n        event_data.alpn_client_preference_list = self._GetValueFromStructure(structure, 'alpn_client_preference_list')\n        response_time_structure = self._GetValueFromStructure(structure, 'response_time')\n        if response_time_structure:\n            event_data.response_time = self._ParseTimeElements(response_time_structure)\n        request_time_structure = structure.get('request_time')\n        if request_time_structure:\n            event_data.request_time = self._ParseTimeElements(request_time_structure)\n        parser_mediator.ProduceEventData(event_data)\n\n    def _ParseTimeElements(self, time_elements_structure):\n        \"\"\"Parses date and time elements of a log line.\n\n        Args:\n          time_elements_structure (pyparsing.ParseResults): date and time elements\n              of a log line.\n\n        Returns:\n          dfdatetime.TimeElements: date and time value.\n\n        Raises:\n          ParseError: if a valid date and time value cannot be derived from\n              the time elements.\n        \"\"\"\n        try:\n            if len(time_elements_structure) == 27:\n                date_time = dfdatetime_time_elements.TimeElementsInMicroseconds()\n                date_time.CopyFromStringISO8601(time_elements_structure)\n            else:\n                date_time = dfdatetime_time_elements.TimeElements()\n                date_time.CopyFromStringISO8601(time_elements_structure)\n                date_time.is_local_time = True\n            return date_time\n        except (TypeError, ValueError) as exception:\n            raise errors.ParseError(f'Unable to parse time elements with error: {exception!s}')\n\n    def CheckRequiredFormat(self, parser_mediator, text_reader):\n        \"\"\"Check if the log record has the minimal structure required by the plugin.\n\n        Args:\n          parser_mediator (ParserMediator): mediates interactions between parsers\n              and other components, such as storage and dfVFS.\n          text_reader (EncodedTextReader): text reader.\n\n        Returns:\n          bool: True if this is the correct plugin, False otherwise.\n        \"\"\"\n        try:\n            structure = self._VerifyString(text_reader.lines)\n        except errors.ParseError:\n            return False\n        time_elements_structure = self._GetValueFromStructure(structure, 'response_time')\n        if time_elements_structure:\n            try:\n                self._ParseTimeElements(time_elements_structure)\n            except errors.ParseError:\n                return False\n        time_elements_structure = self._GetValueFromStructure(structure, 'request_time')\n        if time_elements_structure:\n            try:\n                self._ParseTimeElements(time_elements_structure)\n            except errors.ParseError:\n                return False\n        return True\n\nNow, implement the following class. Do not explain the code. The given class skeleton is as follows:\n\nclass PlayerMixin:\n    '''\n    Mixin class for BedrockServerManager that handles player database management.\n        '''\n\n    def parse_player_cli_argument(self, player_string: str) -> None:\n        '''Parses a comma-separated string of 'player_name:xuid' pairs and saves them to the database.\n        This utility method is designed to process player data provided as a\n        single string, typically from a command-line argument. Each player entry\n        in the string should be in the format \"PlayerName:PlayerXUID\", and multiple\n        entries should be separated by commas. Whitespace around names, XUIDs,\n        commas, and colons is generally handled.\n        Example:\n            ``\"Player One:12345, PlayerTwo:67890\"``\n        Args:\n            player_string (str): The comma-separated string of player data.\n                If empty or not a string, an empty list is returned.\n        Raises:\n            UserInputError: If any player pair within the string does not conform\n                to the \"name:xuid\" format, or if a name or XUID is empty after stripping.\n        '''\n        pass\n\n    def save_player_data(self, players_data: List[Dict[str, str]]) -> int:\n        '''Saves or updates player data in the database.\n        This method merges the provided ``players_data`` with any existing player\n        data in the database.\n        The merging logic is as follows:\n            - If a player's XUID from ``players_data`` already exists in the database,\n              their entry (name and XUID) is updated if different.\n            - If a player's XUID is new, their entry is added to the database.\n        Args:\n            players_data (List[Dict[str, str]]): A list of player dictionaries.\n                Each dictionary must contain string values for ``\"name\"`` and ``\"xuid\"`` keys.\n                Both name and XUID must be non-empty.\n        Returns:\n            int: The total number of players that were newly added or had their\n            existing entry updated. Returns 0 if no changes were made.\n        Raises:\n            UserInputError: If ``players_data`` is not a list, or if any dictionary\n                within it does not conform to the required format (missing keys,\n                non-string values, or empty name/XUID).\n        '''\n        pass\n\n    def get_known_players(self) -> List[Dict[str, str]]:\n        '''Retrieves all known players from the database.\n        Returns:\n            List[Dict[str, str]]: A list of player dictionaries, where each\n            dictionary typically contains ``\"name\"`` and ``\"xuid\"`` keys.\n        '''\n        pass\n\n    def discover_and_store_players_from_all_server_logs(self, app_context: Optional[AppContext]=None) -> Dict[str, Any]:\n        '''Scans all server logs for player data and updates the central player database.\n        This comprehensive method performs the following actions:\n            1. Iterates through all subdirectories within the application's base server\n               directory (defined by ``settings['paths.servers']``).\n            2. For each subdirectory, it attempts to instantiate a\n               :class:`~.core.bedrock_server.BedrockServer` object.\n            3. If the server instance is valid and installed, it calls the server's\n               :meth:`~.core.server.player_mixin.ServerPlayerMixin.scan_log_for_players`\n               method to extract player names and XUIDs from its logs.\n            4. All player data discovered from all server logs is aggregated.\n            5. Unique player entries (based on XUID) are then saved to the database\n               using :meth:`.save_player_data`.\n        Args:\n            None\n        Returns:\n            Dict[str, Any]: A dictionary summarizing the discovery and saving operation,\n            containing the following keys:\n                - ``\"total_entries_in_logs\"`` (int): The total number of player entries\n                  (possibly non-unique) found across all server logs.\n                - ``\"unique_players_submitted_for_saving\"`` (int): The number of unique\n                  player entries (by XUID) that were attempted to be saved.\n                - ``\"actually_saved_or_updated_in_db\"`` (int): The number of players\n                  that were newly added or updated in the database\n                  by the :meth:`.save_player_data` call.\n                - ``\"scan_errors\"`` (List[Dict[str, str]]): A list of dictionaries,\n                  where each entry represents an error encountered while scanning a\n                  specific server's logs or saving the global player DB. Each error\n                  dictionary contains ``\"server\"`` (str, server name or \"GLOBAL_PLAYER_DB\")\n                  and ``\"error\"`` (str, error message).\n        Raises:\n            AppFileNotFoundError: If the main server base directory\n                (``settings['paths.servers']``) is not configured or does not exist.\n            FileOperationError: If the final save operation to the database\n                (via :meth:`.save_player_data`) fails.\n                Note that errors during individual server log scans are caught and\n                reported in the ``\"scan_errors\"`` part of the return value.\n        '''\n        pass"
  }
]