[
  {
    "role": "assistant",
    "content": "You are an expert Python programmer who can correctly implement complete Python classes based on the provided class skeleton."
  },
  {
    "role": "user",
    "content": "For your understanding, following are some (skeleton, code) examples:\n\nExample skeleton:\n\n\nclass JumpStartMetadataBaseFields(JumpStartDataHolderType):\n    '''Data class JumpStart metadata base fields that can be overridden.'''\n\n    def __init__(self, fields: Dict[str, Any], is_hub_content: Optional[bool]=False):\n        '''Initializes a JumpStartMetadataFields object.\n        Args:\n            fields (Dict[str, Any]): Dictionary representation of metadata fields.\n        '''\n        pass\n\n    def from_json(self, json_obj: Dict[str, Any]) -> None:\n        '''Sets fields in object based on json of header.\n        Args:\n            json_obj (Dict[str, Any]): Dictionary representation of spec.\n        '''\n        pass\n\n    def to_json(self) -> Dict[str, Any]:\n        '''Returns json representation of JumpStartMetadataBaseFields object.'''\n        pass\n\n    def set_hub_content_type(self, hub_content_type: HubContentType) -> None:\n        '''Sets the hub content type.'''\n        pass\nCorresponding class implementation:\n\nfrom typing import Any, Callable, Dict, List, Optional, Set, Union\nfrom copy import deepcopy\nfrom sagemaker.jumpstart.hub.parser_utils import camel_to_snake, walk_and_apply_json\n\nclass JumpStartMetadataBaseFields(JumpStartDataHolderType):\n    \"\"\"Data class JumpStart metadata base fields that can be overridden.\"\"\"\n    __slots__ = ['model_id', 'url', 'version', 'min_sdk_version', 'model_types', 'capabilities', 'incremental_training_supported', 'hosting_ecr_specs', 'hosting_ecr_uri', 'hosting_artifact_uri', 'hosting_artifact_key', 'hosting_script_key', 'training_supported', 'training_ecr_specs', 'training_ecr_uri', 'training_artifact_key', 'training_script_key', 'hyperparameters', 'inference_environment_variables', 'inference_vulnerable', 'inference_dependencies', 'inference_vulnerabilities', 'training_vulnerable', 'training_dependencies', 'training_vulnerabilities', 'deprecated', 'usage_info_message', 'deprecated_message', 'deprecate_warn_message', 'default_inference_instance_type', 'supported_inference_instance_types', 'dynamic_container_deployment_supported', 'hosting_resource_requirements', 'default_training_instance_type', 'supported_training_instance_types', 'metrics', 'training_prepacked_script_key', 'training_prepacked_script_version', 'hosting_prepacked_artifact_key', 'hosting_prepacked_artifact_version', 'model_kwargs', 'deploy_kwargs', 'estimator_kwargs', 'fit_kwargs', 'predictor_specs', 'inference_volume_size', 'training_volume_size', 'inference_enable_network_isolation', 'training_enable_network_isolation', 'resource_name_base', 'hosting_eula_key', 'hosting_model_package_arns', 'training_model_package_artifact_uris', 'hosting_use_script_uri', 'hosting_instance_type_variants', 'training_instance_type_variants', 'default_payloads', 'gated_bucket', 'model_subscription_link', 'hosting_additional_data_sources', 'hosting_neuron_model_id', 'hosting_neuron_model_version', 'hub_content_type', '_is_hub_content', 'default_training_dataset_key', 'default_training_dataset_uri']\n    _non_serializable_slots = ['_is_hub_content']\n\n    def __init__(self, fields: Dict[str, Any], is_hub_content: Optional[bool]=False):\n        \"\"\"Initializes a JumpStartMetadataFields object.\n\n        Args:\n            fields (Dict[str, Any]): Dictionary representation of metadata fields.\n        \"\"\"\n        self._is_hub_content = is_hub_content\n        self.from_json(fields)\n\n    def from_json(self, json_obj: Dict[str, Any]) -> None:\n        \"\"\"Sets fields in object based on json of header.\n\n        Args:\n            json_obj (Dict[str, Any]): Dictionary representation of spec.\n        \"\"\"\n        if self._is_hub_content:\n            json_obj = walk_and_apply_json(json_obj, camel_to_snake)\n        self.model_id: str = json_obj.get('model_id')\n        self.url: str = json_obj.get('url')\n        self.version: str = json_obj.get('version')\n        self.min_sdk_version: str = json_obj.get('min_sdk_version')\n        self.incremental_training_supported: bool = bool(json_obj.get('incremental_training_supported', False))\n        if self._is_hub_content:\n            self.capabilities: Optional[List[str]] = json_obj.get('capabilities')\n            self.model_types: Optional[List[str]] = json_obj.get('model_types')\n            self.hosting_ecr_uri: Optional[str] = json_obj.get('hosting_ecr_uri')\n            self._non_serializable_slots.append('hosting_ecr_specs')\n        else:\n            self.hosting_ecr_specs: Optional[JumpStartECRSpecs] = JumpStartECRSpecs(json_obj['hosting_ecr_specs'], is_hub_content=self._is_hub_content) if 'hosting_ecr_specs' in json_obj else None\n            self._non_serializable_slots.append('hosting_ecr_uri')\n        self.hosting_artifact_key: Optional[str] = json_obj.get('hosting_artifact_key')\n        self.hosting_artifact_uri: Optional[str] = json_obj.get('hosting_artifact_uri')\n        self.hosting_script_key: Optional[str] = json_obj.get('hosting_script_key')\n        self.training_supported: Optional[bool] = bool(json_obj.get('training_supported', False))\n        self.inference_environment_variables = [JumpStartEnvironmentVariable(env_variable, is_hub_content=self._is_hub_content) for env_variable in json_obj.get('inference_environment_variables', [])]\n        self.inference_vulnerable: bool = bool(json_obj.get('inference_vulnerable', False))\n        self.inference_dependencies: List[str] = json_obj.get('inference_dependencies', [])\n        self.inference_vulnerabilities: List[str] = json_obj.get('inference_vulnerabilities', [])\n        self.training_vulnerable: bool = bool(json_obj.get('training_vulnerable', False))\n        self.training_dependencies: List[str] = json_obj.get('training_dependencies', [])\n        self.training_vulnerabilities: List[str] = json_obj.get('training_vulnerabilities', [])\n        self.deprecated: bool = bool(json_obj.get('deprecated', False))\n        self.deprecated_message: Optional[str] = json_obj.get('deprecated_message')\n        self.deprecate_warn_message: Optional[str] = json_obj.get('deprecate_warn_message')\n        self.usage_info_message: Optional[str] = json_obj.get('usage_info_message')\n        self.default_inference_instance_type: Optional[str] = json_obj.get('default_inference_instance_type')\n        self.default_training_instance_type: Optional[str] = json_obj.get('default_training_instance_type')\n        self.supported_inference_instance_types: Optional[List[str]] = json_obj.get('supported_inference_instance_types')\n        self.supported_training_instance_types: Optional[List[str]] = json_obj.get('supported_training_instance_types')\n        self.dynamic_container_deployment_supported: Optional[bool] = bool(json_obj.get('dynamic_container_deployment_supported'))\n        self.hosting_resource_requirements: Optional[Dict[str, int]] = json_obj.get('hosting_resource_requirements', None)\n        self.metrics: Optional[List[Dict[str, str]]] = json_obj.get('metrics', None)\n        self.training_prepacked_script_key: Optional[str] = json_obj.get('training_prepacked_script_key', None)\n        self.hosting_prepacked_artifact_key: Optional[str] = json_obj.get('hosting_prepacked_artifact_key', None)\n        if self._is_hub_content:\n            self.training_prepacked_script_version: Optional[str] = json_obj.get('training_prepacked_script_version')\n            self.hosting_prepacked_artifact_version: Optional[str] = json_obj.get('hosting_prepacked_artifact_version')\n        self.model_kwargs = deepcopy(json_obj.get('model_kwargs', {}))\n        self.deploy_kwargs = deepcopy(json_obj.get('deploy_kwargs', {}))\n        self.predictor_specs: Optional[JumpStartPredictorSpecs] = JumpStartPredictorSpecs(json_obj.get('predictor_specs'), is_hub_content=self._is_hub_content) if json_obj.get('predictor_specs') else None\n        self.default_payloads: Optional[Dict[str, JumpStartSerializablePayload]] = {alias: JumpStartSerializablePayload(payload, is_hub_content=self._is_hub_content) for alias, payload in json_obj['default_payloads'].items()} if json_obj.get('default_payloads') else None\n        self.gated_bucket = json_obj.get('gated_bucket', False)\n        self.inference_volume_size: Optional[int] = json_obj.get('inference_volume_size')\n        self.inference_enable_network_isolation: bool = json_obj.get('inference_enable_network_isolation', False)\n        self.resource_name_base: bool = json_obj.get('resource_name_base')\n        self.hosting_eula_key: Optional[str] = json_obj.get('hosting_eula_key')\n        model_package_arns = json_obj.get('hosting_model_package_arns')\n        self.hosting_model_package_arns: Optional[Dict] = model_package_arns if model_package_arns is not None else {}\n        self.hosting_use_script_uri: bool = json_obj.get('hosting_use_script_uri', True)\n        self.hosting_instance_type_variants: Optional[JumpStartInstanceTypeVariants] = JumpStartInstanceTypeVariants(json_obj['hosting_instance_type_variants'], self._is_hub_content) if json_obj.get('hosting_instance_type_variants') else None\n        self.hosting_additional_data_sources: Optional[JumpStartAdditionalDataSources] = JumpStartAdditionalDataSources(json_obj['hosting_additional_data_sources']) if json_obj.get('hosting_additional_data_sources') else None\n        self.hosting_neuron_model_id: Optional[str] = json_obj.get('hosting_neuron_model_id')\n        self.hosting_neuron_model_version: Optional[str] = json_obj.get('hosting_neuron_model_version')\n        if self.training_supported:\n            if self._is_hub_content:\n                self.training_ecr_uri: Optional[str] = json_obj.get('training_ecr_uri')\n                self._non_serializable_slots.append('training_ecr_specs')\n            else:\n                self.training_ecr_specs: Optional[JumpStartECRSpecs] = JumpStartECRSpecs(json_obj['training_ecr_specs']) if 'training_ecr_specs' in json_obj else None\n                self._non_serializable_slots.append('training_ecr_uri')\n            self.training_artifact_key: str = json_obj['training_artifact_key']\n            self.training_script_key: str = json_obj['training_script_key']\n            hyperparameters: Any = json_obj.get('hyperparameters')\n            self.hyperparameters: List[JumpStartHyperparameter] = []\n            if hyperparameters is not None:\n                self.hyperparameters.extend([JumpStartHyperparameter(hyperparameter, is_hub_content=self._is_hub_content) for hyperparameter in hyperparameters])\n            self.estimator_kwargs = deepcopy(json_obj.get('estimator_kwargs', {}))\n            self.fit_kwargs = deepcopy(json_obj.get('fit_kwargs', {}))\n            self.training_volume_size: Optional[int] = json_obj.get('training_volume_size')\n            self.training_enable_network_isolation: bool = json_obj.get('training_enable_network_isolation', False)\n            self.training_model_package_artifact_uris: Optional[Dict] = json_obj.get('training_model_package_artifact_uris')\n            self.training_instance_type_variants: Optional[JumpStartInstanceTypeVariants] = JumpStartInstanceTypeVariants(json_obj['training_instance_type_variants'], is_hub_content=self._is_hub_content) if json_obj.get('training_instance_type_variants') else None\n        self.model_subscription_link = json_obj.get('model_subscription_link')\n        self.default_training_dataset_key: Optional[str] = json_obj.get('default_training_dataset_key')\n        self.default_training_dataset_uri: Optional[str] = json_obj.get('default_training_dataset_uri')\n\n    def to_json(self) -> Dict[str, Any]:\n        \"\"\"Returns json representation of JumpStartMetadataBaseFields object.\"\"\"\n        json_obj = {}\n        for att in self.__slots__:\n            if hasattr(self, att) and att not in getattr(self, '_non_serializable_slots', []):\n                cur_val = getattr(self, att)\n                if issubclass(type(cur_val), JumpStartDataHolderType):\n                    json_obj[att] = cur_val.to_json()\n                elif isinstance(cur_val, list):\n                    json_obj[att] = []\n                    for obj in cur_val:\n                        if issubclass(type(obj), JumpStartDataHolderType):\n                            json_obj[att].append(obj.to_json())\n                        else:\n                            json_obj[att].append(obj)\n                elif isinstance(cur_val, dict):\n                    json_obj[att] = {}\n                    for key, val in cur_val.items():\n                        if issubclass(type(val), JumpStartDataHolderType):\n                            json_obj[att][key] = val.to_json()\n                        else:\n                            json_obj[att][key] = val\n                else:\n                    json_obj[att] = cur_val\n        return json_obj\n\n    def set_hub_content_type(self, hub_content_type: HubContentType) -> None:\n        \"\"\"Sets the hub content type.\"\"\"\n        if self._is_hub_content:\n            self.hub_content_type = hub_content_type\n\nExample skeleton:\n\n\nclass StateTransitionWrapper(Generic[_P, _R, _T]):\n    '''\n    Wraps :class:`StateTransition` with the context of the object it is accessed from.\n    Automatically constructed by :class:`StateTransition`.\n        '''\n\n    def __init__(self, statetransition: StateTransition[_P, _R], obj: _T) -> None:\n        pass\n    @property\n    def data(self) -> dict[str, Any]:\n        '''Return data as provided to the :meth:`~StateManager.transition` decorator.'''\n        pass\n\n    def _validate_available(self) -> Optional[tuple[StateManager, Any, Any]]:\n        '''\n        If the state is invalid for the transition, return details on what didn't match.\n        :return: Tuple of (state manager, current state, label for current state)\n        '''\n        pass\n    @property\n    def is_available(self) -> bool:\n        '''Property that indicates whether this transition is currently available.'''\n        pass\n\n    def __getattr__(self, name: str) -> Any:\n        pass\n\n    def __call__(self, *args: _P.args, **kwargs: _P.kwargs) -> _R:\n        '''Perform the state transition.'''\n        pass\nCorresponding class implementation:\n\nfrom typing import TYPE_CHECKING, Any, Callable, Generic, NoReturn, Optional, Union, cast, overload\nfrom ..utils import LabeledEnum, NameTitle, is_collection\n\nclass StateTransitionWrapper(Generic[_P, _R, _T]):\n    \"\"\"\n    Wraps :class:`StateTransition` with the context of the object it is accessed from.\n\n    Automatically constructed by :class:`StateTransition`.\n    \"\"\"\n\n    def __init__(self, statetransition: StateTransition[_P, _R], obj: _T) -> None:\n        self.statetransition = statetransition\n        self.obj = obj\n\n    @property\n    def data(self) -> dict[str, Any]:\n        \"\"\"Return data as provided to the :meth:`~StateManager.transition` decorator.\"\"\"\n        return self.statetransition.data\n\n    def _validate_available(self) -> Optional[tuple[StateManager, Any, Any]]:\n        \"\"\"\n        If the state is invalid for the transition, return details on what didn't match.\n\n        :return: Tuple of (state manager, current state, label for current state)\n        \"\"\"\n        for statemanager, conditions in self.statetransition.transitions.items():\n            current_state_value = statemanager._get_state_value(self.obj)\n            if conditions.from_ is None:\n                state_valid = True\n            else:\n                mstate = conditions.from_.get(current_state_value)\n                state_valid = mstate is not None and mstate.is_current_in(self.obj)\n            if not state_valid:\n                return (statemanager, current_state_value, statemanager.lenum.get(current_state_value))\n        return None\n\n    @property\n    def is_available(self) -> bool:\n        \"\"\"Property that indicates whether this transition is currently available.\"\"\"\n        return not self._validate_available()\n\n    def __getattr__(self, name: str) -> Any:\n        return getattr(self.statetransition, name)\n\n    def __call__(self, *args: _P.args, **kwargs: _P.kwargs) -> _R:\n        \"\"\"Perform the state transition.\"\"\"\n        state_invalid = self._validate_available()\n        if state_invalid:\n            transition_error.send(self.obj, transition=self.statetransition, statemanager=state_invalid[0])\n            label = state_invalid[2]\n            if isinstance(label, NameTitle):\n                label = label.title\n            raise StateTransitionError(f'Invalid state for transition {self.statetransition.name}: {state_invalid[0]!r} = {label}')\n        transition_before.send(self.obj, transition=self.statetransition)\n        try:\n            result = self.statetransition.func(self.obj, *args, **kwargs)\n        except AbortTransition as e:\n            transition_exception.send(self.obj, transition=self.statetransition, exception=e)\n            return e.result\n        except Exception as e:\n            transition_exception.send(self.obj, transition=self.statetransition, exception=e)\n            raise\n        for statemanager, conditions in self.statetransition.transitions.items():\n            if conditions.to is not None:\n                statemanager._set_state_value(self.obj, conditions.to.value)\n        transition_after.send(self.obj, transition=self.statetransition)\n        return result\n\nNow, implement the following class. Do not explain the code. The given class skeleton is as follows:\n\nclass InMemoryBlobStore:\n    '''In-memory blob storage for testing and short-lived scenarios.'''\n\n    def __init__(self, max_size: int=100):\n        '''\n        Initialize in-memory blob store.\n        Args:\n            max_size: Maximum number of blobs to keep in memory\n        '''\n        pass\n\n    def _evict_if_needed(self) -> None:\n        '''Evict oldest blobs if we've exceeded max_size.'''\n        pass\n\n    def save(self, data: bytes, meta: dict[str, Any]) -> str:\n        '''Save binary data with metadata.'''\n        pass\n\n    def load(self, blob_id: str) -> bytes:\n        '''Load binary data by blob ID.'''\n        pass\n\n    def info(self, blob_id: str) -> dict[str, Any]:\n        '''Get metadata for a blob.'''\n        pass\n\n    def delete(self, blob_id: str) -> None:\n        '''Delete a blob and its metadata.'''\n        pass"
  }
]