[
  {
    "role": "assistant",
    "content": "You are an expert Python programmer who can correctly implement complete Python classes based on the provided class skeleton."
  },
  {
    "role": "user",
    "content": "For your understanding, following are some (skeleton, code) examples:\n\nExample skeleton:\n\n\nclass MRMSGrid(object):\n    '''\n    MRMSGrid reads time series of MRMS grib2 files, interpolates them, and outputs them to netCDF4 format.\n    '''\n\n    def __init__(self, start_date, end_date, variable, path_start, freq='1H'):\n        pass\n\n    def load_data(self):\n        '''\n        Loads data from MRMS GRIB2 files and handles compression duties if files are compressed.\n        '''\n        pass\n\n    def interpolate_grid(self, in_lon, in_lat):\n        '''\n        Interpolates MRMS data to a different grid using cubic bivariate splines\n        '''\n        pass\n\n    def max_neighbor(self, in_lon, in_lat, radius=0.05):\n        '''\n        Finds the largest value within a given radius of a point on the interpolated grid.\n        Args:\n            in_lon: 2D array of longitude values\n            in_lat: 2D array of latitude values\n            radius: radius of influence for largest neighbor search in degrees\n        Returns:\n            Array of interpolated data\n        '''\n        pass\n\n    def interpolate_to_netcdf(self, in_lon, in_lat, out_path, date_unit='seconds since 1970-01-01T00:00', interp_type='spline'):\n        '''\n        Calls the interpolation function and then saves the MRMS data to a netCDF file. It will also create \n        separate directories for each variable if they are not already available.\n        '''\n        pass\nCorresponding class implementation:\n\nimport numpy as np\nfrom netCDF4 import Dataset, date2num\nimport subprocess\nimport xarray as xr\nimport pandas as pd\nimport os\nfrom scipy.interpolate import RectBivariateSpline\nfrom scipy.spatial import cKDTree\n\nclass MRMSGrid(object):\n    \"\"\"\n    MRMSGrid reads time series of MRMS grib2 files, interpolates them, and outputs them to netCDF4 format.\n\n    \"\"\"\n\n    def __init__(self, start_date, end_date, variable, path_start, freq='1H'):\n        self.start_date = start_date\n        self.end_date = end_date\n        self.variable = variable\n        self.path_start = path_start\n        self.freq = freq\n        self.data = None\n        self.all_dates = pd.date_range(start=self.start_date, end=self.end_date, freq=self.freq)\n        self.loaded_dates = None\n        self.lon = None\n        self.lat = None\n        self.load_data()\n\n    def load_data(self):\n        \"\"\"\n        Loads data from MRMS GRIB2 files and handles compression duties if files are compressed.\n        \"\"\"\n        data = []\n        loaded_dates = []\n        loaded_indices = []\n        for t, timestamp in enumerate(self.all_dates):\n            date_str = timestamp.date().strftime('%Y%m%d')\n            full_path = self.path_start + date_str + '/'\n            if self.variable in os.listdir(full_path):\n                full_path += self.variable + '/'\n                data_files = sorted(os.listdir(full_path))\n                file_dates = pd.to_datetime([d.split('_')[-1][0:13] for d in data_files])\n                if timestamp in file_dates:\n                    data_file = data_files[np.where(timestamp == file_dates)[0][0]]\n                    print(full_path + data_file)\n                    if data_file[-2:] == 'gz':\n                        subprocess.call(['gunzip', full_path + data_file])\n                        file_obj = xr.open_dataset(full_path + data_file[:-3])\n                    else:\n                        file_obj = xr.open_dataset(full_path + data_file)\n                    var_name = sorted(file_obj.variables.keys())[0]\n                    data.append(file_obj.variables[var_name][:])\n                    if self.lon is None:\n                        self.lon = file_obj.variables['lon_0'][:]\n                        if np.count_nonzero(self.lon > 180) > 0:\n                            self.lon -= 360\n                        self.lat = file_obj.variables['lat_0'][:]\n                    file_obj.close()\n                    if data_file[-2:] == 'gz':\n                        subprocess.call(['gzip', full_path + data_file[:-3]])\n                    else:\n                        subprocess.call(['gzip', full_path + data_file])\n                    loaded_dates.append(timestamp)\n                    loaded_indices.append(t)\n        if len(loaded_dates) > 0:\n            self.loaded_dates = pd.DatetimeIndex(loaded_dates)\n            self.data = np.ones((self.all_dates.shape[0], data[0].shape[0], data[0].shape[1])) * -9999\n            self.data[loaded_indices] = np.array(data)\n\n    def interpolate_grid(self, in_lon, in_lat):\n        \"\"\"\n        Interpolates MRMS data to a different grid using cubic bivariate splines\n        \"\"\"\n        out_data = np.zeros((self.data.shape[0], in_lon.shape[0], in_lon.shape[1]))\n        for d in range(self.data.shape[0]):\n            print('Loading ', d, self.variable, self.start_date)\n            if self.data[d].max() > -999:\n                step = self.data[d]\n                step[step < 0] = 0\n                if self.lat[-1] < self.lat[0]:\n                    spline = RectBivariateSpline(self.lat[::-1], self.lon, step[::-1], kx=3, ky=3)\n                else:\n                    spline = RectBivariateSpline(self.lat, self.lon, step, kx=3, ky=3)\n                print('Evaluating', d, self.variable, self.start_date)\n                flat_data = spline.ev(in_lat.ravel(), in_lon.ravel())\n                out_data[d] = flat_data.reshape(in_lon.shape)\n                del spline\n            else:\n                print(d, ' is missing')\n                out_data[d] = -9999\n        return out_data\n\n    def max_neighbor(self, in_lon, in_lat, radius=0.05):\n        \"\"\"\n        Finds the largest value within a given radius of a point on the interpolated grid.\n\n        Args:\n            in_lon: 2D array of longitude values\n            in_lat: 2D array of latitude values\n            radius: radius of influence for largest neighbor search in degrees\n\n        Returns:\n            Array of interpolated data\n        \"\"\"\n        out_data = np.zeros((self.data.shape[0], in_lon.shape[0], in_lon.shape[1]))\n        in_tree = cKDTree(np.vstack((in_lat.ravel(), in_lon.ravel())).T)\n        out_indices = np.indices(out_data.shape[1:])\n        out_rows = out_indices[0].ravel()\n        out_cols = out_indices[1].ravel()\n        for d in range(self.data.shape[0]):\n            nz_points = np.where(self.data[d] > 0)\n            if len(nz_points[0]) > 0:\n                nz_vals = self.data[d][nz_points]\n                nz_rank = np.argsort(nz_vals)\n                original_points = cKDTree(np.vstack((self.lat[nz_points[0][nz_rank]], self.lon[nz_points[1][nz_rank]])).T)\n                all_neighbors = original_points.query_ball_tree(in_tree, radius, p=2, eps=0)\n                for n, neighbors in enumerate(all_neighbors):\n                    if len(neighbors) > 0:\n                        out_data[d, out_rows[neighbors], out_cols[neighbors]] = nz_vals[nz_rank][n]\n        return out_data\n\n    def interpolate_to_netcdf(self, in_lon, in_lat, out_path, date_unit='seconds since 1970-01-01T00:00', interp_type='spline'):\n        \"\"\"\n        Calls the interpolation function and then saves the MRMS data to a netCDF file. It will also create \n        separate directories for each variable if they are not already available.\n        \"\"\"\n        if interp_type == 'spline':\n            out_data = self.interpolate_grid(in_lon, in_lat)\n        else:\n            out_data = self.max_neighbor(in_lon, in_lat)\n        if not os.access(out_path + self.variable, os.R_OK):\n            try:\n                os.mkdir(out_path + self.variable)\n            except OSError:\n                print(out_path + self.variable + ' already created')\n        out_file = out_path + self.variable + '/' + '{0}_{1}_{2}.nc'.format(self.variable, self.start_date.strftime('%Y%m%d-%H:%M'), self.end_date.strftime('%Y%m%d-%H:%M'))\n        out_obj = Dataset(out_file, 'w')\n        out_obj.createDimension('time', out_data.shape[0])\n        out_obj.createDimension('y', out_data.shape[1])\n        out_obj.createDimension('x', out_data.shape[2])\n        data_var = out_obj.createVariable(self.variable, 'f4', ('time', 'y', 'x'), zlib=True, fill_value=-9999.0, least_significant_digit=3)\n        data_var[:] = out_data\n        data_var.long_name = self.variable\n        data_var.coordinates = 'latitude longitude'\n        if 'MESH' in self.variable or 'QPE' in self.variable:\n            data_var.units = 'mm'\n        elif 'Reflectivity' in self.variable:\n            data_var.units = 'dBZ'\n        elif 'Rotation' in self.variable:\n            data_var.units = 's-1'\n        else:\n            data_var.units = ''\n        out_lon = out_obj.createVariable('longitude', 'f4', ('y', 'x'), zlib=True)\n        out_lon[:] = in_lon\n        out_lon.units = 'degrees_east'\n        out_lat = out_obj.createVariable('latitude', 'f4', ('y', 'x'), zlib=True)\n        out_lat[:] = in_lat\n        out_lat.units = 'degrees_north'\n        dates = out_obj.createVariable('time', 'i8', ('time',), zlib=True)\n        dates[:] = np.round(date2num(self.all_dates.to_pydatetime(), date_unit)).astype(np.int64)\n        dates.long_name = 'Valid date'\n        dates.units = date_unit\n        out_obj.Conventions = 'CF-1.6'\n        out_obj.close()\n        return\n\nExample skeleton:\n\n\nclass BaseUtmSplitter(AreaSplitter, metaclass=ABCMeta):\n    '''Base splitter that returns bboxes of fixed size aligned to UTM zones or UTM grid tiles as defined by the MGRS\n    The generated bounding box grid will have coordinates in form of\n    `(N * bbox_size_x + offset_x, M * bbox_size_y + offset_y)`\n    '''\n\n    def __init__(self, shape_list: Iterable[Polygon | MultiPolygon | _BaseGeometry], crs: CRS, bbox_size: float | tuple[float, float], offset: tuple[float, float] | None=None):\n        '''\n        :param shape_list: A list of geometrical shapes describing the area of interest\n        :param crs: Coordinate reference system of the shapes in `shape_list`\n        :param bbox_size: A size of generated bounding boxes in horizontal and vertical directions in meters. If a\n            single value is given that will be interpreted as (value, value).\n        :param offset: Bounding box offset in horizontal and vertical directions in meters.\n        '''\n        pass\n    @abstractmethod\n    def _get_utm_polygons(self) -> list[tuple[BaseGeometry, dict[str, Any]]]:\n        '''Find UTM grid zones overlapping with input area shape.'''\n        pass\n    @staticmethod\n    def _get_utm_from_props(utm_dict: dict[str, Any]) -> CRS:\n        '''Return the UTM CRS corresponding to the UTM described by the properties dictionary\n        :param utm_dict: Dictionary reporting name of the UTM zone and MGRS grid\n        :return: UTM coordinate reference system\n        '''\n        pass\n\n    def _align_bbox_to_size(self, bbox: BBox) -> BBox:\n        '''Align input bbox coordinates to be multiples of the bbox size\n        :param bbox: Bounding box in UTM coordinates\n        :return: BBox objects with coordinates multiples of the bbox size\n        '''\n        pass\n\n    def _make_split(self) -> tuple[list[BBox], list[dict[str, object]]]:\n        '''Split each UTM grid into equally sized bboxes in correct UTM zone'''\n        pass\n\n    def get_bbox_list(self, buffer: None | float | tuple[float, float]=None) -> list[BBox]:\n        '''Get list of bounding boxes.\n        The CRS is fixed to the computed UTM CRS. This BBox splitter does not support reducing size of output\n        bounding boxes\n        :param buffer: A percentage of each BBox size increase. This will cause neighbouring bounding boxes to overlap.\n        :return: List of bounding boxes\n        '''\n        pass\nCorresponding class implementation:\n\nfrom shapely.geometry import GeometryCollection, MultiPolygon, Polygon\nfrom .constants import CRS\nfrom .geometry import BBox, Geometry, _BaseGeometry\nimport math\nfrom typing import Any, ClassVar, Iterable, TypeVar, cast\nfrom shapely.geometry.base import BaseGeometry\nfrom abc import ABCMeta, abstractmethod\n\nclass BaseUtmSplitter(AreaSplitter, metaclass=ABCMeta):\n    \"\"\"Base splitter that returns bboxes of fixed size aligned to UTM zones or UTM grid tiles as defined by the MGRS\n\n    The generated bounding box grid will have coordinates in form of\n    `(N * bbox_size_x + offset_x, M * bbox_size_y + offset_y)`\n    \"\"\"\n\n    def __init__(self, shape_list: Iterable[Polygon | MultiPolygon | _BaseGeometry], crs: CRS, bbox_size: float | tuple[float, float], offset: tuple[float, float] | None=None):\n        \"\"\"\n        :param shape_list: A list of geometrical shapes describing the area of interest\n        :param crs: Coordinate reference system of the shapes in `shape_list`\n        :param bbox_size: A size of generated bounding boxes in horizontal and vertical directions in meters. If a\n            single value is given that will be interpreted as (value, value).\n        :param offset: Bounding box offset in horizontal and vertical directions in meters.\n        \"\"\"\n        self.bbox_size = _parse_to_pair(bbox_size, allowed_types=(int, float), param_name='bbox_size')\n        self.offset = _parse_to_pair(offset or 0.0, allowed_types=(int, float), param_name='offset')\n        self.utm_grid = self._get_utm_polygons()\n        super().__init__(shape_list, crs)\n\n    @abstractmethod\n    def _get_utm_polygons(self) -> list[tuple[BaseGeometry, dict[str, Any]]]:\n        \"\"\"Find UTM grid zones overlapping with input area shape.\"\"\"\n\n    @staticmethod\n    def _get_utm_from_props(utm_dict: dict[str, Any]) -> CRS:\n        \"\"\"Return the UTM CRS corresponding to the UTM described by the properties dictionary\n\n        :param utm_dict: Dictionary reporting name of the UTM zone and MGRS grid\n        :return: UTM coordinate reference system\n        \"\"\"\n        hemisphere_digit = 6 if utm_dict['direction'] == 'N' else 7\n        zone_number = utm_dict['zone']\n        return CRS(f'32{hemisphere_digit}{zone_number:02d}')\n\n    def _align_bbox_to_size(self, bbox: BBox) -> BBox:\n        \"\"\"Align input bbox coordinates to be multiples of the bbox size\n\n        :param bbox: Bounding box in UTM coordinates\n        :return: BBox objects with coordinates multiples of the bbox size\n        \"\"\"\n        size_x, size_y = self.bbox_size\n        offset_x, offset_y = self.offset\n        lower_left_x, lower_left_y = bbox.lower_left\n        aligned_x = math.floor((lower_left_x - offset_x) / size_x) * size_x + offset_x\n        aligned_y = math.floor((lower_left_y - offset_y) / size_y) * size_y + offset_y\n        return BBox(((aligned_x, aligned_y), bbox.upper_right), crs=bbox.crs)\n\n    def _make_split(self) -> tuple[list[BBox], list[dict[str, object]]]:\n        \"\"\"Split each UTM grid into equally sized bboxes in correct UTM zone\"\"\"\n        size_x, size_y = self.bbox_size\n        bbox_list: list[BBox] = []\n        info_list: list[dict[str, object]] = []\n        index = 0\n        shape_geometry = Geometry(self.area_shape, self.crs).transform(CRS.WGS84)\n        for utm_cell in self.utm_grid:\n            utm_cell_geom, utm_cell_prop = utm_cell\n            if utm_cell_prop['zone'] == 0:\n                continue\n            utm_crs = self._get_utm_from_props(utm_cell_prop)\n            cell_info = dict(crs=utm_crs.name, utm_zone=str(utm_cell_prop['zone']).zfill(2), utm_row=utm_cell_prop['row'], direction=utm_cell_prop['direction'])\n            intersection = utm_cell_geom.intersection(shape_geometry.geometry)\n            if not intersection.is_empty and isinstance(intersection, GeometryCollection):\n                intersection = MultiPolygon((geo_object for geo_object in intersection if isinstance(geo_object, (Polygon, MultiPolygon))))\n            if intersection.area > 0:\n                intersection = Geometry(intersection, CRS.WGS84).transform(utm_crs)\n                bbox_partition = self._align_bbox_to_size(intersection.bbox).get_partition(size_x=size_x, size_y=size_y)\n                for i, column in enumerate(bbox_partition):\n                    for j, part in enumerate(column):\n                        if part.geometry.intersects(intersection.geometry):\n                            bbox_list.append(part)\n                            info_list.append(dict(**cell_info, index=index, index_x=i, index_y=j))\n                            index += 1\n        return (bbox_list, info_list)\n\n    def get_bbox_list(self, buffer: None | float | tuple[float, float]=None) -> list[BBox]:\n        \"\"\"Get list of bounding boxes.\n\n        The CRS is fixed to the computed UTM CRS. This BBox splitter does not support reducing size of output\n        bounding boxes\n\n        :param buffer: A percentage of each BBox size increase. This will cause neighbouring bounding boxes to overlap.\n        :return: List of bounding boxes\n        \"\"\"\n        return super().get_bbox_list(buffer=buffer)\n\nNow, implement the following class. Do not explain the code. The given class skeleton is as follows:\n\nclass DRFPUtil:\n    '''\n    A utility class for encoding SMILES as drfp fingerprints.\n        '''\n    @staticmethod\n    def shingling_from_mol(in_mol: Mol, radius: int=3, rings: bool=True, min_radius: int=0, get_atom_indices: bool=False, root_central_atom: bool=True, include_hydrogens: bool=False) -> Union[List[str], Tuple[List[str], Dict[str, List[Set[int]]]]]:\n        '''Creates a molecular shingling from a RDKit molecule (rdkit.Chem.rdchem.Mol).\n        Arguments:\n            in_mol: A RDKit molecule instance\n            radius: The drfp radius (a radius of 3 corresponds to drfp6)\n            rings: Whether or not to include rings in the shingling\n            min_radius: The minimum radius that is used to extract n-grams\n        Returns:\n            The molecular shingling.\n        '''\n        pass\n    @staticmethod\n    def internal_encode(in_smiles: str, radius: int=3, min_radius: int=0, rings: bool=True, get_atom_indices: bool=False, root_central_atom: bool=True, include_hydrogens: bool=False) -> Union[Tuple[np.ndarray, np.ndarray], Tuple[np.ndarray, np.ndarray, Dict[str, List[Dict[str, List[Set[int]]]]]]]:\n        '''Creates an drfp array from a reaction SMILES string.\n        Arguments:\n            in_smiles: A valid reaction SMILES string\n            radius: The drfp radius (a radius of 3 corresponds to drfp6)\n            min_radius: The minimum radius that is used to extract n-grams\n            rings: Whether or not to include rings in the shingling\n        Returns:\n            A tuple with two arrays, the first containing the drfp hash values, the second the substructure SMILES\n        '''\n        pass\n    @staticmethod\n    def hash(shingling: List[str]) -> np.ndarray:\n        '''Directly hash all the SMILES in a shingling to a 32-bit integer.\n        Arguments:\n            shingling: A list of n-grams\n        Returns:\n            A list of hashed n-grams\n        '''\n        pass\n    @staticmethod\n    def fold(hash_values: np.ndarray, length: int=2048) -> Tuple[np.ndarray, np.ndarray]:\n        '''Folds the hash values to a binary vector of a given length.\n        Arguments:\n            hash_value: An array containing the hash values\n            length: The length of the folded fingerprint\n        Returns:\n            A tuple containing the folded fingerprint and the indices of the on bits\n        '''\n        pass\n    @staticmethod\n    def encode(X: Union[Iterable, str], n_folded_length: int=2048, min_radius: int=0, radius: int=3, rings: bool=True, mapping: bool=False, atom_index_mapping: bool=False, root_central_atom: bool=True, include_hydrogens: bool=False, show_progress_bar: bool=False) -> Union[List[np.ndarray], Tuple[List[np.ndarray], Dict[int, Set[str]]], Tuple[List[np.ndarray], Dict[int, Set[str]]], List[Dict[str, List[Dict[str, List[Set[int]]]]]]]:\n        '''Encodes a list of reaction SMILES using the drfp fingerprint.\n        Args:\n            X: An iterable (e.g. List) of reaction SMILES or a single reaction SMILES to be encoded\n            n_folded_length: The folded length of the fingerprint (the parameter for the modulo hashing)\n            min_radius: The minimum radius of a substructure (0 includes single atoms)\n            radius: The maximum radius of a substructure\n            rings: Whether to include full rings as substructures\n            mapping: Return a feature to substructure mapping in addition to the fingerprints\n            atom_index_mapping: Return the atom indices of mapped substructures for each reaction\n            root_central_atom: Whether to root the central atom of substructures when generating SMILES\n            show_progress_bar: Whether to show a progress bar when encoding reactions\n        Returns:\n            A list of drfp fingerprints or, if mapping is enabled, a tuple containing a list of drfp fingerprints and a mapping dict.\n        '''\n        pass"
  }
]