[
  {
    "role": "assistant",
    "content": "You are an expert Python programmer who can correctly implement complete Python classes based on the provided class skeleton."
  },
  {
    "role": "user",
    "content": "For your understanding, following are some (skeleton, code) examples:\n\nExample skeleton:\n\n\nclass MultithreadedJobExecutor(JobExecutor):\n    '''\n    Experimental multi-threaded CWL executor.\n    Does simple resource accounting, will not start a job unless it\n    has cores / ram available, but does not make any attempt to\n    optimize usage.\n    '''\n\n    def __init__(self) -> None:\n        '''Initialize.'''\n        pass\n\n    def select_resources(self, request: dict[str, Union[int, float]], runtime_context: RuntimeContext) -> dict[str, Union[int, float]]:\n        '''Naïve check for available cpu cores and memory.'''\n        pass\n\n    def _runner(self, job: Union[JobBase, WorkflowJob, CallbackJob, ExpressionJob], runtime_context: RuntimeContext, TMPDIR_LOCK: threading.Lock) -> None:\n        '''Job running thread.'''\n        pass\n\n    def run_job(self, job: Optional[JobsType], runtime_context: RuntimeContext) -> None:\n        '''Execute a single Job in a separate thread.'''\n        pass\n\n    def wait_for_next_completion(self, runtime_context: RuntimeContext) -> None:\n        '''Wait for jobs to finish.'''\n        pass\n\n    def run_jobs(self, process: Process, job_order_object: CWLObjectType, logger: logging.Logger, runtime_context: RuntimeContext) -> None:\n        pass\nCorresponding class implementation:\n\nfrom .task_queue import TaskQueue\nimport logging\nfrom .errors import WorkflowException\nfrom .context import RuntimeContext, getdefault\nfrom .loghandler import _logger\nimport threading\nfrom .command_line_tool import CallbackJob, ExpressionJob\nfrom .process import Process, cleanIntermediate, relocateOutputs\nfrom .workflow_job import WorkflowJob, WorkflowJobStep\nimport math\nfrom typing import Optional, Union, cast\nfrom .job import JobBase\nimport psutil\nfrom .cuda import cuda_version_and_device_count\nfrom .utils import CWLObjectType, JobsType\nimport functools\n\nclass MultithreadedJobExecutor(JobExecutor):\n    \"\"\"\n    Experimental multi-threaded CWL executor.\n\n    Does simple resource accounting, will not start a job unless it\n    has cores / ram available, but does not make any attempt to\n    optimize usage.\n    \"\"\"\n\n    def __init__(self) -> None:\n        \"\"\"Initialize.\"\"\"\n        super().__init__()\n        self.exceptions: list[WorkflowException] = []\n        self.pending_jobs: list[JobsType] = []\n        self.pending_jobs_lock = threading.Lock()\n        self.max_ram = int(psutil.virtual_memory().available / 2 ** 20)\n        self.max_cores = float(psutil.cpu_count() or 1)\n        self.max_cuda = cuda_version_and_device_count()[1]\n        self.allocated_ram = float(0)\n        self.allocated_cores = float(0)\n        self.allocated_cuda: int = 0\n\n    def select_resources(self, request: dict[str, Union[int, float]], runtime_context: RuntimeContext) -> dict[str, Union[int, float]]:\n        \"\"\"Naïve check for available cpu cores and memory.\"\"\"\n        result: dict[str, Union[int, float]] = {}\n        maxrsc = {'cores': self.max_cores, 'ram': self.max_ram}\n        resources_types = {'cores', 'ram'}\n        if 'cudaDeviceCountMin' in request or 'cudaDeviceCountMax' in request:\n            maxrsc['cudaDeviceCount'] = self.max_cuda\n            resources_types.add('cudaDeviceCount')\n        for rsc in resources_types:\n            rsc_min = request[rsc + 'Min']\n            if rsc_min > maxrsc[rsc]:\n                raise WorkflowException(f'Requested at least {rsc_min} {rsc} but only {maxrsc[rsc]} available')\n            rsc_max = request[rsc + 'Max']\n            if rsc_max < maxrsc[rsc]:\n                result[rsc] = math.ceil(rsc_max)\n            else:\n                result[rsc] = maxrsc[rsc]\n        result['tmpdirSize'] = math.ceil(request['tmpdirMin'])\n        result['outdirSize'] = math.ceil(request['outdirMin'])\n        return result\n\n    def _runner(self, job: Union[JobBase, WorkflowJob, CallbackJob, ExpressionJob], runtime_context: RuntimeContext, TMPDIR_LOCK: threading.Lock) -> None:\n        \"\"\"Job running thread.\"\"\"\n        try:\n            _logger.debug('job: {}, runtime_context: {}, TMPDIR_LOCK: {}'.format(job, runtime_context, TMPDIR_LOCK))\n            job.run(runtime_context, TMPDIR_LOCK)\n        except WorkflowException as err:\n            _logger.exception(f'Got workflow error: {err}')\n            self.exceptions.append(err)\n        except Exception as err:\n            _logger.exception(f'Got workflow error: {err}')\n            wf_exc = WorkflowException(str(err))\n            wf_exc.__cause__ = err\n            wf_exc.__suppress_context__ = True\n            self.exceptions.append(wf_exc)\n        finally:\n            if runtime_context.workflow_eval_lock:\n                with runtime_context.workflow_eval_lock:\n                    if isinstance(job, JobBase):\n                        ram = job.builder.resources['ram']\n                        self.allocated_ram -= ram\n                        cores = job.builder.resources['cores']\n                        self.allocated_cores -= cores\n                        cudaDevices: int = cast(int, job.builder.resources.get('cudaDeviceCount', 0))\n                        self.allocated_cuda -= cudaDevices\n                    runtime_context.workflow_eval_lock.notify_all()\n\n    def run_job(self, job: Optional[JobsType], runtime_context: RuntimeContext) -> None:\n        \"\"\"Execute a single Job in a separate thread.\"\"\"\n        if job is not None:\n            with self.pending_jobs_lock:\n                self.pending_jobs.append(job)\n        with self.pending_jobs_lock:\n            n = 0\n            while n + 1 <= len(self.pending_jobs):\n                job = self.pending_jobs[n]\n                if isinstance(job, JobBase):\n                    ram = job.builder.resources['ram']\n                    cores = job.builder.resources['cores']\n                    cudaDevices = cast(int, job.builder.resources.get('cudaDeviceCount', 0))\n                    if ram > self.max_ram or cores > self.max_cores or cudaDevices > self.max_cuda:\n                        _logger.error('Job \"%s\" cannot be run, requests more resources (%s) than available on this host (already allocated ram is %d, allocated cores is %d, allocated CUDA is %d, max ram %d, max cores %d, max CUDA %d).', job.name, job.builder.resources, self.allocated_ram, self.allocated_cores, self.allocated_cuda, self.max_ram, self.max_cores, self.max_cuda)\n                        self.pending_jobs.remove(job)\n                        return\n                    if self.allocated_ram + ram > self.max_ram or self.allocated_cores + cores > self.max_cores or self.allocated_cuda + cudaDevices > self.max_cuda:\n                        _logger.debug('Job \"%s\" cannot run yet, resources (%s) are not available (already allocated ram is %d, allocated cores is %d, allocated CUDA devices is %d, max ram %d, max cores %d, max CUDA %d).', job.name, job.builder.resources, self.allocated_ram, self.allocated_cores, self.allocated_cuda, self.max_ram, self.max_cores, self.max_cuda)\n                        n += 1\n                        continue\n                if isinstance(job, JobBase):\n                    ram = job.builder.resources['ram']\n                    self.allocated_ram += ram\n                    cores = job.builder.resources['cores']\n                    self.allocated_cores += cores\n                    cuda = cast(int, job.builder.resources.get('cudaDevices', 0))\n                    self.allocated_cuda += cuda\n                self.taskqueue.add(functools.partial(self._runner, job, runtime_context, TMPDIR_LOCK), runtime_context.workflow_eval_lock)\n                self.pending_jobs.remove(job)\n\n    def wait_for_next_completion(self, runtime_context: RuntimeContext) -> None:\n        \"\"\"Wait for jobs to finish.\"\"\"\n        if runtime_context.workflow_eval_lock is not None:\n            runtime_context.workflow_eval_lock.wait(timeout=3)\n        if self.exceptions:\n            raise self.exceptions[0]\n\n    def run_jobs(self, process: Process, job_order_object: CWLObjectType, logger: logging.Logger, runtime_context: RuntimeContext) -> None:\n        self.taskqueue: TaskQueue = TaskQueue(threading.Lock(), int(math.ceil(self.max_cores)))\n        try:\n            jobiter = process.job(job_order_object, self.output_callback, runtime_context)\n            if runtime_context.workflow_eval_lock is None:\n                raise WorkflowException('runtimeContext.workflow_eval_lock must not be None')\n            runtime_context.workflow_eval_lock.acquire()\n            for job in jobiter:\n                if job is not None:\n                    if isinstance(job, JobBase):\n                        job.builder = runtime_context.builder or job.builder\n                        if job.outdir is not None:\n                            self.output_dirs.add(job.outdir)\n                self.run_job(job, runtime_context)\n                if job is None:\n                    if self.taskqueue.in_flight > 0:\n                        self.wait_for_next_completion(runtime_context)\n                    else:\n                        logger.error('Workflow cannot make any more progress.')\n                        break\n            self.run_job(None, runtime_context)\n            while self.taskqueue.in_flight > 0:\n                self.wait_for_next_completion(runtime_context)\n                self.run_job(None, runtime_context)\n            runtime_context.workflow_eval_lock.release()\n        finally:\n            self.taskqueue.drain()\n            self.taskqueue.join()\n\nExample skeleton:\n\n\nclass MapItem:\n\n    def __init__(self, buff: bytes, cm: ClassManager) -> None:\n        '''\n        Implementation of a map_item, which occours in a map_list\n        https://source.android.com/devices/tech/dalvik/dex-format#map-item\n        '''\n        pass\n\n    def get_off(self) -> int:\n        '''Gets the offset of the map item itself inside the DEX file'''\n        pass\n\n    def get_offset(self) -> int:\n        '''Gets the offset of the item of the map item'''\n        pass\n\n    def get_type(self) -> TypeMapItem:\n        pass\n\n    def get_size(self) -> int:\n        '''\n        Returns the number of items found at the location indicated by\n        [get_offset][androguard.core.dex.MapItem.get_offset].\n        :returns: number of items\n        '''\n        pass\n\n    def parse(self) -> None:\n        '''parse this map_item by parsing its potential [TypeMapItem][androguard.core.dex.dex_types.TypeMapItem] type and cast it appropriately.'''\n        pass\n\n    def show(self) -> None:\n        pass\n\n    def get_obj(self) -> object:\n        '''\n        Return the associated item itself.\n        Might return `None`, if [parse][androguard.core.dex.MapItem.parse] was not called yet.\n        This method is the same as `item`.\n        :returns: item object\n        '''\n        pass\n\n    def get_raw(self) -> bytes:\n        pass\n\n    def get_length(self) -> int:\n        pass\n\n    def set_item(self, item: object) -> None:\n        pass\nCorresponding class implementation:\n\nimport time\nfrom androguard.core import apk, bytecode, mutf8\nfrom struct import calcsize, pack, unpack\nfrom loguru import logger\nfrom .dex_types import ACCESS_FLAGS, TYPE_DESCRIPTOR, Kind, Operand, TypeMapItem\n\nclass MapItem:\n\n    def __init__(self, buff: bytes, cm: ClassManager) -> None:\n        \"\"\"\n        Implementation of a map_item, which occours in a map_list\n\n        https://source.android.com/devices/tech/dalvik/dex-format#map-item\n        \"\"\"\n        self.CM = cm\n        self.buff = buff\n        self.off = buff.tell()\n        self.type = TypeMapItem(cm.packer['H'].unpack(buff.read(2))[0])\n        self.unused, self.size, self.offset = cm.packer['H2I'].unpack(buff.read(10))\n        self.item = None\n\n    def get_off(self) -> int:\n        \"\"\"Gets the offset of the map item itself inside the DEX file\"\"\"\n        return self.off\n\n    def get_offset(self) -> int:\n        \"\"\"Gets the offset of the item of the map item\"\"\"\n        return self.offset\n\n    def get_type(self) -> TypeMapItem:\n        return self.type\n\n    def get_size(self) -> int:\n        \"\"\"\n        Returns the number of items found at the location indicated by\n        [get_offset][androguard.core.dex.MapItem.get_offset].\n\n        :returns: number of items\n        \"\"\"\n        return self.size\n\n    def parse(self) -> None:\n        \"\"\"parse this map_item by parsing its potential [TypeMapItem][androguard.core.dex.dex_types.TypeMapItem] type and cast it appropriately.\"\"\"\n        logger.debug(\"Starting parsing map_item '{}'\".format(self.type.name))\n        started_at = time.time()\n        buff = self.buff\n        cm = self.CM\n        if TypeMapItem.STRING_ID_ITEM == self.type:\n            buff.seek(self.offset)\n            self.item = [StringIdItem(buff, cm) for _ in range(self.size)]\n        elif TypeMapItem.CODE_ITEM == self.type:\n            buff.seek(self.offset + self.offset % 4)\n            self.item = CodeItem(self.size, buff, cm)\n        elif TypeMapItem.TYPE_ID_ITEM == self.type:\n            buff.seek(self.offset + self.offset % 4)\n            self.item = TypeHIdItem(self.size, buff, cm)\n        elif TypeMapItem.PROTO_ID_ITEM == self.type:\n            buff.seek(self.offset + self.offset % 4)\n            self.item = ProtoHIdItem(self.size, buff, cm)\n        elif TypeMapItem.FIELD_ID_ITEM == self.type:\n            buff.seek(self.offset + self.offset % 4)\n            self.item = FieldHIdItem(self.size, buff, cm)\n        elif TypeMapItem.METHOD_ID_ITEM == self.type:\n            buff.seek(self.offset + self.offset % 4)\n            self.item = MethodHIdItem(self.size, buff, cm)\n        elif TypeMapItem.CLASS_DEF_ITEM == self.type:\n            buff.seek(self.offset + self.offset % 4)\n            self.item = ClassHDefItem(self.size, buff, cm)\n        elif TypeMapItem.HEADER_ITEM == self.type:\n            buff.seek(self.offset + self.offset % 4)\n            self.item = HeaderItem(self.size, buff, cm)\n        elif TypeMapItem.ANNOTATION_ITEM == self.type:\n            buff.seek(self.offset)\n            self.item = [AnnotationItem(buff, cm) for _ in range(self.size)]\n        elif TypeMapItem.ANNOTATION_SET_ITEM == self.type:\n            buff.seek(self.offset + self.offset % 4)\n            self.item = [AnnotationSetItem(buff, cm) for _ in range(self.size)]\n        elif TypeMapItem.ANNOTATIONS_DIRECTORY_ITEM == self.type:\n            buff.seek(self.offset + self.offset % 4)\n            self.item = [AnnotationsDirectoryItem(buff, cm) for _ in range(self.size)]\n        elif TypeMapItem.HIDDENAPI_CLASS_DATA_ITEM == self.type:\n            buff.seek(self.offset)\n            self.item = HiddenApiClassDataItem(buff, cm)\n        elif TypeMapItem.ANNOTATION_SET_REF_LIST == self.type:\n            buff.seek(self.offset + self.offset % 4)\n            self.item = [AnnotationSetRefList(buff, cm) for _ in range(self.size)]\n        elif TypeMapItem.TYPE_LIST == self.type:\n            buff.seek(self.offset + self.offset % 4)\n            self.item = [TypeList(buff, cm) for _ in range(self.size)]\n        elif TypeMapItem.STRING_DATA_ITEM == self.type:\n            buff.seek(self.offset)\n            self.item = [StringDataItem(buff, cm) for _ in range(self.size)]\n        elif TypeMapItem.DEBUG_INFO_ITEM == self.type:\n            buff.seek(self.offset)\n            self.item = DebugInfoItemEmpty(buff, cm)\n        elif TypeMapItem.ENCODED_ARRAY_ITEM == self.type:\n            buff.seek(self.offset)\n            self.item = [EncodedArrayItem(buff, cm) for _ in range(self.size)]\n        elif TypeMapItem.CLASS_DATA_ITEM == self.type:\n            buff.seek(self.offset)\n            self.item = [ClassDataItem(buff, cm) for _ in range(self.size)]\n        elif TypeMapItem.MAP_LIST == self.type:\n            buff.seek(self.offset + self.offset % 4)\n            pass\n        else:\n            logger.warning(\"Map item with id '{type}' offset: 0x{off:x} ({off}) size: {size} is unknown. Is this a newer DEX format?\".format(type=self.type, off=buff.tell(), size=self.size))\n        diff = time.time() - started_at\n        minutes, seconds = (diff // 60, diff % 60)\n        logger.debug(\"End of parsing map_item '{}'. Required time {:.0f}:{:07.4f}\".format(self.type.name, minutes, seconds))\n\n    def show(self) -> None:\n        bytecode._Print('\\tMAP_TYPE_ITEM', self.type.name)\n        if self.item is not None:\n            if isinstance(self.item, list):\n                for i in self.item:\n                    i.show()\n            else:\n                self.item.show()\n\n    def get_obj(self) -> object:\n        \"\"\"\n        Return the associated item itself.\n        Might return `None`, if [parse][androguard.core.dex.MapItem.parse] was not called yet.\n\n        This method is the same as `item`.\n\n        :returns: item object\n        \"\"\"\n        return self.item\n    get_item = get_obj\n\n    def get_raw(self) -> bytes:\n        if isinstance(self.item, list):\n            self.offset = self.item[0].get_off()\n        else:\n            self.offset = self.item.get_off()\n        return self.CM.packer['2H2I'].pack(self.type, self.unused, self.size, self.offset)\n\n    def get_length(self) -> int:\n        return calcsize('HHII')\n\n    def set_item(self, item: object) -> None:\n        self.item = item\n\nNow, implement the following class. Do not explain the code. The given class skeleton is as follows:\n\nclass BoundedASTCache:\n    '''Memory-aware AST cache with automatic cleanup to prevent memory leaks.\n    Uses LRU eviction strategy and monitors memory usage to maintain\n    reasonable memory consumption during long-running analysis sessions.\n    '''\n\n    def __init__(self, max_entries: int=1000, max_memory_mb: int=500):\n        '''Initialize the bounded AST cache.\n        Args:\n            max_entries: Maximum number of AST entries to cache\n            max_memory_mb: Soft memory limit in MB for cache eviction\n        '''\n        pass\n\n    def __setitem__(self, key: Path, value: tuple[Node, str]) -> None:\n        '''Add or update an AST cache entry with automatic cleanup.'''\n        pass\n\n    def __getitem__(self, key: Path) -> tuple[Node, str]:\n        '''Get AST cache entry and mark as recently used.'''\n        pass\n\n    def __delitem__(self, key: Path) -> None:\n        '''Remove entry from cache.'''\n        pass\n\n    def __contains__(self, key: Path) -> bool:\n        '''Check if key exists in cache.'''\n        pass\n\n    def items(self) -> Any:\n        '''Return all cache items.'''\n        pass\n\n    def _enforce_limits(self) -> None:\n        '''Enforce cache size and memory limits by evicting old entries.'''\n        pass\n\n    def _should_evict_for_memory(self) -> bool:\n        '''Check if we should evict entries due to memory pressure.'''\n        pass"
  }
]