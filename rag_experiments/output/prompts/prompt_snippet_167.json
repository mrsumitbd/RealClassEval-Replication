[
  {
    "role": "assistant",
    "content": "You are an expert Python programmer who can correctly implement complete Python classes based on the provided class skeleton."
  },
  {
    "role": "user",
    "content": "For your understanding, following are some (skeleton, code) examples:\n\nExample skeleton:\n\n\nclass JumpStartMetadataBaseFields(JumpStartDataHolderType):\n    '''Data class JumpStart metadata base fields that can be overridden.'''\n\n    def __init__(self, fields: Dict[str, Any], is_hub_content: Optional[bool]=False):\n        '''Initializes a JumpStartMetadataFields object.\n        Args:\n            fields (Dict[str, Any]): Dictionary representation of metadata fields.\n        '''\n        pass\n\n    def from_json(self, json_obj: Dict[str, Any]) -> None:\n        '''Sets fields in object based on json of header.\n        Args:\n            json_obj (Dict[str, Any]): Dictionary representation of spec.\n        '''\n        pass\n\n    def to_json(self) -> Dict[str, Any]:\n        '''Returns json representation of JumpStartMetadataBaseFields object.'''\n        pass\n\n    def set_hub_content_type(self, hub_content_type: HubContentType) -> None:\n        '''Sets the hub content type.'''\n        pass\nCorresponding class implementation:\n\nfrom typing import Any, Callable, Dict, List, Optional, Set, Union\nfrom copy import deepcopy\nfrom sagemaker.jumpstart.hub.parser_utils import camel_to_snake, walk_and_apply_json\n\nclass JumpStartMetadataBaseFields(JumpStartDataHolderType):\n    \"\"\"Data class JumpStart metadata base fields that can be overridden.\"\"\"\n    __slots__ = ['model_id', 'url', 'version', 'min_sdk_version', 'model_types', 'capabilities', 'incremental_training_supported', 'hosting_ecr_specs', 'hosting_ecr_uri', 'hosting_artifact_uri', 'hosting_artifact_key', 'hosting_script_key', 'training_supported', 'training_ecr_specs', 'training_ecr_uri', 'training_artifact_key', 'training_script_key', 'hyperparameters', 'inference_environment_variables', 'inference_vulnerable', 'inference_dependencies', 'inference_vulnerabilities', 'training_vulnerable', 'training_dependencies', 'training_vulnerabilities', 'deprecated', 'usage_info_message', 'deprecated_message', 'deprecate_warn_message', 'default_inference_instance_type', 'supported_inference_instance_types', 'dynamic_container_deployment_supported', 'hosting_resource_requirements', 'default_training_instance_type', 'supported_training_instance_types', 'metrics', 'training_prepacked_script_key', 'training_prepacked_script_version', 'hosting_prepacked_artifact_key', 'hosting_prepacked_artifact_version', 'model_kwargs', 'deploy_kwargs', 'estimator_kwargs', 'fit_kwargs', 'predictor_specs', 'inference_volume_size', 'training_volume_size', 'inference_enable_network_isolation', 'training_enable_network_isolation', 'resource_name_base', 'hosting_eula_key', 'hosting_model_package_arns', 'training_model_package_artifact_uris', 'hosting_use_script_uri', 'hosting_instance_type_variants', 'training_instance_type_variants', 'default_payloads', 'gated_bucket', 'model_subscription_link', 'hosting_additional_data_sources', 'hosting_neuron_model_id', 'hosting_neuron_model_version', 'hub_content_type', '_is_hub_content', 'default_training_dataset_key', 'default_training_dataset_uri']\n    _non_serializable_slots = ['_is_hub_content']\n\n    def __init__(self, fields: Dict[str, Any], is_hub_content: Optional[bool]=False):\n        \"\"\"Initializes a JumpStartMetadataFields object.\n\n        Args:\n            fields (Dict[str, Any]): Dictionary representation of metadata fields.\n        \"\"\"\n        self._is_hub_content = is_hub_content\n        self.from_json(fields)\n\n    def from_json(self, json_obj: Dict[str, Any]) -> None:\n        \"\"\"Sets fields in object based on json of header.\n\n        Args:\n            json_obj (Dict[str, Any]): Dictionary representation of spec.\n        \"\"\"\n        if self._is_hub_content:\n            json_obj = walk_and_apply_json(json_obj, camel_to_snake)\n        self.model_id: str = json_obj.get('model_id')\n        self.url: str = json_obj.get('url')\n        self.version: str = json_obj.get('version')\n        self.min_sdk_version: str = json_obj.get('min_sdk_version')\n        self.incremental_training_supported: bool = bool(json_obj.get('incremental_training_supported', False))\n        if self._is_hub_content:\n            self.capabilities: Optional[List[str]] = json_obj.get('capabilities')\n            self.model_types: Optional[List[str]] = json_obj.get('model_types')\n            self.hosting_ecr_uri: Optional[str] = json_obj.get('hosting_ecr_uri')\n            self._non_serializable_slots.append('hosting_ecr_specs')\n        else:\n            self.hosting_ecr_specs: Optional[JumpStartECRSpecs] = JumpStartECRSpecs(json_obj['hosting_ecr_specs'], is_hub_content=self._is_hub_content) if 'hosting_ecr_specs' in json_obj else None\n            self._non_serializable_slots.append('hosting_ecr_uri')\n        self.hosting_artifact_key: Optional[str] = json_obj.get('hosting_artifact_key')\n        self.hosting_artifact_uri: Optional[str] = json_obj.get('hosting_artifact_uri')\n        self.hosting_script_key: Optional[str] = json_obj.get('hosting_script_key')\n        self.training_supported: Optional[bool] = bool(json_obj.get('training_supported', False))\n        self.inference_environment_variables = [JumpStartEnvironmentVariable(env_variable, is_hub_content=self._is_hub_content) for env_variable in json_obj.get('inference_environment_variables', [])]\n        self.inference_vulnerable: bool = bool(json_obj.get('inference_vulnerable', False))\n        self.inference_dependencies: List[str] = json_obj.get('inference_dependencies', [])\n        self.inference_vulnerabilities: List[str] = json_obj.get('inference_vulnerabilities', [])\n        self.training_vulnerable: bool = bool(json_obj.get('training_vulnerable', False))\n        self.training_dependencies: List[str] = json_obj.get('training_dependencies', [])\n        self.training_vulnerabilities: List[str] = json_obj.get('training_vulnerabilities', [])\n        self.deprecated: bool = bool(json_obj.get('deprecated', False))\n        self.deprecated_message: Optional[str] = json_obj.get('deprecated_message')\n        self.deprecate_warn_message: Optional[str] = json_obj.get('deprecate_warn_message')\n        self.usage_info_message: Optional[str] = json_obj.get('usage_info_message')\n        self.default_inference_instance_type: Optional[str] = json_obj.get('default_inference_instance_type')\n        self.default_training_instance_type: Optional[str] = json_obj.get('default_training_instance_type')\n        self.supported_inference_instance_types: Optional[List[str]] = json_obj.get('supported_inference_instance_types')\n        self.supported_training_instance_types: Optional[List[str]] = json_obj.get('supported_training_instance_types')\n        self.dynamic_container_deployment_supported: Optional[bool] = bool(json_obj.get('dynamic_container_deployment_supported'))\n        self.hosting_resource_requirements: Optional[Dict[str, int]] = json_obj.get('hosting_resource_requirements', None)\n        self.metrics: Optional[List[Dict[str, str]]] = json_obj.get('metrics', None)\n        self.training_prepacked_script_key: Optional[str] = json_obj.get('training_prepacked_script_key', None)\n        self.hosting_prepacked_artifact_key: Optional[str] = json_obj.get('hosting_prepacked_artifact_key', None)\n        if self._is_hub_content:\n            self.training_prepacked_script_version: Optional[str] = json_obj.get('training_prepacked_script_version')\n            self.hosting_prepacked_artifact_version: Optional[str] = json_obj.get('hosting_prepacked_artifact_version')\n        self.model_kwargs = deepcopy(json_obj.get('model_kwargs', {}))\n        self.deploy_kwargs = deepcopy(json_obj.get('deploy_kwargs', {}))\n        self.predictor_specs: Optional[JumpStartPredictorSpecs] = JumpStartPredictorSpecs(json_obj.get('predictor_specs'), is_hub_content=self._is_hub_content) if json_obj.get('predictor_specs') else None\n        self.default_payloads: Optional[Dict[str, JumpStartSerializablePayload]] = {alias: JumpStartSerializablePayload(payload, is_hub_content=self._is_hub_content) for alias, payload in json_obj['default_payloads'].items()} if json_obj.get('default_payloads') else None\n        self.gated_bucket = json_obj.get('gated_bucket', False)\n        self.inference_volume_size: Optional[int] = json_obj.get('inference_volume_size')\n        self.inference_enable_network_isolation: bool = json_obj.get('inference_enable_network_isolation', False)\n        self.resource_name_base: bool = json_obj.get('resource_name_base')\n        self.hosting_eula_key: Optional[str] = json_obj.get('hosting_eula_key')\n        model_package_arns = json_obj.get('hosting_model_package_arns')\n        self.hosting_model_package_arns: Optional[Dict] = model_package_arns if model_package_arns is not None else {}\n        self.hosting_use_script_uri: bool = json_obj.get('hosting_use_script_uri', True)\n        self.hosting_instance_type_variants: Optional[JumpStartInstanceTypeVariants] = JumpStartInstanceTypeVariants(json_obj['hosting_instance_type_variants'], self._is_hub_content) if json_obj.get('hosting_instance_type_variants') else None\n        self.hosting_additional_data_sources: Optional[JumpStartAdditionalDataSources] = JumpStartAdditionalDataSources(json_obj['hosting_additional_data_sources']) if json_obj.get('hosting_additional_data_sources') else None\n        self.hosting_neuron_model_id: Optional[str] = json_obj.get('hosting_neuron_model_id')\n        self.hosting_neuron_model_version: Optional[str] = json_obj.get('hosting_neuron_model_version')\n        if self.training_supported:\n            if self._is_hub_content:\n                self.training_ecr_uri: Optional[str] = json_obj.get('training_ecr_uri')\n                self._non_serializable_slots.append('training_ecr_specs')\n            else:\n                self.training_ecr_specs: Optional[JumpStartECRSpecs] = JumpStartECRSpecs(json_obj['training_ecr_specs']) if 'training_ecr_specs' in json_obj else None\n                self._non_serializable_slots.append('training_ecr_uri')\n            self.training_artifact_key: str = json_obj['training_artifact_key']\n            self.training_script_key: str = json_obj['training_script_key']\n            hyperparameters: Any = json_obj.get('hyperparameters')\n            self.hyperparameters: List[JumpStartHyperparameter] = []\n            if hyperparameters is not None:\n                self.hyperparameters.extend([JumpStartHyperparameter(hyperparameter, is_hub_content=self._is_hub_content) for hyperparameter in hyperparameters])\n            self.estimator_kwargs = deepcopy(json_obj.get('estimator_kwargs', {}))\n            self.fit_kwargs = deepcopy(json_obj.get('fit_kwargs', {}))\n            self.training_volume_size: Optional[int] = json_obj.get('training_volume_size')\n            self.training_enable_network_isolation: bool = json_obj.get('training_enable_network_isolation', False)\n            self.training_model_package_artifact_uris: Optional[Dict] = json_obj.get('training_model_package_artifact_uris')\n            self.training_instance_type_variants: Optional[JumpStartInstanceTypeVariants] = JumpStartInstanceTypeVariants(json_obj['training_instance_type_variants'], is_hub_content=self._is_hub_content) if json_obj.get('training_instance_type_variants') else None\n        self.model_subscription_link = json_obj.get('model_subscription_link')\n        self.default_training_dataset_key: Optional[str] = json_obj.get('default_training_dataset_key')\n        self.default_training_dataset_uri: Optional[str] = json_obj.get('default_training_dataset_uri')\n\n    def to_json(self) -> Dict[str, Any]:\n        \"\"\"Returns json representation of JumpStartMetadataBaseFields object.\"\"\"\n        json_obj = {}\n        for att in self.__slots__:\n            if hasattr(self, att) and att not in getattr(self, '_non_serializable_slots', []):\n                cur_val = getattr(self, att)\n                if issubclass(type(cur_val), JumpStartDataHolderType):\n                    json_obj[att] = cur_val.to_json()\n                elif isinstance(cur_val, list):\n                    json_obj[att] = []\n                    for obj in cur_val:\n                        if issubclass(type(obj), JumpStartDataHolderType):\n                            json_obj[att].append(obj.to_json())\n                        else:\n                            json_obj[att].append(obj)\n                elif isinstance(cur_val, dict):\n                    json_obj[att] = {}\n                    for key, val in cur_val.items():\n                        if issubclass(type(val), JumpStartDataHolderType):\n                            json_obj[att][key] = val.to_json()\n                        else:\n                            json_obj[att][key] = val\n                else:\n                    json_obj[att] = cur_val\n        return json_obj\n\n    def set_hub_content_type(self, hub_content_type: HubContentType) -> None:\n        \"\"\"Sets the hub content type.\"\"\"\n        if self._is_hub_content:\n            self.hub_content_type = hub_content_type\n\nExample skeleton:\n\n\nclass Step:\n    '''State machine for executing generic actions related to stacks.\n    Attributes:\n        fn: Function to run to execute the step.\n            This function will be ran multiple times until the step is \"done\".\n        last_updated: Time when the step was last updated.\n        logger: Logger for logging messages about the step.\n        stack: the stack associated with this step\n        status: The status of step.\n        watch_func: Function that will be called to \"tail\" the step action.\n    '''\n\n    def __init__(self, stack: Stack, *, fn: Callable[..., Any] | None=None, watch_func: Callable[..., Any] | None=None) -> None:\n        '''Instantiate class.\n        Args:\n            stack: The stack associated\n                with this step\n            fn: Function to run to execute the step.\n                This function will be ran multiple times until the step is \"done\".\n            watch_func: Function that will be called to \"tail\" the step action.\n        '''\n        pass\n\n    def run(self) -> bool:\n        '''Run this step until it has completed or been skipped.'''\n        pass\n\n    def _run_once(self) -> Status:\n        '''Run a step exactly once.'''\n        pass\n    @property\n    def name(self) -> str:\n        '''Name of the step.\n        This is equal to the name of the stack it operates on.\n        '''\n        pass\n    @property\n    def requires(self) -> set[str]:\n        '''Return a list of step names this step depends on.'''\n        pass\n    @property\n    def required_by(self) -> set[str]:\n        '''Return a list of step names that depend on this step.'''\n        pass\n    @property\n    def completed(self) -> bool:\n        '''Return True if the step is in a COMPLETE state.'''\n        pass\n    @property\n    def skipped(self) -> bool:\n        '''Return True if the step is in a SKIPPED state.'''\n        pass\n    @property\n    def failed(self) -> bool:\n        '''Return True if the step is in a FAILED state.'''\n        pass\n    @property\n    def done(self) -> bool:\n        '''Return True if the step is finished.\n        To be ``True``, status must be either COMPLETE, SKIPPED or FAILED)\n        '''\n        pass\n    @property\n    def ok(self) -> bool:\n        '''Return True if the step is finished (either COMPLETE or SKIPPED).'''\n        pass\n    @property\n    def submitted(self) -> bool:\n        '''Return True if the step is SUBMITTED, COMPLETE, or SKIPPED.'''\n        pass\n\n    def set_status(self, status: Status) -> None:\n        '''Set the current step's status.\n        Args:\n            status: The status to set the step to.\n        '''\n        pass\n    def completed(self) -> bool:\n        '''Shortcut for ``set_status(COMPLETE)``.'''\n        pass\n\n    def log_step(self) -> None:\n        '''Construct a log message for a set and log it to the UI.'''\n        pass\n    def skipped(self) -> bool:\n        '''Shortcut for ``set_status(SKIPPED)``.'''\n        pass\n    def submitted(self) -> bool:\n        '''Shortcut for ``set_status(SUBMITTED)``.'''\n        pass\n    @classmethod\n    def from_stack_name(cls, stack_name: str, context: CfnginContext, requires: list[str] | set[str] | None=None, fn: Callable[..., Status] | None=None, watch_func: Callable[..., Any] | None=None) -> Step:\n        '''Create a step using only a stack name.\n        Args:\n            stack_name: Name of a CloudFormation stack.\n            context: Context object. Required to initialize a \"fake\"\n                :class:`runway.cfngin.stack.Stack`.\n            requires: Stacks that this stack depends on.\n            fn: The function to run to execute the step.\n                This function will be ran multiple times until the step is \"done\".\n            watch_func: an optional function that will be called to \"tail\" the\n                step action.\n        '''\n        pass\n    @classmethod\n    def from_persistent_graph(cls, graph_dict: dict[str, list[str]] | dict[str, set[str]] | OrderedDict[str, set[str]], context: CfnginContext, fn: Callable[..., Status] | None=None, watch_func: Callable[..., Any] | None=None) -> list[Step]:\n        '''Create a steps for a persistent graph dict.\n        Args:\n            graph_dict: A graph dict.\n            context: Context object. Required to initialize a \"fake\"\n                :class:`runway.cfngin.stack.Stack`.\n            requires: Stacks that this stack depends on.\n            fn: The function to run to execute the step.\n                This function will be ran multiple times until the step is \"done\".\n            watch_func: an optional function that will be called to \"tail\" the\n                step action.\n        '''\n        pass\n\n    def __repr__(self) -> str:\n        '''Object represented as a string.'''\n        pass\n\n    def __str__(self) -> str:\n        '''Object displayed as a string.'''\n        pass\nCorresponding class implementation:\n\nfrom .status import COMPLETE, FAILED, PENDING, SKIPPED, SUBMITTED, FailedStatus, SkippedStatus\nimport time\nfrom .ui import ui\nfrom .._logging import LogLevels, PrefixAdaptor\nimport threading\nfrom .exceptions import CancelExecution, GraphError, PersistentGraphLocked, PlanFailed\nfrom .stack import Stack\nfrom typing import TYPE_CHECKING, Any, Callable, NoReturn, TypeVar, overload\n\nclass Step:\n    \"\"\"State machine for executing generic actions related to stacks.\n\n    Attributes:\n        fn: Function to run to execute the step.\n            This function will be ran multiple times until the step is \"done\".\n        last_updated: Time when the step was last updated.\n        logger: Logger for logging messages about the step.\n        stack: the stack associated with this step\n        status: The status of step.\n        watch_func: Function that will be called to \"tail\" the step action.\n\n    \"\"\"\n    fn: Callable[..., Any] | None\n    last_updated: float\n    logger: PrefixAdaptor\n    stack: Stack\n    status: Status\n    watch_func: Callable[..., Any] | None\n\n    def __init__(self, stack: Stack, *, fn: Callable[..., Any] | None=None, watch_func: Callable[..., Any] | None=None) -> None:\n        \"\"\"Instantiate class.\n\n        Args:\n            stack: The stack associated\n                with this step\n            fn: Function to run to execute the step.\n                This function will be ran multiple times until the step is \"done\".\n            watch_func: Function that will be called to \"tail\" the step action.\n\n        \"\"\"\n        self.stack = stack\n        self.status = PENDING\n        self.last_updated = time.time()\n        self.logger = PrefixAdaptor(self.stack.name, LOGGER)\n        self.fn = fn\n        self.watch_func = watch_func\n\n    def run(self) -> bool:\n        \"\"\"Run this step until it has completed or been skipped.\"\"\"\n        stop_watcher = threading.Event()\n        watcher = None\n        if self.watch_func:\n            watcher = threading.Thread(target=self.watch_func, args=(self.stack, stop_watcher))\n            watcher.start()\n        try:\n            while not self.done:\n                self._run_once()\n        finally:\n            if watcher:\n                stop_watcher.set()\n                watcher.join()\n        return self.ok\n\n    def _run_once(self) -> Status:\n        \"\"\"Run a step exactly once.\"\"\"\n        if not self.fn:\n            raise TypeError('Step.fn must be type Callable[..., Status] not None')\n        try:\n            status = self.fn(self.stack, status=self.status)\n        except CancelExecution:\n            status = SkippedStatus('canceled execution')\n        except Exception as err:\n            LOGGER.exception(err)\n            status = FailedStatus(reason=str(err))\n        self.set_status(status)\n        return status\n\n    @property\n    def name(self) -> str:\n        \"\"\"Name of the step.\n\n        This is equal to the name of the stack it operates on.\n\n        \"\"\"\n        return self.stack.name\n\n    @property\n    def requires(self) -> set[str]:\n        \"\"\"Return a list of step names this step depends on.\"\"\"\n        return self.stack.requires\n\n    @property\n    def required_by(self) -> set[str]:\n        \"\"\"Return a list of step names that depend on this step.\"\"\"\n        return self.stack.required_by\n\n    @property\n    def completed(self) -> bool:\n        \"\"\"Return True if the step is in a COMPLETE state.\"\"\"\n        return self.status == COMPLETE\n\n    @property\n    def skipped(self) -> bool:\n        \"\"\"Return True if the step is in a SKIPPED state.\"\"\"\n        return self.status == SKIPPED\n\n    @property\n    def failed(self) -> bool:\n        \"\"\"Return True if the step is in a FAILED state.\"\"\"\n        return self.status == FAILED\n\n    @property\n    def done(self) -> bool:\n        \"\"\"Return True if the step is finished.\n\n        To be ``True``, status must be either COMPLETE, SKIPPED or FAILED)\n\n        \"\"\"\n        return self.completed or self.skipped or self.failed\n\n    @property\n    def ok(self) -> bool:\n        \"\"\"Return True if the step is finished (either COMPLETE or SKIPPED).\"\"\"\n        return self.completed or self.skipped\n\n    @property\n    def submitted(self) -> bool:\n        \"\"\"Return True if the step is SUBMITTED, COMPLETE, or SKIPPED.\"\"\"\n        return self.status >= SUBMITTED\n\n    def set_status(self, status: Status) -> None:\n        \"\"\"Set the current step's status.\n\n        Args:\n            status: The status to set the step to.\n\n        \"\"\"\n        if status is not self.status:\n            LOGGER.debug('setting %s state to %s...', self.stack.name, status.name)\n            self.status = status\n            self.last_updated = time.time()\n            if self.stack.logging:\n                self.log_step()\n\n    def complete(self) -> None:\n        \"\"\"Shortcut for ``set_status(COMPLETE)``.\"\"\"\n        self.set_status(COMPLETE)\n\n    def log_step(self) -> None:\n        \"\"\"Construct a log message for a set and log it to the UI.\"\"\"\n        msg = self.status.name\n        if self.status.reason:\n            msg += f' ({self.status.reason})'\n        if self.status.code == SUBMITTED.code:\n            ui.log(LogLevels.NOTICE, msg, logger=self.logger)\n        elif self.status.code == COMPLETE.code:\n            ui.log(LogLevels.SUCCESS, msg, logger=self.logger)\n        elif self.status.code == FAILED.code:\n            ui.log(LogLevels.ERROR, msg, logger=self.logger)\n        else:\n            ui.info(msg, logger=self.logger)\n\n    def skip(self) -> None:\n        \"\"\"Shortcut for ``set_status(SKIPPED)``.\"\"\"\n        self.set_status(SKIPPED)\n\n    def submit(self) -> None:\n        \"\"\"Shortcut for ``set_status(SUBMITTED)``.\"\"\"\n        self.set_status(SUBMITTED)\n\n    @classmethod\n    def from_stack_name(cls, stack_name: str, context: CfnginContext, requires: list[str] | set[str] | None=None, fn: Callable[..., Status] | None=None, watch_func: Callable[..., Any] | None=None) -> Step:\n        \"\"\"Create a step using only a stack name.\n\n        Args:\n            stack_name: Name of a CloudFormation stack.\n            context: Context object. Required to initialize a \"fake\"\n                :class:`runway.cfngin.stack.Stack`.\n            requires: Stacks that this stack depends on.\n            fn: The function to run to execute the step.\n                This function will be ran multiple times until the step is \"done\".\n            watch_func: an optional function that will be called to \"tail\" the\n                step action.\n\n        \"\"\"\n        from runway.config.models.cfngin import CfnginStackDefinitionModel\n        stack_def = CfnginStackDefinitionModel.model_construct(name=stack_name, requires=requires or [])\n        stack = Stack(stack_def, context)\n        return cls(stack, fn=fn, watch_func=watch_func)\n\n    @classmethod\n    def from_persistent_graph(cls, graph_dict: dict[str, list[str]] | dict[str, set[str]] | OrderedDict[str, set[str]], context: CfnginContext, fn: Callable[..., Status] | None=None, watch_func: Callable[..., Any] | None=None) -> list[Step]:\n        \"\"\"Create a steps for a persistent graph dict.\n\n        Args:\n            graph_dict: A graph dict.\n            context: Context object. Required to initialize a \"fake\"\n                :class:`runway.cfngin.stack.Stack`.\n            requires: Stacks that this stack depends on.\n            fn: The function to run to execute the step.\n                This function will be ran multiple times until the step is \"done\".\n            watch_func: an optional function that will be called to \"tail\" the\n                step action.\n\n        \"\"\"\n        return [cls.from_stack_name(name, context, requires, fn, watch_func) for name, requires in graph_dict.items()]\n\n    def __repr__(self) -> str:\n        \"\"\"Object represented as a string.\"\"\"\n        return f'<CFNgin.plan.Step:{self.stack.name}>'\n\n    def __str__(self) -> str:\n        \"\"\"Object displayed as a string.\"\"\"\n        return self.stack.name\n\nNow, implement the following class. Do not explain the code. The given class skeleton is as follows:\n\nclass PackingMetrics:\n    '''Class for tracking and computing metrics for sequence packing algorithms.\n    This class provides methods to calculate various metrics that evaluate the\n    efficiency and effectiveness of sequence packing algorithms, such as bin\n    utilization, waste, and imbalance.\n    '''\n\n    def __init__(self):\n        '''Initialize the metrics tracker.'''\n        pass\n\n    def reset(self) -> None:\n        '''Reset all metrics.'''\n        pass\n\n    def update(self, sequence_lengths: List[int], bins: List[List[int]], bin_capacity: int, packing_time: Optional[float]=None) -> Dict[str, float]:\n        '''Update metrics with a new packing solution.\n        Args:\n            sequence_lengths: List of sequence lengths\n            bins: List of bins, where each bin is a list of indices\n            bin_capacity: Maximum capacity of each bin\n            packing_time: Optional time taken to compute the packing solution\n        Returns:\n            Dictionary of metrics for this packing solution\n        '''\n        pass\n\n    def calculate_stats_only(self, sequence_lengths: List[int], bins: List[List[int]], bin_capacity: int) -> Dict[str, float]:\n        '''Calculate metrics for a packing solution without updating the tracker.\n        Args:\n            sequence_lengths: List of sequence lengths\n            bins: List of bins, where each bin is a list of indices\n            bin_capacity: Maximum capacity of each bin\n        Returns:\n            Dictionary of metrics for this packing solution\n        '''\n        pass\n\n    def get_aggregated_stats(self) -> Dict[str, float]:\n        '''Get aggregated metrics across all packing operations.\n        Returns:\n            Dictionary of aggregated metrics\n        '''\n        pass\n\n    def print_aggregated_stats(self) -> None:\n        '''Print the aggregated metrics in a formatted way.'''\n        pass"
  }
]