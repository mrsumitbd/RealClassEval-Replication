[
  {
    "role": "assistant",
    "content": "You are an expert Python programmer who can correctly implement complete Python classes based on the provided class skeleton."
  },
  {
    "role": "user",
    "content": "For your understanding, following are some (skeleton, code) examples:\n\nExample skeleton:\n\n\nclass RandomGrayscale(torch.nn.Module):\n    '''Randomly convert image to grayscale with a probability of p (default 0.1).\n    If the image is torch Tensor, it is expected\n    to have [..., 3, H, W] shape, where ... means an arbitrary number of leading dimensions\n    Args:\n        p (float): probability that image should be converted to grayscale.\n    Returns:\n        PIL Image or Tensor: Grayscale version of the input image with probability p and unchanged\n        with probability (1-p).\n        - If input image is 1 channel: grayscale version is 1 channel\n        - If input image is 3 channel: grayscale version is 3 channel with r == g == b\n    '''\n\n    def __init__(self, p=0.1):\n        pass\n\n    def forward(self, img):\n        '''\n        Args:\n            img (PIL Image or Tensor): Image to be converted to grayscale.\n        Returns:\n            PIL Image or Tensor: Randomly grayscaled image.\n        '''\n        pass\n\n    def __repr__(self) -> str:\n        pass\nCorresponding class implementation:\n\nfrom ..utils import _log_api_usage_once\nfrom . import functional as F\nimport torch\n\nclass RandomGrayscale(torch.nn.Module):\n    \"\"\"Randomly convert image to grayscale with a probability of p (default 0.1).\n    If the image is torch Tensor, it is expected\n    to have [..., 3, H, W] shape, where ... means an arbitrary number of leading dimensions\n\n    Args:\n        p (float): probability that image should be converted to grayscale.\n\n    Returns:\n        PIL Image or Tensor: Grayscale version of the input image with probability p and unchanged\n        with probability (1-p).\n        - If input image is 1 channel: grayscale version is 1 channel\n        - If input image is 3 channel: grayscale version is 3 channel with r == g == b\n\n    \"\"\"\n\n    def __init__(self, p=0.1):\n        super().__init__()\n        _log_api_usage_once(self)\n        self.p = p\n\n    def forward(self, img):\n        \"\"\"\n        Args:\n            img (PIL Image or Tensor): Image to be converted to grayscale.\n\n        Returns:\n            PIL Image or Tensor: Randomly grayscaled image.\n        \"\"\"\n        num_output_channels, _, _ = F.get_dimensions(img)\n        if torch.rand(1) < self.p:\n            return F.rgb_to_grayscale(img, num_output_channels=num_output_channels)\n        return img\n\n    def __repr__(self) -> str:\n        return f'{self.__class__.__name__}(p={self.p})'\n\nExample skeleton:\n\n\nclass ResizeTransform(Transform):\n    '''\n    Resize the image.\n    '''\n\n    def __init__(self, h, w, new_h, new_w, interp):\n        '''\n        Args:\n            h, w (int):\n            new_h, new_w (int):\n            interp (int): cv2 interpolation method\n        '''\n        pass\n\n    def apply_image(self, img):\n        pass\n\n    def apply_coords(self, coords):\n        pass\nCorresponding class implementation:\n\nimport numpy as np\nimport cv2\n\nclass ResizeTransform(Transform):\n    \"\"\"\n    Resize the image.\n    \"\"\"\n\n    def __init__(self, h, w, new_h, new_w, interp):\n        \"\"\"\n        Args:\n            h, w (int):\n            new_h, new_w (int):\n            interp (int): cv2 interpolation method\n        \"\"\"\n        super(ResizeTransform, self).__init__()\n        self._init(locals())\n\n    def apply_image(self, img):\n        assert img.shape[:2] == (self.h, self.w)\n        ret = cv2.resize(img, (self.new_w, self.new_h), interpolation=self.interp)\n        if img.ndim == 3 and ret.ndim == 2:\n            ret = ret[:, :, np.newaxis]\n        return ret\n\n    def apply_coords(self, coords):\n        coords[:, 0] = coords[:, 0] * (self.new_w * 1.0 / self.w)\n        coords[:, 1] = coords[:, 1] * (self.new_h * 1.0 / self.h)\n        return coords\n\nNow, implement the following class. Do not explain the code. The given class skeleton is as follows:\n\nclass CenterCrop:\n    '''\n    Applies center cropping to images for classification tasks.\n    This class performs center cropping on input images, resizing them to a specified size while maintaining the aspect\n    ratio. It is designed to be part of a transformation pipeline, e.g., T.Compose([CenterCrop(size), ToTensor()]).\n    Attributes:\n        h (int): Target height of the cropped image.\n        w (int): Target width of the cropped image.\n    Methods:\n        __call__: Applies the center crop transformation to an input image.\n    Examples:\n        >>> transform = CenterCrop(640)\n        >>> image = np.random.randint(0, 255, (1080, 1920, 3), dtype=np.uint8)\n        >>> cropped_image = transform(image)\n        >>> print(cropped_image.shape)\n        (640, 640, 3)\n    '''\n\n    def __init__(self, size=640):\n        '''\n        Initializes the CenterCrop object for image preprocessing.\n        This class is designed to be part of a transformation pipeline, e.g., T.Compose([CenterCrop(size), ToTensor()]).\n        It performs a center crop on input images to a specified size.\n        Args:\n            size (int | Tuple[int, int]): The desired output size of the crop. If size is an int, a square crop\n                (size, size) is made. If size is a sequence like (h, w), it is used as the output size.\n        Returns:\n            (None): This method initializes the object and does not return anything.\n        Examples:\n            >>> transform = CenterCrop(224)\n            >>> img = np.random.rand(300, 300, 3)\n            >>> cropped_img = transform(img)\n            >>> print(cropped_img.shape)\n            (224, 224, 3)\n        '''\n        pass\n\n    def __call__(self, im):\n        '''\n        Applies center cropping to an input image.\n        This method resizes and crops the center of the image using a letterbox method. It maintains the aspect\n        ratio of the original image while fitting it into the specified dimensions.\n        Args:\n            im (numpy.ndarray | PIL.Image.Image): The input image as a numpy array of shape (H, W, C) or a\n                PIL Image object.\n        Returns:\n            (numpy.ndarray): The center-cropped and resized image as a numpy array of shape (self.h, self.w, C).\n        Examples:\n            >>> transform = CenterCrop(size=224)\n            >>> image = np.random.randint(0, 255, (640, 480, 3), dtype=np.uint8)\n            >>> cropped_image = transform(image)\n            >>> assert cropped_image.shape == (224, 224, 3)\n        '''\n        pass"
  }
]