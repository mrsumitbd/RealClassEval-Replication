[
  {
    "role": "assistant",
    "content": "You are an expert Python programmer who can correctly implement complete Python classes based on the provided class skeleton."
  },
  {
    "role": "user",
    "content": "For your understanding, following are some (skeleton, code) examples:\n\nExample skeleton:\n\n\nclass MultithreadedJobExecutor(JobExecutor):\n    '''\n    Experimental multi-threaded CWL executor.\n    Does simple resource accounting, will not start a job unless it\n    has cores / ram available, but does not make any attempt to\n    optimize usage.\n    '''\n\n    def __init__(self) -> None:\n        '''Initialize.'''\n        pass\n\n    def select_resources(self, request: dict[str, Union[int, float]], runtime_context: RuntimeContext) -> dict[str, Union[int, float]]:\n        '''Naïve check for available cpu cores and memory.'''\n        pass\n\n    def _runner(self, job: Union[JobBase, WorkflowJob, CallbackJob, ExpressionJob], runtime_context: RuntimeContext, TMPDIR_LOCK: threading.Lock) -> None:\n        '''Job running thread.'''\n        pass\n\n    def run_job(self, job: Optional[JobsType], runtime_context: RuntimeContext) -> None:\n        '''Execute a single Job in a separate thread.'''\n        pass\n\n    def wait_for_next_completion(self, runtime_context: RuntimeContext) -> None:\n        '''Wait for jobs to finish.'''\n        pass\n\n    def run_jobs(self, process: Process, job_order_object: CWLObjectType, logger: logging.Logger, runtime_context: RuntimeContext) -> None:\n        pass\nCorresponding class implementation:\n\nfrom .task_queue import TaskQueue\nimport logging\nfrom .errors import WorkflowException\nfrom .context import RuntimeContext, getdefault\nfrom .loghandler import _logger\nimport threading\nfrom .command_line_tool import CallbackJob, ExpressionJob\nfrom .process import Process, cleanIntermediate, relocateOutputs\nfrom .workflow_job import WorkflowJob, WorkflowJobStep\nimport math\nfrom typing import Optional, Union, cast\nfrom .job import JobBase\nimport psutil\nfrom .cuda import cuda_version_and_device_count\nfrom .utils import CWLObjectType, JobsType\nimport functools\n\nclass MultithreadedJobExecutor(JobExecutor):\n    \"\"\"\n    Experimental multi-threaded CWL executor.\n\n    Does simple resource accounting, will not start a job unless it\n    has cores / ram available, but does not make any attempt to\n    optimize usage.\n    \"\"\"\n\n    def __init__(self) -> None:\n        \"\"\"Initialize.\"\"\"\n        super().__init__()\n        self.exceptions: list[WorkflowException] = []\n        self.pending_jobs: list[JobsType] = []\n        self.pending_jobs_lock = threading.Lock()\n        self.max_ram = int(psutil.virtual_memory().available / 2 ** 20)\n        self.max_cores = float(psutil.cpu_count() or 1)\n        self.max_cuda = cuda_version_and_device_count()[1]\n        self.allocated_ram = float(0)\n        self.allocated_cores = float(0)\n        self.allocated_cuda: int = 0\n\n    def select_resources(self, request: dict[str, Union[int, float]], runtime_context: RuntimeContext) -> dict[str, Union[int, float]]:\n        \"\"\"Naïve check for available cpu cores and memory.\"\"\"\n        result: dict[str, Union[int, float]] = {}\n        maxrsc = {'cores': self.max_cores, 'ram': self.max_ram}\n        resources_types = {'cores', 'ram'}\n        if 'cudaDeviceCountMin' in request or 'cudaDeviceCountMax' in request:\n            maxrsc['cudaDeviceCount'] = self.max_cuda\n            resources_types.add('cudaDeviceCount')\n        for rsc in resources_types:\n            rsc_min = request[rsc + 'Min']\n            if rsc_min > maxrsc[rsc]:\n                raise WorkflowException(f'Requested at least {rsc_min} {rsc} but only {maxrsc[rsc]} available')\n            rsc_max = request[rsc + 'Max']\n            if rsc_max < maxrsc[rsc]:\n                result[rsc] = math.ceil(rsc_max)\n            else:\n                result[rsc] = maxrsc[rsc]\n        result['tmpdirSize'] = math.ceil(request['tmpdirMin'])\n        result['outdirSize'] = math.ceil(request['outdirMin'])\n        return result\n\n    def _runner(self, job: Union[JobBase, WorkflowJob, CallbackJob, ExpressionJob], runtime_context: RuntimeContext, TMPDIR_LOCK: threading.Lock) -> None:\n        \"\"\"Job running thread.\"\"\"\n        try:\n            _logger.debug('job: {}, runtime_context: {}, TMPDIR_LOCK: {}'.format(job, runtime_context, TMPDIR_LOCK))\n            job.run(runtime_context, TMPDIR_LOCK)\n        except WorkflowException as err:\n            _logger.exception(f'Got workflow error: {err}')\n            self.exceptions.append(err)\n        except Exception as err:\n            _logger.exception(f'Got workflow error: {err}')\n            wf_exc = WorkflowException(str(err))\n            wf_exc.__cause__ = err\n            wf_exc.__suppress_context__ = True\n            self.exceptions.append(wf_exc)\n        finally:\n            if runtime_context.workflow_eval_lock:\n                with runtime_context.workflow_eval_lock:\n                    if isinstance(job, JobBase):\n                        ram = job.builder.resources['ram']\n                        self.allocated_ram -= ram\n                        cores = job.builder.resources['cores']\n                        self.allocated_cores -= cores\n                        cudaDevices: int = cast(int, job.builder.resources.get('cudaDeviceCount', 0))\n                        self.allocated_cuda -= cudaDevices\n                    runtime_context.workflow_eval_lock.notify_all()\n\n    def run_job(self, job: Optional[JobsType], runtime_context: RuntimeContext) -> None:\n        \"\"\"Execute a single Job in a separate thread.\"\"\"\n        if job is not None:\n            with self.pending_jobs_lock:\n                self.pending_jobs.append(job)\n        with self.pending_jobs_lock:\n            n = 0\n            while n + 1 <= len(self.pending_jobs):\n                job = self.pending_jobs[n]\n                if isinstance(job, JobBase):\n                    ram = job.builder.resources['ram']\n                    cores = job.builder.resources['cores']\n                    cudaDevices = cast(int, job.builder.resources.get('cudaDeviceCount', 0))\n                    if ram > self.max_ram or cores > self.max_cores or cudaDevices > self.max_cuda:\n                        _logger.error('Job \"%s\" cannot be run, requests more resources (%s) than available on this host (already allocated ram is %d, allocated cores is %d, allocated CUDA is %d, max ram %d, max cores %d, max CUDA %d).', job.name, job.builder.resources, self.allocated_ram, self.allocated_cores, self.allocated_cuda, self.max_ram, self.max_cores, self.max_cuda)\n                        self.pending_jobs.remove(job)\n                        return\n                    if self.allocated_ram + ram > self.max_ram or self.allocated_cores + cores > self.max_cores or self.allocated_cuda + cudaDevices > self.max_cuda:\n                        _logger.debug('Job \"%s\" cannot run yet, resources (%s) are not available (already allocated ram is %d, allocated cores is %d, allocated CUDA devices is %d, max ram %d, max cores %d, max CUDA %d).', job.name, job.builder.resources, self.allocated_ram, self.allocated_cores, self.allocated_cuda, self.max_ram, self.max_cores, self.max_cuda)\n                        n += 1\n                        continue\n                if isinstance(job, JobBase):\n                    ram = job.builder.resources['ram']\n                    self.allocated_ram += ram\n                    cores = job.builder.resources['cores']\n                    self.allocated_cores += cores\n                    cuda = cast(int, job.builder.resources.get('cudaDevices', 0))\n                    self.allocated_cuda += cuda\n                self.taskqueue.add(functools.partial(self._runner, job, runtime_context, TMPDIR_LOCK), runtime_context.workflow_eval_lock)\n                self.pending_jobs.remove(job)\n\n    def wait_for_next_completion(self, runtime_context: RuntimeContext) -> None:\n        \"\"\"Wait for jobs to finish.\"\"\"\n        if runtime_context.workflow_eval_lock is not None:\n            runtime_context.workflow_eval_lock.wait(timeout=3)\n        if self.exceptions:\n            raise self.exceptions[0]\n\n    def run_jobs(self, process: Process, job_order_object: CWLObjectType, logger: logging.Logger, runtime_context: RuntimeContext) -> None:\n        self.taskqueue: TaskQueue = TaskQueue(threading.Lock(), int(math.ceil(self.max_cores)))\n        try:\n            jobiter = process.job(job_order_object, self.output_callback, runtime_context)\n            if runtime_context.workflow_eval_lock is None:\n                raise WorkflowException('runtimeContext.workflow_eval_lock must not be None')\n            runtime_context.workflow_eval_lock.acquire()\n            for job in jobiter:\n                if job is not None:\n                    if isinstance(job, JobBase):\n                        job.builder = runtime_context.builder or job.builder\n                        if job.outdir is not None:\n                            self.output_dirs.add(job.outdir)\n                self.run_job(job, runtime_context)\n                if job is None:\n                    if self.taskqueue.in_flight > 0:\n                        self.wait_for_next_completion(runtime_context)\n                    else:\n                        logger.error('Workflow cannot make any more progress.')\n                        break\n            self.run_job(None, runtime_context)\n            while self.taskqueue.in_flight > 0:\n                self.wait_for_next_completion(runtime_context)\n                self.run_job(None, runtime_context)\n            runtime_context.workflow_eval_lock.release()\n        finally:\n            self.taskqueue.drain()\n            self.taskqueue.join()\n\nExample skeleton:\n\n\nclass UtilTestsJSON(unittest.TestCase):\n    '''Utility JSON.'''\n\n    def setUp(self) -> None:\n        '''Create test suite.'''\n        pass\n\n    def tearDown(self) -> None:\n        '''Teardown test suite.'''\n        pass\n\n    def test_json_save(self) -> None:\n        '''Test json save.'''\n        pass\n\n    def test_json_load(self) -> None:\n        '''Test json load.'''\n        pass\n\n    def test_load_file_not_found(self) -> None:\n        '''Test json file missing.'''\n        pass\n\n    def test_load_not_json(self) -> None:\n        '''Test of load not json.'''\n        pass\n\n    def test_save_not_serializable(self) -> None:\n        '''Test save of illegal path.'''\n        pass\n\n    def test_os_error(self) -> None:\n        '''Test os error is thrown.'''\n        pass\nCorresponding class implementation:\n\nfrom unittest.mock import patch\nimport pytest\nimport unittest\nimport json\nfrom pytradfri.util import BitChoices, load_json, save_json\nfrom pytradfri.error import PytradfriError\nimport tempfile\nfrom os import path\nimport shutil\n\nclass UtilTestsJSON(unittest.TestCase):\n    \"\"\"Utility JSON.\"\"\"\n\n    def setUp(self) -> None:\n        \"\"\"Create test suite.\"\"\"\n        self.test_dir = tempfile.mkdtemp()\n\n    def tearDown(self) -> None:\n        \"\"\"Teardown test suite.\"\"\"\n        shutil.rmtree(self.test_dir)\n\n    def test_json_save(self) -> None:\n        \"\"\"Test json save.\"\"\"\n        filename = path.join(self.test_dir, 'sample_psk_file.txt')\n        conf = {'identity': 'pytradfri', 'key': '123abc'}\n        written_file = save_json(filename, conf)\n        self.assertTrue(written_file)\n\n    def test_json_load(self) -> None:\n        \"\"\"Test json load.\"\"\"\n        config = {'identity': 'hashstring', 'key': 'secretkey'}\n        data = json.dumps(config, sort_keys=True, indent=4)\n        with open(path.join(self.test_dir, 'sample_psk_file2.txt'), 'w', encoding='utf-8') as fil:\n            fil.write(data)\n        json_data = load_json(path.join(self.test_dir, 'sample_psk_file2.txt'))\n        self.assertEqual(json_data, {'identity': 'hashstring', 'key': 'secretkey'})\n\n    def test_load_file_not_found(self) -> None:\n        \"\"\"Test json file missing.\"\"\"\n        assert not load_json(path.join(self.test_dir, 'not_a_file'))\n\n    def test_load_not_json(self) -> None:\n        \"\"\"Test of load not json.\"\"\"\n        data = '{not valid json'\n        with open(path.join(self.test_dir, 'sample_psk_file3.txt'), 'w', encoding='utf-8') as fil:\n            fil.write(data)\n        with pytest.raises(PytradfriError):\n            load_json(path.join(self.test_dir, 'sample_psk_file3.txt'))\n\n    def test_save_not_serializable(self) -> None:\n        \"\"\"Test save of illegal path.\"\"\"\n        filename = path.join(self.test_dir, 'should_not_save')\n        conf = b'bytes are not serializable'\n        with pytest.raises(PytradfriError):\n            save_json(filename, conf)\n\n    def test_os_error(self) -> None:\n        \"\"\"Test os error is thrown.\"\"\"\n        with patch('builtins.open', side_effect=OSError(-1)):\n            with pytest.raises(PytradfriError):\n                load_json('whatever')\n            with pytest.raises(PytradfriError):\n                save_json('whatever', {})\n\nNow, implement the following class. Do not explain the code. The given class skeleton is as follows:\n\nclass ValidationMixin:\n    '''Handles the validation process, including generation, scoring, and aggregation.'''\n\n    def _validate(self) -> Dict[str, float]:\n        '''Performs validation by generating, scoring, and aggregating metrics across all ranks.'''\n        pass\n\n    def _prepare_validation_batch(self) -> DataProto:\n        '''Fetches and prepares a single batch for validation.'''\n        pass\n\n    def _prepare_generation_batch(self, batch: DataProto) -> DataProto:\n        '''Pops keys from a batch to isolate data needed for sequence generation.'''\n        pass\n\n    def _generate_for_validation(self, batch_proto: DataProto) -> DataProto:\n        '''Generates sequences using the rollout worker for a validation batch.'''\n        pass\n\n    def _score_and_package_results(self, generated_proto: DataProto) -> List[ValidationResult]:\n        '''Scores generated sequences and packages them into ValidationResult objects.'''\n        pass\n\n    def _aggregate_and_log_validation_metrics(self, all_payloads: List[ValidationPayload]) -> Dict[str, float]:\n        '''On Rank 0, aggregates all validation results and logs performance.'''\n        pass\n\n    def _aggregate_validation_results(self, all_payloads: List[ValidationPayload]) -> Dict[str, float]:\n        '''Computes the final metric dictionary from all gathered validation payloads.'''\n        pass\n\n    def _dump_validation_generations(self, results: List[ValidationResult]):\n        '''\n        Dumps local validation generation results to a rank-specific JSONL file.\n        This method is called by each rank to dump its own portion of the\n        validation data into a shared directory.\n        Args:\n            results: A list of ValidationResult objects containing the local\n                     data for the current rank.\n        '''\n        pass"
  }
]