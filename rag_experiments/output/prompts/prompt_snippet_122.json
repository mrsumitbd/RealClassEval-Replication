[
  {
    "role": "assistant",
    "content": "You are an expert Python programmer who can correctly implement complete Python classes based on the provided class skeleton."
  },
  {
    "role": "user",
    "content": "For your understanding, following are some (skeleton, code) examples:\n\nExample skeleton:\n\n\nclass Filter(ABC, Generic[FilterValueT]):\n    '''\n    A class representing a Lavalink audio filter.\n    Parameters\n    ----------\n    values: Union[Dict[str, Any], Sequence[Union[float, int]], float]\n        The values for this filter.\n    plugin_filter: :class:`bool`\n        Whether this filter is part of a Lavalink plugin. Typically, this will be ``True``\n        when creating your own filters.\n    Attributes\n    ----------\n    values: Union[Dict[str, Any], Sequence[Union[float, int]], float]\n        The values for this filter.\n    plugin_filter: :class:`bool`\n        Whether this filter is part of a Lavalink plugin.\n    '''\n\n    def __init__(self, values: FilterValueT, plugin_filter: bool=False):\n        pass\n    @abstractmethod\n    def update(self, **kwargs):\n        ''' Updates the internal values to match those provided. '''\n        pass\n    @abstractmethod\n    def serialize(self) -> Dict[str, FilterValueT]:\n        '''\n        Transforms the internal values into a dict matching the structure Lavalink expects.\n        Example:\n            .. code:: python\n                return {\"yourCustomFilter\": {\"gain\": 5}}\n        '''\n        pass\nCorresponding class implementation:\n\nfrom typing import TYPE_CHECKING, Any, Dict, Final, Generic, Optional, Sequence, TypeVar, Union, cast\nfrom abc import ABC, abstractmethod\n\nclass Filter(ABC, Generic[FilterValueT]):\n    \"\"\"\n    A class representing a Lavalink audio filter.\n\n    Parameters\n    ----------\n    values: Union[Dict[str, Any], Sequence[Union[float, int]], float]\n        The values for this filter.\n    plugin_filter: :class:`bool`\n        Whether this filter is part of a Lavalink plugin. Typically, this will be ``True``\n        when creating your own filters.\n\n    Attributes\n    ----------\n    values: Union[Dict[str, Any], Sequence[Union[float, int]], float]\n        The values for this filter.\n    plugin_filter: :class:`bool`\n        Whether this filter is part of a Lavalink plugin.\n    \"\"\"\n    __slots__ = ('values', 'plugin_filter')\n\n    def __init__(self, values: FilterValueT, plugin_filter: bool=False):\n        self.values: FilterValueT = values\n        self.plugin_filter: Final[bool] = plugin_filter\n\n    @abstractmethod\n    def update(self, **kwargs):\n        \"\"\" Updates the internal values to match those provided. \"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def serialize(self) -> Dict[str, FilterValueT]:\n        \"\"\"\n        Transforms the internal values into a dict matching the structure Lavalink expects.\n\n        Example:\n\n            .. code:: python\n\n                return {\"yourCustomFilter\": {\"gain\": 5}}\n        \"\"\"\n        raise NotImplementedError\n\nExample skeleton:\n\n\nclass PandasOnUnidistDataframeVirtualPartition(PandasDataframeAxisPartition):\n    '''\n    The class implements the interface in ``PandasDataframeAxisPartition``.\n    Parameters\n    ----------\n    list_of_partitions : Union[list, PandasOnUnidistDataframePartition]\n        List of ``PandasOnUnidistDataframePartition`` and\n        ``PandasOnUnidistDataframeVirtualPartition`` objects, or a single\n        ``PandasOnUnidistDataframePartition``.\n    get_ip : bool, default: False\n        Whether to get node IP addresses to conforming partitions or not.\n    full_axis : bool, default: True\n        Whether or not the virtual partition encompasses the whole axis.\n    call_queue : list, optional\n        A list of tuples (callable, args, kwargs) that contains deferred calls.\n    length : unidist.ObjectRef or int, optional\n        Length, or reference to length, of wrapped ``pandas.DataFrame``.\n    width : unidist.ObjectRef or int, optional\n        Width, or reference to width, of wrapped ``pandas.DataFrame``.\n    '''\n    @classmethod\n    def _get_deploy_axis_func(cls):\n        pass\n    @classmethod\n    def _get_deploy_split_func(cls):\n        pass\n    @classmethod\n    def _get_drain_func(cls):\n        pass\n    @property\n    def list_of_ips(self):\n        '''\n        Get the IPs holding the physical objects composing this partition.\n        Returns\n        -------\n        List\n            A list of IPs as ``unidist.ObjectRef`` or str.\n        '''\n        pass\n    @classmethod\n    @_inherit_docstrings(PandasDataframeAxisPartition.deploy_splitting_func)\n    def deploy_splitting_func(cls, axis, func, f_args, f_kwargs, num_splits, *partitions, extract_metadata=False):\n        pass\n    @classmethod\n    def deploy_axis_func(cls, axis, func, f_args, f_kwargs, num_splits, maintain_partitioning, *partitions, min_block_size, lengths=None, manual_partition=False, max_retries=None):\n        '''\n        Deploy a function along a full axis.\n        Parameters\n        ----------\n        axis : {0, 1}\n            The axis to perform the function along.\n        func : callable\n            The function to perform.\n        f_args : list or tuple\n            Positional arguments to pass to ``func``.\n        f_kwargs : dict\n            Keyword arguments to pass to ``func``.\n        num_splits : int\n            The number of splits to return (see ``split_result_of_axis_func_pandas``).\n        maintain_partitioning : bool\n            If True, keep the old partitioning if possible.\n            If False, create a new partition layout.\n        *partitions : iterable\n            All partitions that make up the full axis (row or column).\n        min_block_size : int\n            Minimum number of rows/columns in a single split.\n        lengths : list, optional\n            The list of lengths to shuffle the object.\n        manual_partition : bool, default: False\n            If True, partition the result with `lengths`.\n        max_retries : int, default: None\n            The max number of times to retry the func.\n        Returns\n        -------\n        list\n            A list of ``unidist.ObjectRef``-s.\n        '''\n        pass\n    @classmethod\n    def deploy_func_between_two_axis_partitions(cls, axis, func, f_args, f_kwargs, num_splits, len_of_left, other_shape, *partitions, min_block_size):\n        '''\n        Deploy a function along a full axis between two data sets.\n        Parameters\n        ----------\n        axis : {0, 1}\n            The axis to perform the function along.\n        func : callable\n            The function to perform.\n        f_args : list or tuple\n            Positional arguments to pass to ``func``.\n        f_kwargs : dict\n            Keyword arguments to pass to ``func``.\n        num_splits : int\n            The number of splits to return (see ``split_result_of_axis_func_pandas``).\n        len_of_left : int\n            The number of values in `partitions` that belong to the left data set.\n        other_shape : np.ndarray\n            The shape of right frame in terms of partitions, i.e.\n            (other_shape[i-1], other_shape[i]) will indicate slice to restore i-1 axis partition.\n        *partitions : iterable\n            All partitions that make up the full axis (row or column) for both data sets.\n        min_block_size : int\n            Minimum number of rows/columns in a single split.\n        Returns\n        -------\n        list\n            A list of ``unidist.ObjectRef``-s.\n        '''\n        pass\n\n    def wait(self):\n        '''Wait completing computations on the object wrapped by the partition.'''\n        pass\nCorresponding class implementation:\n\nfrom .partition import PandasOnUnidistDataframePartition\nfrom modin.core.execution.unidist.common import UnidistWrapper\nfrom modin.core.dataframe.pandas.partitioning.axis_partition import PandasDataframeAxisPartition\nfrom modin.utils import _inherit_docstrings\n\nclass PandasOnUnidistDataframeVirtualPartition(PandasDataframeAxisPartition):\n    \"\"\"\n    The class implements the interface in ``PandasDataframeAxisPartition``.\n\n    Parameters\n    ----------\n    list_of_partitions : Union[list, PandasOnUnidistDataframePartition]\n        List of ``PandasOnUnidistDataframePartition`` and\n        ``PandasOnUnidistDataframeVirtualPartition`` objects, or a single\n        ``PandasOnUnidistDataframePartition``.\n    get_ip : bool, default: False\n        Whether to get node IP addresses to conforming partitions or not.\n    full_axis : bool, default: True\n        Whether or not the virtual partition encompasses the whole axis.\n    call_queue : list, optional\n        A list of tuples (callable, args, kwargs) that contains deferred calls.\n    length : unidist.ObjectRef or int, optional\n        Length, or reference to length, of wrapped ``pandas.DataFrame``.\n    width : unidist.ObjectRef or int, optional\n        Width, or reference to width, of wrapped ``pandas.DataFrame``.\n    \"\"\"\n    _PARTITIONS_METADATA_LEN = 3\n    partition_type = PandasOnUnidistDataframePartition\n    axis = None\n    _DEPLOY_AXIS_FUNC = None\n    _DEPLOY_SPLIT_FUNC = None\n    _DRAIN_FUNC = None\n\n    @classmethod\n    def _get_deploy_axis_func(cls):\n        if cls._DEPLOY_AXIS_FUNC is None:\n            cls._DEPLOY_AXIS_FUNC = UnidistWrapper.put(PandasDataframeAxisPartition.deploy_axis_func)\n        return cls._DEPLOY_AXIS_FUNC\n\n    @classmethod\n    def _get_deploy_split_func(cls):\n        if cls._DEPLOY_SPLIT_FUNC is None:\n            cls._DEPLOY_SPLIT_FUNC = UnidistWrapper.put(PandasDataframeAxisPartition.deploy_splitting_func)\n        return cls._DEPLOY_SPLIT_FUNC\n\n    @classmethod\n    def _get_drain_func(cls):\n        if cls._DRAIN_FUNC is None:\n            cls._DRAIN_FUNC = UnidistWrapper.put(PandasDataframeAxisPartition.drain)\n        return cls._DRAIN_FUNC\n\n    @property\n    def list_of_ips(self):\n        \"\"\"\n        Get the IPs holding the physical objects composing this partition.\n\n        Returns\n        -------\n        List\n            A list of IPs as ``unidist.ObjectRef`` or str.\n        \"\"\"\n        result = [None] * len(self.list_of_block_partitions)\n        for idx, partition in enumerate(self.list_of_block_partitions):\n            partition.drain_call_queue()\n            result[idx] = partition.ip(materialize=False)\n        return result\n\n    @classmethod\n    @_inherit_docstrings(PandasDataframeAxisPartition.deploy_splitting_func)\n    def deploy_splitting_func(cls, axis, func, f_args, f_kwargs, num_splits, *partitions, extract_metadata=False):\n        return _deploy_unidist_func.options(num_returns=num_splits * (1 + cls._PARTITIONS_METADATA_LEN) if extract_metadata else num_splits).remote(cls._get_deploy_split_func(), axis, func, f_args, f_kwargs, num_splits, *partitions, extract_metadata=extract_metadata)\n\n    @classmethod\n    def deploy_axis_func(cls, axis, func, f_args, f_kwargs, num_splits, maintain_partitioning, *partitions, min_block_size, lengths=None, manual_partition=False, max_retries=None):\n        \"\"\"\n        Deploy a function along a full axis.\n\n        Parameters\n        ----------\n        axis : {0, 1}\n            The axis to perform the function along.\n        func : callable\n            The function to perform.\n        f_args : list or tuple\n            Positional arguments to pass to ``func``.\n        f_kwargs : dict\n            Keyword arguments to pass to ``func``.\n        num_splits : int\n            The number of splits to return (see ``split_result_of_axis_func_pandas``).\n        maintain_partitioning : bool\n            If True, keep the old partitioning if possible.\n            If False, create a new partition layout.\n        *partitions : iterable\n            All partitions that make up the full axis (row or column).\n        min_block_size : int\n            Minimum number of rows/columns in a single split.\n        lengths : list, optional\n            The list of lengths to shuffle the object.\n        manual_partition : bool, default: False\n            If True, partition the result with `lengths`.\n        max_retries : int, default: None\n            The max number of times to retry the func.\n\n        Returns\n        -------\n        list\n            A list of ``unidist.ObjectRef``-s.\n        \"\"\"\n        return _deploy_unidist_func.options(num_returns=(num_splits if lengths is None else len(lengths)) * (1 + cls._PARTITIONS_METADATA_LEN), **{'max_retries': max_retries} if max_retries is not None else {}).remote(cls._get_deploy_axis_func(), axis, func, f_args, f_kwargs, num_splits, maintain_partitioning, *partitions, manual_partition=manual_partition, min_block_size=min_block_size, lengths=lengths)\n\n    @classmethod\n    def deploy_func_between_two_axis_partitions(cls, axis, func, f_args, f_kwargs, num_splits, len_of_left, other_shape, *partitions, min_block_size):\n        \"\"\"\n        Deploy a function along a full axis between two data sets.\n\n        Parameters\n        ----------\n        axis : {0, 1}\n            The axis to perform the function along.\n        func : callable\n            The function to perform.\n        f_args : list or tuple\n            Positional arguments to pass to ``func``.\n        f_kwargs : dict\n            Keyword arguments to pass to ``func``.\n        num_splits : int\n            The number of splits to return (see ``split_result_of_axis_func_pandas``).\n        len_of_left : int\n            The number of values in `partitions` that belong to the left data set.\n        other_shape : np.ndarray\n            The shape of right frame in terms of partitions, i.e.\n            (other_shape[i-1], other_shape[i]) will indicate slice to restore i-1 axis partition.\n        *partitions : iterable\n            All partitions that make up the full axis (row or column) for both data sets.\n        min_block_size : int\n            Minimum number of rows/columns in a single split.\n\n        Returns\n        -------\n        list\n            A list of ``unidist.ObjectRef``-s.\n        \"\"\"\n        return _deploy_unidist_func.options(num_returns=num_splits * (1 + cls._PARTITIONS_METADATA_LEN)).remote(PandasDataframeAxisPartition.deploy_func_between_two_axis_partitions, axis, func, f_args, f_kwargs, num_splits, len_of_left, other_shape, *partitions, min_block_size=min_block_size)\n\n    def wait(self):\n        \"\"\"Wait completing computations on the object wrapped by the partition.\"\"\"\n        self.drain_call_queue()\n        futures = self.list_of_blocks\n        UnidistWrapper.wait(futures)\n\nNow, implement the following class. Do not explain the code. The given class skeleton is as follows:\n\nclass NunchakuQwenImageDiTLoader:\n    '''\n    Loader for Nunchaku Qwen-Image models.\n    Attributes\n    ----------\n    RETURN_TYPES : tuple\n        Output types for the node (\"MODEL\",).\n    FUNCTION : str\n        Name of the function to call (\"load_model\").\n    CATEGORY : str\n        Node category (\"Nunchaku\").\n    TITLE : str\n        Node title (\"Nunchaku Qwen-Image DiT Loader\").\n    '''\n    @classmethod\n    def INPUT_TYPES(s):\n        '''\n        Define the input types and tooltips for the node.\n        Returns\n        -------\n        dict\n            A dictionary specifying the required inputs and their descriptions for the node interface.\n        '''\n        pass\n\n    def load_model(self, model_name: str, cpu_offload: str, **kwargs):\n        '''\n        Load the Qwen-Image model from file and return a patched model.\n        Parameters\n        ----------\n        model_name : str\n            The filename of the Qwen-Image model to load.\n        cpu_offload : str\n            Whether to enable CPU offload for the transformer model.\n        Returns\n        -------\n        tuple\n            A tuple containing the loaded and patched model.\n        '''\n        pass"
  }
]