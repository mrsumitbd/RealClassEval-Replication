[
  {
    "role": "assistant",
    "content": "You are an expert Python programmer who can correctly implement complete Python classes based on the provided class skeleton."
  },
  {
    "role": "user",
    "content": "For your understanding, following are some (skeleton, code) examples:\n\nExample skeleton:\n\n\nclass LightController:\n    '''LightController sets the Flex's status bar to match the protocol status.'''\n\n    def __init__(self, api: HardwareControlAPI, run_orchestrator_store: Optional[RunOrchestratorStore]) -> None:\n        '''Create a new LightController.'''\n        pass\n\n    def mark_initialization_done(self) -> None:\n        '''Called once the robot server hardware initialization finishes.'''\n        pass\n\n    def update_run_orchestrator_store(self, run_orchestrator_store: RunOrchestratorStore) -> None:\n        '''Provide a handle to an EngineStore for the light control task.'''\n        pass\n\n    def update_run_orchestrator_store(self, run_orchestrator_store: RunOrchestratorStore) -> None:\n        '''Update the status bar if the current run status has changed.'''\n        pass\n\n    def _get_current_engine_status(self) -> Optional[EngineStatus]:\n        '''Get the `status` value from the engine's active run engine.'''\n        pass\n\n    def _get_active_updates(self) -> List[SubSystem]:\n        '''Get any active firmware updates.'''\n        pass\n\n    def get_current_status(self) -> Status:\n        '''Get the overall status of the system for light purposes.'''\n        pass\nCorresponding class implementation:\n\nfrom opentrons.hardware_control.types import StatusBarState, EstopState, SubSystem, UpdateState\nfrom typing import Optional, List\nfrom opentrons.hardware_control import HardwareControlAPI\nfrom .run_orchestrator_store import RunOrchestratorStore\nfrom opentrons.protocol_engine.types import EngineStatus\n\nclass LightController:\n    \"\"\"LightController sets the Flex's status bar to match the protocol status.\"\"\"\n\n    def __init__(self, api: HardwareControlAPI, run_orchestrator_store: Optional[RunOrchestratorStore]) -> None:\n        \"\"\"Create a new LightController.\"\"\"\n        self._api = api\n        self._run_orchestrator_store = run_orchestrator_store\n        self._initialization_done = False\n\n    def mark_initialization_done(self) -> None:\n        \"\"\"Called once the robot server hardware initialization finishes.\"\"\"\n        self._initialization_done = True\n\n    def update_run_orchestrator_store(self, run_orchestrator_store: RunOrchestratorStore) -> None:\n        \"\"\"Provide a handle to an EngineStore for the light control task.\"\"\"\n        self._run_orchestrator_store = run_orchestrator_store\n\n    async def update(self, prev_status: Optional[Status], new_status: Status) -> None:\n        \"\"\"Update the status bar if the current run status has changed.\"\"\"\n        if prev_status == new_status:\n            return\n        if new_status.estop_status == EstopState.PHYSICALLY_ENGAGED:\n            await self._api.set_status_bar_state(state=StatusBarState.SOFTWARE_ERROR)\n        elif len(new_status.active_updates) > 0:\n            state = _active_updates_to_status_bar(previous=[] if prev_status is None else prev_status.active_updates, current=new_status.active_updates, initialization_done=self._initialization_done, force_value=True if prev_status is not None and prev_status.estop_status is EstopState.PHYSICALLY_ENGAGED else False)\n            if state is not None:\n                await self._api.set_status_bar_state(state=state)\n        else:\n            await self._api.set_status_bar_state(state=_engine_status_to_status_bar(status=new_status.engine_status, initialization_done=self._initialization_done))\n\n    def _get_current_engine_status(self) -> Optional[EngineStatus]:\n        \"\"\"Get the `status` value from the engine's active run engine.\"\"\"\n        if self._run_orchestrator_store is None:\n            return None\n        current_id = self._run_orchestrator_store.current_run_id\n        if current_id is not None:\n            return self._run_orchestrator_store.get_status()\n        return None\n\n    def _get_active_updates(self) -> List[SubSystem]:\n        \"\"\"Get any active firmware updates.\"\"\"\n        return [subsystem for subsystem, status in self._api.attached_subsystems.items() if status.update_state is not None and status.update_state is UpdateState.updating]\n\n    def get_current_status(self) -> Status:\n        \"\"\"Get the overall status of the system for light purposes.\"\"\"\n        return Status(active_updates=self._get_active_updates(), estop_status=self._api.get_estop_state(), engine_status=self._get_current_engine_status())\n\nExample skeleton:\n\n\nclass MultithreadedJobExecutor(JobExecutor):\n    '''\n    Experimental multi-threaded CWL executor.\n    Does simple resource accounting, will not start a job unless it\n    has cores / ram available, but does not make any attempt to\n    optimize usage.\n    '''\n\n    def __init__(self) -> None:\n        '''Initialize.'''\n        pass\n\n    def select_resources(self, request: dict[str, Union[int, float]], runtime_context: RuntimeContext) -> dict[str, Union[int, float]]:\n        '''Naïve check for available cpu cores and memory.'''\n        pass\n\n    def _runner(self, job: Union[JobBase, WorkflowJob, CallbackJob, ExpressionJob], runtime_context: RuntimeContext, TMPDIR_LOCK: threading.Lock) -> None:\n        '''Job running thread.'''\n        pass\n\n    def run_job(self, job: Optional[JobsType], runtime_context: RuntimeContext) -> None:\n        '''Execute a single Job in a separate thread.'''\n        pass\n\n    def wait_for_next_completion(self, runtime_context: RuntimeContext) -> None:\n        '''Wait for jobs to finish.'''\n        pass\n\n    def run_jobs(self, process: Process, job_order_object: CWLObjectType, logger: logging.Logger, runtime_context: RuntimeContext) -> None:\n        pass\nCorresponding class implementation:\n\nfrom .task_queue import TaskQueue\nimport logging\nfrom .errors import WorkflowException\nfrom .context import RuntimeContext, getdefault\nfrom .loghandler import _logger\nimport threading\nfrom .command_line_tool import CallbackJob, ExpressionJob\nfrom .process import Process, cleanIntermediate, relocateOutputs\nfrom .workflow_job import WorkflowJob, WorkflowJobStep\nimport math\nfrom typing import Optional, Union, cast\nfrom .job import JobBase\nimport psutil\nfrom .cuda import cuda_version_and_device_count\nfrom .utils import CWLObjectType, JobsType\nimport functools\n\nclass MultithreadedJobExecutor(JobExecutor):\n    \"\"\"\n    Experimental multi-threaded CWL executor.\n\n    Does simple resource accounting, will not start a job unless it\n    has cores / ram available, but does not make any attempt to\n    optimize usage.\n    \"\"\"\n\n    def __init__(self) -> None:\n        \"\"\"Initialize.\"\"\"\n        super().__init__()\n        self.exceptions: list[WorkflowException] = []\n        self.pending_jobs: list[JobsType] = []\n        self.pending_jobs_lock = threading.Lock()\n        self.max_ram = int(psutil.virtual_memory().available / 2 ** 20)\n        self.max_cores = float(psutil.cpu_count() or 1)\n        self.max_cuda = cuda_version_and_device_count()[1]\n        self.allocated_ram = float(0)\n        self.allocated_cores = float(0)\n        self.allocated_cuda: int = 0\n\n    def select_resources(self, request: dict[str, Union[int, float]], runtime_context: RuntimeContext) -> dict[str, Union[int, float]]:\n        \"\"\"Naïve check for available cpu cores and memory.\"\"\"\n        result: dict[str, Union[int, float]] = {}\n        maxrsc = {'cores': self.max_cores, 'ram': self.max_ram}\n        resources_types = {'cores', 'ram'}\n        if 'cudaDeviceCountMin' in request or 'cudaDeviceCountMax' in request:\n            maxrsc['cudaDeviceCount'] = self.max_cuda\n            resources_types.add('cudaDeviceCount')\n        for rsc in resources_types:\n            rsc_min = request[rsc + 'Min']\n            if rsc_min > maxrsc[rsc]:\n                raise WorkflowException(f'Requested at least {rsc_min} {rsc} but only {maxrsc[rsc]} available')\n            rsc_max = request[rsc + 'Max']\n            if rsc_max < maxrsc[rsc]:\n                result[rsc] = math.ceil(rsc_max)\n            else:\n                result[rsc] = maxrsc[rsc]\n        result['tmpdirSize'] = math.ceil(request['tmpdirMin'])\n        result['outdirSize'] = math.ceil(request['outdirMin'])\n        return result\n\n    def _runner(self, job: Union[JobBase, WorkflowJob, CallbackJob, ExpressionJob], runtime_context: RuntimeContext, TMPDIR_LOCK: threading.Lock) -> None:\n        \"\"\"Job running thread.\"\"\"\n        try:\n            _logger.debug('job: {}, runtime_context: {}, TMPDIR_LOCK: {}'.format(job, runtime_context, TMPDIR_LOCK))\n            job.run(runtime_context, TMPDIR_LOCK)\n        except WorkflowException as err:\n            _logger.exception(f'Got workflow error: {err}')\n            self.exceptions.append(err)\n        except Exception as err:\n            _logger.exception(f'Got workflow error: {err}')\n            wf_exc = WorkflowException(str(err))\n            wf_exc.__cause__ = err\n            wf_exc.__suppress_context__ = True\n            self.exceptions.append(wf_exc)\n        finally:\n            if runtime_context.workflow_eval_lock:\n                with runtime_context.workflow_eval_lock:\n                    if isinstance(job, JobBase):\n                        ram = job.builder.resources['ram']\n                        self.allocated_ram -= ram\n                        cores = job.builder.resources['cores']\n                        self.allocated_cores -= cores\n                        cudaDevices: int = cast(int, job.builder.resources.get('cudaDeviceCount', 0))\n                        self.allocated_cuda -= cudaDevices\n                    runtime_context.workflow_eval_lock.notify_all()\n\n    def run_job(self, job: Optional[JobsType], runtime_context: RuntimeContext) -> None:\n        \"\"\"Execute a single Job in a separate thread.\"\"\"\n        if job is not None:\n            with self.pending_jobs_lock:\n                self.pending_jobs.append(job)\n        with self.pending_jobs_lock:\n            n = 0\n            while n + 1 <= len(self.pending_jobs):\n                job = self.pending_jobs[n]\n                if isinstance(job, JobBase):\n                    ram = job.builder.resources['ram']\n                    cores = job.builder.resources['cores']\n                    cudaDevices = cast(int, job.builder.resources.get('cudaDeviceCount', 0))\n                    if ram > self.max_ram or cores > self.max_cores or cudaDevices > self.max_cuda:\n                        _logger.error('Job \"%s\" cannot be run, requests more resources (%s) than available on this host (already allocated ram is %d, allocated cores is %d, allocated CUDA is %d, max ram %d, max cores %d, max CUDA %d).', job.name, job.builder.resources, self.allocated_ram, self.allocated_cores, self.allocated_cuda, self.max_ram, self.max_cores, self.max_cuda)\n                        self.pending_jobs.remove(job)\n                        return\n                    if self.allocated_ram + ram > self.max_ram or self.allocated_cores + cores > self.max_cores or self.allocated_cuda + cudaDevices > self.max_cuda:\n                        _logger.debug('Job \"%s\" cannot run yet, resources (%s) are not available (already allocated ram is %d, allocated cores is %d, allocated CUDA devices is %d, max ram %d, max cores %d, max CUDA %d).', job.name, job.builder.resources, self.allocated_ram, self.allocated_cores, self.allocated_cuda, self.max_ram, self.max_cores, self.max_cuda)\n                        n += 1\n                        continue\n                if isinstance(job, JobBase):\n                    ram = job.builder.resources['ram']\n                    self.allocated_ram += ram\n                    cores = job.builder.resources['cores']\n                    self.allocated_cores += cores\n                    cuda = cast(int, job.builder.resources.get('cudaDevices', 0))\n                    self.allocated_cuda += cuda\n                self.taskqueue.add(functools.partial(self._runner, job, runtime_context, TMPDIR_LOCK), runtime_context.workflow_eval_lock)\n                self.pending_jobs.remove(job)\n\n    def wait_for_next_completion(self, runtime_context: RuntimeContext) -> None:\n        \"\"\"Wait for jobs to finish.\"\"\"\n        if runtime_context.workflow_eval_lock is not None:\n            runtime_context.workflow_eval_lock.wait(timeout=3)\n        if self.exceptions:\n            raise self.exceptions[0]\n\n    def run_jobs(self, process: Process, job_order_object: CWLObjectType, logger: logging.Logger, runtime_context: RuntimeContext) -> None:\n        self.taskqueue: TaskQueue = TaskQueue(threading.Lock(), int(math.ceil(self.max_cores)))\n        try:\n            jobiter = process.job(job_order_object, self.output_callback, runtime_context)\n            if runtime_context.workflow_eval_lock is None:\n                raise WorkflowException('runtimeContext.workflow_eval_lock must not be None')\n            runtime_context.workflow_eval_lock.acquire()\n            for job in jobiter:\n                if job is not None:\n                    if isinstance(job, JobBase):\n                        job.builder = runtime_context.builder or job.builder\n                        if job.outdir is not None:\n                            self.output_dirs.add(job.outdir)\n                self.run_job(job, runtime_context)\n                if job is None:\n                    if self.taskqueue.in_flight > 0:\n                        self.wait_for_next_completion(runtime_context)\n                    else:\n                        logger.error('Workflow cannot make any more progress.')\n                        break\n            self.run_job(None, runtime_context)\n            while self.taskqueue.in_flight > 0:\n                self.wait_for_next_completion(runtime_context)\n                self.run_job(None, runtime_context)\n            runtime_context.workflow_eval_lock.release()\n        finally:\n            self.taskqueue.drain()\n            self.taskqueue.join()\n\nNow, implement the following class. Do not explain the code. The given class skeleton is as follows:\n\nclass MemoryManager:\n    '''Simple memory manager that leverages PyTorch's built-in memory optimizations.'''\n\n    def __init__(self):\n        '''Initialize the memory manager.'''\n        pass\n\n    def get_memory_info(self) -> Dict[str, Any]:\n        '''Get current memory usage information.'''\n        pass\n\n    def cleanup_memory(self, force: bool=False) -> None:\n        '''Free up memory by garbage collection and emptying CUDA cache.'''\n        pass\n\n    def get_optimal_training_config(self) -> Dict[str, Any]:\n        '''Get recommended configurations for model training based on hardware capabilities.'''\n        pass\n\n    def optimize_model_for_training(self, model):\n        '''Apply PyTorch's built-in memory optimizations for training.'''\n        pass\n\n    def optimize_training_args(self, training_args):\n        '''Configure training arguments for efficient memory usage.'''\n        pass"
  }
]