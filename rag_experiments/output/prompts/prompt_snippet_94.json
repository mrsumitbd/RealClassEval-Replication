[
  {
    "role": "assistant",
    "content": "You are an expert Python programmer who can correctly implement complete Python classes based on the provided class skeleton."
  },
  {
    "role": "user",
    "content": "For your understanding, following are some (skeleton, code) examples:\n\nExample skeleton:\n\n\nclass PCAM(VisionDataset):\n    '''`PCAM Dataset   <https://github.com/basveeling/pcam>`_.\n    The PatchCamelyon dataset is a binary classification dataset with 327,680\n    color images (96px x 96px), extracted from histopathologic scans of lymph node\n    sections. Each image is annotated with a binary label indicating presence of\n    metastatic tissue.\n    This dataset requires the ``h5py`` package which you can install with ``pip install h5py``.\n    Args:\n         root (str or ``pathlib.Path``): Root directory of the dataset.\n         split (string, optional): The dataset split, supports ``\"train\"`` (default), ``\"test\"`` or ``\"val\"``.\n         transform (callable, optional): A function/transform that takes in a PIL image and returns a transformed\n             version. E.g, ``transforms.RandomCrop``.\n         target_transform (callable, optional): A function/transform that takes in the target and transforms it.\n         download (bool, optional): If True, downloads the dataset from the internet and puts it into ``root/pcam``. If\n             dataset is already downloaded, it is not downloaded again.\n             .. warning::\n                To download the dataset `gdown <https://github.com/wkentaro/gdown>`_ is required.\n    '''\n\n    def __init__(self, root: Union[str, pathlib.Path], split: str='train', transform: Optional[Callable]=None, target_transform: Optional[Callable]=None, download: bool=False):\n        pass\n\n    def __len__(self) -> int:\n        pass\n\n    def __getitem__(self, idx: int) -> tuple[Any, Any]:\n        pass\n\n    def _check_exists(self) -> bool:\n        pass\n\n    def _download(self) -> None:\n        pass\nCorresponding class implementation:\n\nfrom typing import Any, Callable, Optional, Union\nimport pathlib\nfrom .vision import VisionDataset\nfrom PIL import Image\nfrom .utils import _decompress, download_file_from_google_drive, verify_str_arg\n\nclass PCAM(VisionDataset):\n    \"\"\"`PCAM Dataset   <https://github.com/basveeling/pcam>`_.\n\n    The PatchCamelyon dataset is a binary classification dataset with 327,680\n    color images (96px x 96px), extracted from histopathologic scans of lymph node\n    sections. Each image is annotated with a binary label indicating presence of\n    metastatic tissue.\n\n    This dataset requires the ``h5py`` package which you can install with ``pip install h5py``.\n\n    Args:\n         root (str or ``pathlib.Path``): Root directory of the dataset.\n         split (string, optional): The dataset split, supports ``\"train\"`` (default), ``\"test\"`` or ``\"val\"``.\n         transform (callable, optional): A function/transform that takes in a PIL image and returns a transformed\n             version. E.g, ``transforms.RandomCrop``.\n         target_transform (callable, optional): A function/transform that takes in the target and transforms it.\n         download (bool, optional): If True, downloads the dataset from the internet and puts it into ``root/pcam``. If\n             dataset is already downloaded, it is not downloaded again.\n\n             .. warning::\n\n                To download the dataset `gdown <https://github.com/wkentaro/gdown>`_ is required.\n    \"\"\"\n    _FILES = {'train': {'images': ('camelyonpatch_level_2_split_train_x.h5', '1Ka0XfEMiwgCYPdTI-vv6eUElOBnKFKQ2', '1571f514728f59376b705fc836ff4b63'), 'targets': ('camelyonpatch_level_2_split_train_y.h5', '1269yhu3pZDP8UYFQs-NYs3FPwuK-nGSG', '35c2d7259d906cfc8143347bb8e05be7')}, 'test': {'images': ('camelyonpatch_level_2_split_test_x.h5', '1qV65ZqZvWzuIVthK8eVDhIwrbnsJdbg_', 'd8c2d60d490dbd479f8199bdfa0cf6ec'), 'targets': ('camelyonpatch_level_2_split_test_y.h5', '17BHrSrwWKjYsOgTMmoqrIjDy6Fa2o_gP', '60a7035772fbdb7f34eb86d4420cf66a')}, 'val': {'images': ('camelyonpatch_level_2_split_valid_x.h5', '1hgshYGWK8V-eGRy8LToWJJgDU_rXWVJ3', 'd5b63470df7cfa627aeec8b9dc0c066e'), 'targets': ('camelyonpatch_level_2_split_valid_y.h5', '1bH8ZRbhSVAhScTS0p9-ZzGnX91cHT3uO', '2b85f58b927af9964a4c15b8f7e8f179')}}\n\n    def __init__(self, root: Union[str, pathlib.Path], split: str='train', transform: Optional[Callable]=None, target_transform: Optional[Callable]=None, download: bool=False):\n        try:\n            import h5py\n            self.h5py = h5py\n        except ImportError:\n            raise RuntimeError('h5py is not found. This dataset needs to have h5py installed: please run pip install h5py')\n        self._split = verify_str_arg(split, 'split', ('train', 'test', 'val'))\n        super().__init__(root, transform=transform, target_transform=target_transform)\n        self._base_folder = pathlib.Path(self.root) / 'pcam'\n        if download:\n            self._download()\n        if not self._check_exists():\n            raise RuntimeError('Dataset not found. You can use download=True to download it')\n\n    def __len__(self) -> int:\n        images_file = self._FILES[self._split]['images'][0]\n        with self.h5py.File(self._base_folder / images_file) as images_data:\n            return images_data['x'].shape[0]\n\n    def __getitem__(self, idx: int) -> tuple[Any, Any]:\n        images_file = self._FILES[self._split]['images'][0]\n        with self.h5py.File(self._base_folder / images_file) as images_data:\n            image = Image.fromarray(images_data['x'][idx]).convert('RGB')\n        targets_file = self._FILES[self._split]['targets'][0]\n        with self.h5py.File(self._base_folder / targets_file) as targets_data:\n            target = int(targets_data['y'][idx, 0, 0, 0])\n        if self.transform:\n            image = self.transform(image)\n        if self.target_transform:\n            target = self.target_transform(target)\n        return (image, target)\n\n    def _check_exists(self) -> bool:\n        images_file = self._FILES[self._split]['images'][0]\n        targets_file = self._FILES[self._split]['targets'][0]\n        return all((self._base_folder.joinpath(h5_file).exists() for h5_file in (images_file, targets_file)))\n\n    def _download(self) -> None:\n        if self._check_exists():\n            return\n        for file_name, file_id, md5 in self._FILES[self._split].values():\n            archive_name = file_name + '.gz'\n            download_file_from_google_drive(file_id, str(self._base_folder), filename=archive_name, md5=md5)\n            _decompress(str(self._base_folder / archive_name))\n\nExample skeleton:\n\n\nclass Caltech101(VisionDataset):\n    '''`Caltech 101 <https://data.caltech.edu/records/20086>`_ Dataset.\n    .. warning::\n        This class needs `scipy <https://docs.scipy.org/doc/>`_ to load target files from `.mat` format.\n    Args:\n        root (str or ``pathlib.Path``): Root directory of dataset where directory\n            ``caltech101`` exists or will be saved to if download is set to True.\n        target_type (string or list, optional): Type of target to use, ``category`` or\n            ``annotation``. Can also be a list to output a tuple with all specified\n            target types.  ``category`` represents the target class, and\n            ``annotation`` is a list of points from a hand-generated outline.\n            Defaults to ``category``.\n        transform (callable, optional): A function/transform that takes in a PIL image\n            and returns a transformed version. E.g, ``transforms.RandomCrop``\n        target_transform (callable, optional): A function/transform that takes in the\n            target and transforms it.\n        download (bool, optional): If true, downloads the dataset from the internet and\n            puts it in root directory. If dataset is already downloaded, it is not\n            downloaded again.\n            .. warning::\n                To download the dataset `gdown <https://github.com/wkentaro/gdown>`_ is required.\n    '''\n\n    def __init__(self, root: Union[str, Path], target_type: Union[list[str], str]='category', transform: Optional[Callable]=None, target_transform: Optional[Callable]=None, download: bool=False) -> None:\n        pass\n\n    def __getitem__(self, index: int) -> tuple[Any, Any]:\n        '''\n        Args:\n            index (int): Index\n        Returns:\n            tuple: (image, target) where the type of target specified by target_type.\n        '''\n        pass\n\n    def _check_integrity(self) -> bool:\n        pass\n\n    def __len__(self) -> int:\n        pass\n\n    def download(self) -> None:\n        pass\n\n    def extra_repr(self) -> str:\n        pass\nCorresponding class implementation:\n\nfrom PIL import Image\nfrom .vision import VisionDataset\nfrom typing import Any, Callable, Optional, Union\nimport shutil\nfrom pathlib import Path\nimport os\nimport os.path\nfrom .utils import download_and_extract_archive, extract_archive, verify_str_arg\n\nclass Caltech101(VisionDataset):\n    \"\"\"`Caltech 101 <https://data.caltech.edu/records/20086>`_ Dataset.\n\n    .. warning::\n\n        This class needs `scipy <https://docs.scipy.org/doc/>`_ to load target files from `.mat` format.\n\n    Args:\n        root (str or ``pathlib.Path``): Root directory of dataset where directory\n            ``caltech101`` exists or will be saved to if download is set to True.\n        target_type (string or list, optional): Type of target to use, ``category`` or\n            ``annotation``. Can also be a list to output a tuple with all specified\n            target types.  ``category`` represents the target class, and\n            ``annotation`` is a list of points from a hand-generated outline.\n            Defaults to ``category``.\n        transform (callable, optional): A function/transform that takes in a PIL image\n            and returns a transformed version. E.g, ``transforms.RandomCrop``\n        target_transform (callable, optional): A function/transform that takes in the\n            target and transforms it.\n        download (bool, optional): If true, downloads the dataset from the internet and\n            puts it in root directory. If dataset is already downloaded, it is not\n            downloaded again.\n\n            .. warning::\n\n                To download the dataset `gdown <https://github.com/wkentaro/gdown>`_ is required.\n    \"\"\"\n\n    def __init__(self, root: Union[str, Path], target_type: Union[list[str], str]='category', transform: Optional[Callable]=None, target_transform: Optional[Callable]=None, download: bool=False) -> None:\n        super().__init__(os.path.join(root, 'caltech101'), transform=transform, target_transform=target_transform)\n        os.makedirs(self.root, exist_ok=True)\n        if isinstance(target_type, str):\n            target_type = [target_type]\n        self.target_type = [verify_str_arg(t, 'target_type', ('category', 'annotation')) for t in target_type]\n        if download:\n            self.download()\n        if not self._check_integrity():\n            raise RuntimeError('Dataset not found or corrupted. You can use download=True to download it')\n        self.categories = sorted(os.listdir(os.path.join(self.root, '101_ObjectCategories')))\n        self.categories.remove('BACKGROUND_Google')\n        name_map = {'Faces': 'Faces_2', 'Faces_easy': 'Faces_3', 'Motorbikes': 'Motorbikes_16', 'airplanes': 'Airplanes_Side_2'}\n        self.annotation_categories = list(map(lambda x: name_map[x] if x in name_map else x, self.categories))\n        self.index: list[int] = []\n        self.y = []\n        for i, c in enumerate(self.categories):\n            n = len(os.listdir(os.path.join(self.root, '101_ObjectCategories', c)))\n            self.index.extend(range(1, n + 1))\n            self.y.extend(n * [i])\n\n    def __getitem__(self, index: int) -> tuple[Any, Any]:\n        \"\"\"\n        Args:\n            index (int): Index\n\n        Returns:\n            tuple: (image, target) where the type of target specified by target_type.\n        \"\"\"\n        import scipy.io\n        img = Image.open(os.path.join(self.root, '101_ObjectCategories', self.categories[self.y[index]], f'image_{self.index[index]:04d}.jpg'))\n        target: Any = []\n        for t in self.target_type:\n            if t == 'category':\n                target.append(self.y[index])\n            elif t == 'annotation':\n                data = scipy.io.loadmat(os.path.join(self.root, 'Annotations', self.annotation_categories[self.y[index]], f'annotation_{self.index[index]:04d}.mat'))\n                target.append(data['obj_contour'])\n        target = tuple(target) if len(target) > 1 else target[0]\n        if self.transform is not None:\n            img = self.transform(img)\n        if self.target_transform is not None:\n            target = self.target_transform(target)\n        return (img, target)\n\n    def _check_integrity(self) -> bool:\n        return os.path.exists(os.path.join(self.root, '101_ObjectCategories'))\n\n    def __len__(self) -> int:\n        return len(self.index)\n\n    def download(self) -> None:\n        if self._check_integrity():\n            return\n        download_and_extract_archive('https://data.caltech.edu/records/mzrjq-6wc02/files/caltech-101.zip', download_root=self.root, filename='caltech-101.zip', md5='3138e1922a9193bfa496528edbbc45d0')\n        gzip_folder = os.path.join(self.root, 'caltech-101')\n        for gzip_file in os.listdir(gzip_folder):\n            if gzip_file.endswith('.gz'):\n                extract_archive(os.path.join(gzip_folder, gzip_file), self.root)\n        shutil.rmtree(gzip_folder)\n        os.remove(os.path.join(self.root, 'caltech-101.zip'))\n\n    def extra_repr(self) -> str:\n        return 'Target type: {target_type}'.format(**self.__dict__)\n\nNow, implement the following class. Do not explain the code. The given class skeleton is as follows:\n\nclass HUBDatasetStats:\n    '''\n    A class for generating HUB dataset JSON and `-hub` dataset directory.\n    Args:\n        path (str): Path to data.yaml or data.zip (with data.yaml inside data.zip). Default is 'coco8.yaml'.\n        task (str): Dataset task. Options are 'detect', 'segment', 'pose', 'classify'. Default is 'detect'.\n        autodownload (bool): Attempt to download dataset if not found locally. Default is False.\n    Example:\n        Download *.zip files from https://github.com/ultralytics/hub/tree/main/example_datasets\n            i.e. https://github.com/ultralytics/hub/raw/main/example_datasets/coco8.zip for coco8.zip.\n        ```python\n        from ultralytics.data.utils import HUBDatasetStats\n        stats = HUBDatasetStats(\"path/to/coco8.zip\", task=\"detect\")  # detect dataset\n        stats = HUBDatasetStats(\"path/to/coco8-seg.zip\", task=\"segment\")  # segment dataset\n        stats = HUBDatasetStats(\"path/to/coco8-pose.zip\", task=\"pose\")  # pose dataset\n        stats = HUBDatasetStats(\"path/to/dota8.zip\", task=\"obb\")  # OBB dataset\n        stats = HUBDatasetStats(\"path/to/imagenet10.zip\", task=\"classify\")  # classification dataset\n        stats.get_json(save=True)\n        stats.process_images()\n        ```\n    '''\n\n    def __init__(self, path='coco8.yaml', task='detect', autodownload=False):\n        '''Initialize class.'''\n        pass\n    @staticmethod\n    def _unzip(path):\n        '''Unzip data.zip.'''\n        pass\n\n    def _hub_ops(self, f):\n        '''Saves a compressed image for HUB previews.'''\n        pass\n\n    def get_json(self, save=False, verbose=False):\n        '''Return dataset JSON for Ultralytics HUB.'''\n        pass\n\n        def _round(labels):\n                '''Update labels to integer class and 4 decimal place floats.'''\n                pass\n\n    def process_images(self):\n        '''Compress images for Ultralytics HUB.'''\n        pass"
  }
]