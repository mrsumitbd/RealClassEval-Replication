[
  {
    "role": "assistant",
    "content": "You are an expert Python programmer who can correctly implement complete Python classes based on the provided class skeleton."
  },
  {
    "role": "user",
    "content": "For your understanding, following are some (skeleton, code) examples:\n\nExample skeleton:\n\n\nclass ActorPoolStrategy(ComputeStrategy):\n    '''Specify the compute strategy for a Dataset transform.\n    ActorPoolStrategy specifies that an autoscaling pool of actors should be used\n    for a given Dataset transform. This is useful for stateful setup of callable\n    classes.\n    For a fixed-sized pool of size ``n``, specify ``compute=ActorPoolStrategy(size=n)``.\n    To autoscale from ``m`` to ``n`` actors, specify\n    ``ActorPoolStrategy(min_size=m, max_size=n)``.\n    To increase opportunities for pipelining task dependency prefetching with\n    computation and avoiding actor startup delays, set max_tasks_in_flight_per_actor\n    to 2 or greater; to try to decrease the delay due to queueing of tasks on the worker\n    actors, set max_tasks_in_flight_per_actor to 1.\n    '''\n\n    def __init__(self, *, size: Optional[int]=None, min_size: Optional[int]=None, max_size: Optional[int]=None, initial_size: Optional[int]=None, max_tasks_in_flight_per_actor: Optional[int]=None):\n        '''Construct ActorPoolStrategy for a Dataset transform.\n        Args:\n            size: Specify a fixed size actor pool of this size. It is an error to\n                specify both `size` and `min_size` or `max_size`.\n            min_size: The minimum size of the actor pool.\n            max_size: The maximum size of the actor pool.\n            initial_size: The initial number of actors to start with. If not specified,\n                defaults to min_size. Must be between min_size and max_size.\n            max_tasks_in_flight_per_actor: The maximum number of tasks to concurrently\n                send to a single actor worker. Increasing this will increase\n                opportunities for pipelining task dependency prefetching with\n                computation and avoiding actor startup delays, but will also increase\n                queueing delay.\n                                '''\n                                pass\n\n    def __eq__(self, other: Any) -> bool:\n        pass\n\n    def __repr__(self) -> str:\n        pass\nCorresponding class implementation:\n\nfrom typing import Any, Callable, Iterable, Optional, TypeVar, Union\n\nclass ActorPoolStrategy(ComputeStrategy):\n    \"\"\"Specify the compute strategy for a Dataset transform.\n\n    ActorPoolStrategy specifies that an autoscaling pool of actors should be used\n    for a given Dataset transform. This is useful for stateful setup of callable\n    classes.\n\n    For a fixed-sized pool of size ``n``, specify ``compute=ActorPoolStrategy(size=n)``.\n    To autoscale from ``m`` to ``n`` actors, specify\n    ``ActorPoolStrategy(min_size=m, max_size=n)``.\n\n    To increase opportunities for pipelining task dependency prefetching with\n    computation and avoiding actor startup delays, set max_tasks_in_flight_per_actor\n    to 2 or greater; to try to decrease the delay due to queueing of tasks on the worker\n    actors, set max_tasks_in_flight_per_actor to 1.\n    \"\"\"\n\n    def __init__(self, *, size: Optional[int]=None, min_size: Optional[int]=None, max_size: Optional[int]=None, initial_size: Optional[int]=None, max_tasks_in_flight_per_actor: Optional[int]=None):\n        \"\"\"Construct ActorPoolStrategy for a Dataset transform.\n\n        Args:\n            size: Specify a fixed size actor pool of this size. It is an error to\n                specify both `size` and `min_size` or `max_size`.\n            min_size: The minimum size of the actor pool.\n            max_size: The maximum size of the actor pool.\n            initial_size: The initial number of actors to start with. If not specified,\n                defaults to min_size. Must be between min_size and max_size.\n            max_tasks_in_flight_per_actor: The maximum number of tasks to concurrently\n                send to a single actor worker. Increasing this will increase\n                opportunities for pipelining task dependency prefetching with\n                computation and avoiding actor startup delays, but will also increase\n                queueing delay.\n        \"\"\"\n        if size is not None:\n            if size < 1:\n                raise ValueError('size must be >= 1', size)\n            if max_size is not None or min_size is not None or initial_size is not None:\n                raise ValueError('min_size, max_size, and initial_size cannot be set at the same time as `size`')\n            min_size = size\n            max_size = size\n            initial_size = size\n        if min_size is not None and min_size < 1:\n            raise ValueError('min_size must be >= 1', min_size)\n        if max_size is not None:\n            if min_size is None:\n                min_size = 1\n            if min_size > max_size:\n                raise ValueError('min_size must be <= max_size', min_size, max_size)\n        if max_tasks_in_flight_per_actor is not None and max_tasks_in_flight_per_actor < 1:\n            raise ValueError('max_tasks_in_flight_per_actor must be >= 1, got: ', max_tasks_in_flight_per_actor)\n        self.min_size = min_size or 1\n        self.max_size = max_size or float('inf')\n        if initial_size is not None:\n            if initial_size < self.min_size:\n                raise ValueError(f'initial_size ({initial_size}) must be >= min_size ({self.min_size})')\n            if self.max_size != float('inf') and initial_size > self.max_size:\n                raise ValueError(f'initial_size ({initial_size}) must be <= max_size ({self.max_size})')\n        self.initial_size = initial_size or self.min_size\n        self.max_tasks_in_flight_per_actor = max_tasks_in_flight_per_actor\n        self.num_workers = 0\n        self.ready_to_total_workers_ratio = 0.8\n\n    def __eq__(self, other: Any) -> bool:\n        return isinstance(other, ActorPoolStrategy) and (self.min_size == other.min_size and self.max_size == other.max_size and (self.initial_size == other.initial_size) and (self.max_tasks_in_flight_per_actor == other.max_tasks_in_flight_per_actor))\n\n    def __repr__(self) -> str:\n        return f'ActorPoolStrategy(min_size={self.min_size}, max_size={self.max_size}, initial_size={self.initial_size}, max_tasks_in_flight_per_actor={self.max_tasks_in_flight_per_actor})num_workers={self.num_workers}, ready_to_total_workers_ratio={self.ready_to_total_workers_ratio})'\n\nExample skeleton:\n\n\nclass SabrePreLayout(AnalysisPass):\n    '''Choose a starting layout to use for additional Sabre layout trials.\n    Property Set Values Written\n    ---------------------------\n    ``sabre_starting_layouts`` (``list[Layout]``)\n        An optional list of :class:`~.Layout` objects to use for additional Sabre layout trials.\n    **References:**\n    [1] Henry Zou and Matthew Treinish and Kevin Hartman and Alexander Ivrii and Jake Lishman.\n    \"LightSABRE: A Lightweight and Enhanced SABRE Algorithm\"\n    `arXiv:2409.08368 <https://doi.org/10.48550/arXiv.2409.08368>`__\n    '''\n\n    def __init__(self, coupling_map, max_distance=2, error_rate=0.1, max_trials_vf2=100, call_limit_vf2=None, improve_layout=True):\n        '''SabrePreLayout initializer.\n        The pass works by augmenting the coupling map with more and more \"extra\" edges\n        until VF2 succeeds to find a perfect graph isomorphism. More precisely, the\n        augmented coupling map contains edges between nodes that are within a given\n        distance ``d`` in the original coupling map, and the value of ``d`` is increased\n        until an isomorphism is found.\n        Intuitively, a better layout involves fewer extra edges. The pass also optionally\n        minimizes the number of extra edges involved in the layout until a local minimum\n        is found. This involves removing extra edges and running VF2 to see if an\n        isomorphism still exists.\n        Args:\n            coupling_map (Union[CouplingMap, Target]): directed graph representing the\n                original coupling map or a target modelling the backend (including its\n                connectivity).\n            max_distance (int): the maximum distance to consider for augmented coupling maps.\n            error_rate (float): the error rate to assign to the \"extra\" edges. A non-zero\n                error rate prioritizes VF2 to choose original edges over extra edges.\n            max_trials_vf2 (int): specifies the maximum number of VF2 trials. A larger number\n                allows VF2 to explore more layouts, eventually choosing the one with the smallest\n                error rate.\n            call_limit_vf2 (int): limits each call to VF2 by bounding the number of VF2 state visits.\n            improve_layout (bool): whether to improve the layout by minimizing the number of\n                extra edges involved. This might be time-consuming as this requires additional\n                VF2 calls.\n        Raises:\n            TranspilerError: At runtime, if neither ``coupling_map`` or ``target`` are provided.\n        '''\n        pass\n\n    def run(self, dag):\n        '''Run the SabrePreLayout pass on `dag`.\n        The discovered starting layout is written to the property set\n        value ``sabre_starting_layouts``.\n        Args:\n            dag (DAGCircuit): DAG to create starting layout for.\n        '''\n        pass\n\n    def _add_extra_edges(self, distance):\n        '''Augments the coupling map with extra edges that connect nodes ``distance``\n        apart in the original graph. The extra edges are assigned errors allowing VF2\n        to prioritize real edges over extra edges.\n        '''\n        pass\n\n    def _get_extra_edges_used(self, dag, layout):\n        '''Returns the set of extra edges involved in the layout.'''\n        pass\n\n    def _find_layout(self, dag, edges):\n        '''Checks if there is a layout for a given set of edges.'''\n        pass\n\n    def _minimize_extra_edges(self, dag, starting_layout):\n        '''Minimizes the set of extra edges involved in the layout. This iteratively\n        removes extra edges from the coupling map and uses VF2 to check if a layout\n        still exists. This is reasonably efficiently as it only looks for a local\n        minimum.\n        '''\n        pass\nCorresponding class implementation:\n\nfrom qiskit._accelerate.error_map import ErrorMap\nimport itertools\nfrom qiskit.transpiler.target import Target\nfrom qiskit.transpiler.basepasses import AnalysisPass\nfrom qiskit.transpiler.exceptions import TranspilerError\nfrom qiskit.transpiler.coupling import CouplingMap\nfrom qiskit.transpiler.passes.layout.vf2_layout import VF2Layout\n\nclass SabrePreLayout(AnalysisPass):\n    \"\"\"Choose a starting layout to use for additional Sabre layout trials.\n\n    Property Set Values Written\n    ---------------------------\n\n    ``sabre_starting_layouts`` (``list[Layout]``)\n        An optional list of :class:`~.Layout` objects to use for additional Sabre layout trials.\n\n    **References:**\n\n    [1] Henry Zou and Matthew Treinish and Kevin Hartman and Alexander Ivrii and Jake Lishman.\n    \"LightSABRE: A Lightweight and Enhanced SABRE Algorithm\"\n    `arXiv:2409.08368 <https://doi.org/10.48550/arXiv.2409.08368>`__\n    \"\"\"\n\n    def __init__(self, coupling_map, max_distance=2, error_rate=0.1, max_trials_vf2=100, call_limit_vf2=None, improve_layout=True):\n        \"\"\"SabrePreLayout initializer.\n\n        The pass works by augmenting the coupling map with more and more \"extra\" edges\n        until VF2 succeeds to find a perfect graph isomorphism. More precisely, the\n        augmented coupling map contains edges between nodes that are within a given\n        distance ``d`` in the original coupling map, and the value of ``d`` is increased\n        until an isomorphism is found.\n\n        Intuitively, a better layout involves fewer extra edges. The pass also optionally\n        minimizes the number of extra edges involved in the layout until a local minimum\n        is found. This involves removing extra edges and running VF2 to see if an\n        isomorphism still exists.\n\n        Args:\n            coupling_map (Union[CouplingMap, Target]): directed graph representing the\n                original coupling map or a target modelling the backend (including its\n                connectivity).\n            max_distance (int): the maximum distance to consider for augmented coupling maps.\n            error_rate (float): the error rate to assign to the \"extra\" edges. A non-zero\n                error rate prioritizes VF2 to choose original edges over extra edges.\n            max_trials_vf2 (int): specifies the maximum number of VF2 trials. A larger number\n                allows VF2 to explore more layouts, eventually choosing the one with the smallest\n                error rate.\n            call_limit_vf2 (int): limits each call to VF2 by bounding the number of VF2 state visits.\n            improve_layout (bool): whether to improve the layout by minimizing the number of\n                extra edges involved. This might be time-consuming as this requires additional\n                VF2 calls.\n\n        Raises:\n            TranspilerError: At runtime, if neither ``coupling_map`` or ``target`` are provided.\n        \"\"\"\n        self.max_distance = max_distance\n        self.error_rate = error_rate\n        self.max_trials_vf2 = max_trials_vf2\n        self.call_limit_vf2 = call_limit_vf2\n        self.improve_layout = improve_layout\n        if isinstance(coupling_map, Target):\n            self.target = coupling_map\n            self.coupling_map = self.target.build_coupling_map()\n        else:\n            self.target = None\n            self.coupling_map = coupling_map\n        super().__init__()\n\n    def run(self, dag):\n        \"\"\"Run the SabrePreLayout pass on `dag`.\n\n        The discovered starting layout is written to the property set\n        value ``sabre_starting_layouts``.\n\n        Args:\n            dag (DAGCircuit): DAG to create starting layout for.\n        \"\"\"\n        if self.coupling_map is None:\n            raise TranspilerError('SabrePreLayout requires coupling_map to be used with eitherCouplingMap or a Target.')\n        starting_layout = None\n        cur_distance = 1\n        while cur_distance <= self.max_distance:\n            augmented_map, augmented_error_map = self._add_extra_edges(cur_distance)\n            pass_ = VF2Layout(augmented_map, seed=-1, max_trials=self.max_trials_vf2, call_limit=self.call_limit_vf2)\n            pass_.property_set['vf2_avg_error_map'] = augmented_error_map\n            pass_.run(dag)\n            if 'layout' in pass_.property_set:\n                starting_layout = pass_.property_set['layout']\n                break\n            cur_distance += 1\n        if cur_distance > 1 and starting_layout is not None:\n            if self.improve_layout:\n                starting_layout = self._minimize_extra_edges(dag, starting_layout)\n            if 'sabre_starting_layouts' not in self.property_set:\n                self.property_set['sabre_starting_layouts'] = [starting_layout]\n            else:\n                self.property_set['sabre_starting_layouts'].append(starting_layout)\n\n    def _add_extra_edges(self, distance):\n        \"\"\"Augments the coupling map with extra edges that connect nodes ``distance``\n        apart in the original graph. The extra edges are assigned errors allowing VF2\n        to prioritize real edges over extra edges.\n        \"\"\"\n        nq = len(self.coupling_map.graph)\n        augmented_coupling_map = CouplingMap()\n        augmented_coupling_map.graph = self.coupling_map.graph.copy()\n        augmented_error_map = ErrorMap(nq)\n        for x, y in itertools.combinations(self.coupling_map.graph.node_indices(), 2):\n            d = self.coupling_map.distance(x, y)\n            if 1 < d <= distance:\n                error_rate = 1 - (1 - self.error_rate) ** d\n                augmented_coupling_map.add_edge(x, y)\n                augmented_error_map.add_error((x, y), error_rate)\n                augmented_coupling_map.add_edge(y, x)\n                augmented_error_map.add_error((y, x), error_rate)\n        return (augmented_coupling_map, augmented_error_map)\n\n    def _get_extra_edges_used(self, dag, layout):\n        \"\"\"Returns the set of extra edges involved in the layout.\"\"\"\n        extra_edges_used = set()\n        virtual_bits = layout.get_virtual_bits()\n        for node in dag.two_qubit_ops():\n            p0 = virtual_bits[node.qargs[0]]\n            p1 = virtual_bits[node.qargs[1]]\n            if self.coupling_map.distance(p0, p1) > 1:\n                extra_edge = (p0, p1) if p0 < p1 else (p1, p0)\n                extra_edges_used.add(extra_edge)\n        return extra_edges_used\n\n    def _find_layout(self, dag, edges):\n        \"\"\"Checks if there is a layout for a given set of edges.\"\"\"\n        cm = CouplingMap(edges)\n        pass_ = VF2Layout(cm, seed=0, max_trials=1, call_limit=self.call_limit_vf2)\n        pass_.run(dag)\n        return pass_.property_set.get('layout', None)\n\n    def _minimize_extra_edges(self, dag, starting_layout):\n        \"\"\"Minimizes the set of extra edges involved in the layout. This iteratively\n        removes extra edges from the coupling map and uses VF2 to check if a layout\n        still exists. This is reasonably efficiently as it only looks for a local\n        minimum.\n        \"\"\"\n        real_edges = []\n        for x, y in itertools.combinations(self.coupling_map.graph.node_indices(), 2):\n            d = self.coupling_map.distance(x, y)\n            if d == 1:\n                real_edges.append((x, y))\n        best_layout = starting_layout\n        extra_edges_necessary = []\n        extra_edges_unprocessed_set = self._get_extra_edges_used(dag, starting_layout)\n        while extra_edges_unprocessed_set:\n            edge_chosen = next(iter(extra_edges_unprocessed_set))\n            extra_edges_unprocessed_set.remove(edge_chosen)\n            layout = self._find_layout(dag, real_edges + extra_edges_necessary + list(extra_edges_unprocessed_set))\n            if layout is None:\n                extra_edges_necessary.append(edge_chosen)\n            else:\n                extra_edges_unprocessed_set = self._get_extra_edges_used(dag, layout).difference(set(extra_edges_necessary))\n                best_layout = layout\n        return best_layout\n\nNow, implement the following class. Do not explain the code. The given class skeleton is as follows:\n\nclass DeployRay:\n    '''A class for managing Ray deployment and serving of models.\n    This class provides functionality to initialize Ray, start Ray Serve,\n    deploy models, and manage the lifecycle of the Ray cluster. It supports\n    both NeMo inframework models, Hugging Face models, and TensorRT-LLM models.\n    Attributes:\n        address (str): The address of the Ray cluster to connect to.\n        num_cpus (int): Number of CPUs to allocate for the Ray cluster.\n        num_gpus (int): Number of GPUs to allocate for the Ray cluster.\n        include_dashboard (bool): Whether to include the Ray dashboard.\n        ignore_reinit_error (bool): Whether to ignore errors when reinitializing Ray.\n        runtime_env (dict): Runtime environment configuration for Ray.\n        host (str): Host address to bind the server to.\n        port (int): Port number for the server.\n    Methods:\n        deploy_inframework_model: Deploy a NeMo inframework model using Ray Serve.\n        deploy_huggingface_model: Deploy a Hugging Face model using Ray Serve.\n        deploy_tensorrt_llm_model: Deploy a TensorRT-LLM model using Ray Serve.\n    '''\n\n    def __init__(self, address: str='auto', num_cpus: Optional[int]=None, num_gpus: int=1, include_dashboard: bool=False, ignore_reinit_error: bool=True, runtime_env: dict=None, host: str='0.0.0.0', port: Optional[int]=None):\n        '''Initialize the DeployRay instance and set up the Ray cluster.\n        Args:\n            address (str, optional): Address of the Ray cluster. Defaults to \"auto\".\n            num_cpus (int, optional): Number of CPUs to allocate. If None, uses all available. Defaults to None.\n            num_gpus (int, optional): Number of GPUs to allocate. Defaults to 1.\n            include_dashboard (bool, optional): Whether to include the dashboard. Defaults to False.\n            ignore_reinit_error (bool, optional): Whether to ignore reinit errors. Defaults to True.\n            runtime_env (dict, optional): Runtime environment configuration. Defaults to None.\n            host (str, optional): Host address to bind the server to. Defaults to \"0.0.0.0\".\n            port (int, optional): Port number for the server. If None, an available port will be found. Defaults to None.\n        Raises:\n            Exception: If Ray is not installed.\n        '''\n        pass\n\n    def _signal_handler(self, signum, frame):\n        '''Handle signal interrupts and gracefully shutdown the deployer.'''\n        pass\n\n    def _start(self):\n        '''Start Ray Serve with the configured host and port.\n        Uses the host and port specified during DeployRay initialization.\n        If port is None, an available port will be found automatically.\n        '''\n        pass\n\n    def _stop(self):\n        '''Stop the Ray Serve deployment and shutdown the Ray cluster.\n        This method attempts to gracefully shutdown both Ray Serve and the Ray cluster.\n        If any errors occur during shutdown, they are logged as warnings.\n        '''\n        pass\n\n    def deploy_inframework_model(self, nemo_checkpoint: str, num_gpus: int=1, tensor_model_parallel_size: int=1, pipeline_model_parallel_size: int=1, expert_model_parallel_size: int=1, context_parallel_size: int=1, model_id: str='nemo-model', num_cpus_per_replica: float=8, num_replicas: int=1, enable_cuda_graphs: bool=False, enable_flash_decode: bool=False, legacy_ckpt: bool=False, max_batch_size: int=32, random_seed: Optional[int]=None, test_mode: bool=False, megatron_checkpoint_filepath: str=None, model_type: str='gpt', model_format: str='nemo', micro_batch_size: Optional[int]=None):\n        '''Deploy an inframework NeMo/Megatron model using Ray Serve.\n        This method handles the complete deployment lifecycle including:\n        - Starting Ray Serve\n        - Creating and deploying the MegatronRayDeployable\n        - Setting up signal handlers for graceful shutdown\n        - Keeping the deployment running until interrupted\n        Args:\n            nemo_checkpoint (str): Path to the .nemo checkpoint file.\n            num_gpus (int, optional): Number of GPUs per node. Defaults to 1.\n            tensor_model_parallel_size (int, optional): Tensor model parallel size. Defaults to 1.\n            pipeline_model_parallel_size (int, optional): Pipeline model parallel size. Defaults to 1.\n            expert_model_parallel_size (int, optional): Expert model parallel size. Defaults to 1.\n            context_parallel_size (int, optional): Context parallel size. Defaults to 1.\n            model_id (str, optional): Model identifier for API responses. Defaults to \"nemo-model\".\n            num_cpus_per_replica (float, optional): CPUs per model replica. Defaults to 8.\n            num_replicas (int, optional): Number of replicas for deployment. Defaults to 1.\n            enable_cuda_graphs (bool, optional): Enable CUDA graphs. Defaults to False.\n            enable_flash_decode (bool, optional): Enable Flash Attention decode. Defaults to False.\n            legacy_ckpt (bool, optional): Use legacy checkpoint format. Defaults to False.\n            test_mode (bool, optional): Enable test mode. Defaults to False.\n            megatron_checkpoint_filepath (str, optional): Path to the Megatron checkpoint file. Defaults to None.\n            model_type (str, optional): Type of model to load. Defaults to \"gpt\".\n            model_format (str, optional): Format of model to load. Defaults to \"nemo\".\n            micro_batch_size (Optional[int], optional): Micro batch size for model execution. Defaults to None.\n        Raises:\n            SystemExit: If parallelism configuration is invalid.\n            Exception: If deployment fails.\n        '''\n        pass\n\n    def deploy_huggingface_model(self, hf_model_id_path: str, task: str='text-generation', trust_remote_code: bool=True, device_map: Optional[str]=None, max_memory: Optional[str]=None, model_id: str='hf-model', num_replicas: int=1, num_cpus_per_replica: float=8, num_gpus_per_replica: int=1, max_ongoing_requests: int=10, use_vllm_backend: bool=False, test_mode: bool=False):\n        '''Deploy a Hugging Face model using Ray Serve.\n        This method handles the complete deployment lifecycle including:\n        - Starting Ray Serve\n        - Creating and deploying the HFRayDeployable\n        - Setting up signal handlers for graceful shutdown\n        - Keeping the deployment running until interrupted\n        Args:\n            hf_model_id_path (str): Path to the HuggingFace model or model identifier.\n                Can be a local path or a model ID from HuggingFace Hub.\n            task (str, optional): HuggingFace task type. Defaults to \"text-generation\".\n            trust_remote_code (bool, optional): Whether to trust remote code when loading the model. Defaults to True.\n            device_map (str, optional): Device mapping strategy for model placement. Defaults to \"auto\".\n            max_memory (str, optional): Maximum memory allocation when using balanced device map. Defaults to None.\n            model_id (str, optional): Model identifier for API responses. Defaults to \"hf-model\".\n            num_replicas (int, optional): Number of replicas for deployment. Defaults to 1.\n            num_cpus_per_replica (float, optional): CPUs per model replica. Defaults to 8.\n            num_gpus_per_replica (int, optional): GPUs per model replica. Defaults to 1.\n            max_ongoing_requests (int, optional): Maximum number of ongoing requests per replica. Defaults to 10.\n            use_vllm_backend (bool, optional): Whether to use vLLM backend for deployment. If True, exports the HF ckpt\n            to vLLM format and uses vLLM backend for inference. Defaults to False.\n            test_mode (bool, optional): Enable test mode. Defaults to False.\n        Raises:\n            Exception: If Ray is not installed or deployment fails.\n        '''\n        pass\n\n    def deploy_tensorrt_llm_model(self, trt_llm_path: str, model_id: str='tensorrt-llm-model', use_python_runtime: bool=True, multi_block_mode: bool=False, lora_ckpt_list: Optional[list]=None, enable_chunked_context: bool=False, max_tokens_in_paged_kv_cache: Optional[int]=None, num_replicas: int=1, num_cpus_per_replica: float=8, num_gpus_per_replica: int=1, max_ongoing_requests: int=10, test_mode: bool=False):\n        '''Deploy a TensorRT-LLM model using Ray Serve.\n        This method handles the complete deployment lifecycle including:\n        - Starting Ray Serve\n        - Creating and deploying the TensorRTLLMRayDeployable\n        - Setting up signal handlers for graceful shutdown\n        - Keeping the deployment running until interrupted\n        Note: This method assumes the model is already converted to TensorRT-LLM format.\n        The conversion should be done before calling this API.\n        Args:\n            trt_llm_path (str): Path to the TensorRT-LLM model directory with pre-built engines.\n            model_id (str, optional): Model identifier for API responses. Defaults to \"tensorrt-llm-model\".\n            use_python_runtime (bool, optional): Whether to use Python runtime (vs C++ runtime). Defaults to True.\n            multi_block_mode (bool, optional): Whether to enable multi-block mode. Defaults to False.\n            lora_ckpt_list (list, optional): List of LoRA checkpoint paths. Defaults to None.\n            enable_chunked_context (bool, optional): Whether to enable chunked context (C++ runtime only). Defaults to False.\n            max_tokens_in_paged_kv_cache (int, optional): Maximum tokens in paged KV cache (C++ runtime only). Defaults to None.\n            num_replicas (int, optional): Number of replicas for deployment. Defaults to 1.\n            num_cpus_per_replica (float, optional): CPUs per model replica. Defaults to 8.\n            num_gpus_per_replica (int, optional): GPUs per model replica. Defaults to 1.\n            max_ongoing_requests (int, optional): Maximum number of ongoing requests per replica. Defaults to 10.\n            test_mode (bool, optional): Enable test mode. Defaults to False.\n        Raises:\n            Exception: If Ray is not installed or deployment fails.\n            ValueError: If C++ runtime specific options are used with Python runtime.\n        '''\n        pass"
  }
]