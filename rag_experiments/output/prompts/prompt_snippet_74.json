[
  {
    "role": "assistant",
    "content": "You are an expert Python programmer who can correctly implement complete Python classes based on the provided class skeleton."
  },
  {
    "role": "user",
    "content": "For your understanding, following are some (skeleton, code) examples:\n\nExample skeleton:\n\n\nclass ReMoClient(HttpClient):\n    '''ReMo API client.\n    This class implements a simple client to retrieve events from\n    projects in a ReMo site.\n    :param url: URL of ReMo (sample https://reps.mozilla.org)\n    :param archive: an archive to store/read fetched data\n    :param from_archive: it tells whether to write/read the archive\n    :param ssl_verify: enable/disable SSL verification\n    :raises HTTPError: when an error occurs doing the request\n    '''\n\n    def __init__(self, url, archive=None, from_archive=False, ssl_verify=True):\n        pass\n\n    def get_items(self, category=CATEGORY_EVENT, offset=REMO_DEFAULT_OFFSET):\n        '''Retrieve all items for category using pagination '''\n        pass\n\n    def fetch(self, url, payload=None):\n        '''Return the textual content associated to the Response object'''\n        pass\nCorresponding class implementation:\n\nfrom ...client import HttpClient\nimport urllib.parse\nfrom grimoirelab_toolkit.uris import urijoin\nimport json\n\nclass ReMoClient(HttpClient):\n    \"\"\"ReMo API client.\n\n    This class implements a simple client to retrieve events from\n    projects in a ReMo site.\n\n    :param url: URL of ReMo (sample https://reps.mozilla.org)\n    :param archive: an archive to store/read fetched data\n    :param from_archive: it tells whether to write/read the archive\n    :param ssl_verify: enable/disable SSL verification\n\n    :raises HTTPError: when an error occurs doing the request\n    \"\"\"\n    FIRST_PAGE = 1\n    ITEMS_PER_PAGE = 20\n    API_PATH = '/api/remo/v1'\n\n    def __init__(self, url, archive=None, from_archive=False, ssl_verify=True):\n        super().__init__(url, archive=archive, from_archive=from_archive, ssl_verify=ssl_verify)\n        self.api_activities_url = urijoin(self.base_url, ReMoClient.API_PATH + '/activities/')\n        self.api_activities_url += '/'\n        self.api_events_url = urijoin(self.base_url, ReMoClient.API_PATH + '/events/')\n        self.api_events_url += '/'\n        self.api_users_url = urijoin(self.base_url, ReMoClient.API_PATH + '/users/')\n        self.api_users_url += '/'\n\n    def get_items(self, category=CATEGORY_EVENT, offset=REMO_DEFAULT_OFFSET):\n        \"\"\"Retrieve all items for category using pagination \"\"\"\n        more = True\n        next_uri = None\n        page = ReMoClient.FIRST_PAGE\n        page += int(offset / ReMoClient.ITEMS_PER_PAGE)\n        if category == CATEGORY_EVENT:\n            api = self.api_events_url\n        elif category == CATEGORY_ACTIVITY:\n            api = self.api_activities_url\n        elif category == CATEGORY_USER:\n            api = self.api_users_url\n        else:\n            raise ValueError(category + ' not supported in ReMo')\n        while more:\n            params = {'page': page, 'orderby': 'ASC'}\n            logger.debug('ReMo client calls APIv2: %s params: %s', api, str(params))\n            raw_items = self.fetch(api, payload=params)\n            yield raw_items\n            items_data = json.loads(raw_items)\n            next_uri = items_data['next']\n            if not next_uri:\n                more = False\n            else:\n                parsed_uri = urllib.parse.urlparse(next_uri)\n                parsed_params = urllib.parse.parse_qs(parsed_uri.query)\n                page = parsed_params['page'][0]\n\n    def fetch(self, url, payload=None):\n        \"\"\"Return the textual content associated to the Response object\"\"\"\n        response = super().fetch(url, payload)\n        return response.text\n\nExample skeleton:\n\n\nclass GCPCompute(GCPResource):\n    '''Abstraction around GCP compute resource'''\n\n    def get_new_authorized_http(self, http: AuthorizedHttp) -> AuthorizedHttp:\n        '''Generate a new AuthorizedHttp object with the given credentials.'''\n        pass\n\n    def wait_for_operation(self, operation: dict, max_polls: int=MAX_POLLS, poll_interval: int=POLL_INTERVAL) -> dict:\n        '''Poll for compute zone operation until finished.'''\n        pass\n\n    def list_instances(self, label_filters: Optional[dict]=None, is_terminated: bool=False) -> List[GCPComputeNode]:\n        pass\n\n    def get_instance(self, node_id: str) -> GCPComputeNode:\n        pass\n\n    def set_labels(self, node: GCPComputeNode, labels: dict, wait_for_operation: bool=True) -> dict:\n        pass\n\n    def _convert_resources_to_urls(self, configuration_dict: Dict[str, Any]) -> Dict[str, Any]:\n        '''Ensures that resources are in their full URL form.\n        GCP expects machineType and acceleratorType to be a full URL (e.g.\n        `zones/us-west1/machineTypes/n1-standard-2`) instead of just the\n        type (`n1-standard-2`)\n        Args:\n            configuration_dict: Dict of options that will be passed to GCP\n        Returns:\n            Input dictionary, but with possibly expanding `machineType` and\n                `acceleratorType`.\n        '''\n        pass\n\n    def create_instance(self, base_config: dict, labels: dict, wait_for_operation: bool=True) -> Tuple[dict, str]:\n        pass\n\n    def delete_instance(self, node_id: str, wait_for_operation: bool=True) -> dict:\n        pass\n\n    def stop_instance(self, node_id: str, wait_for_operation: bool=True) -> dict:\n        pass\n\n    def start_instance(self, node_id: str, wait_for_operation: bool=True) -> dict:\n        pass\nCorresponding class implementation:\n\nfrom copy import deepcopy\nimport time\nimport httplib2\nfrom typing import Any, Dict, List, Optional, Tuple, Union\nimport re\nfrom ray.autoscaler.tags import TAG_RAY_CLUSTER_NAME, TAG_RAY_NODE_NAME\nfrom google_auth_httplib2 import AuthorizedHttp\n\nclass GCPCompute(GCPResource):\n    \"\"\"Abstraction around GCP compute resource\"\"\"\n\n    def get_new_authorized_http(self, http: AuthorizedHttp) -> AuthorizedHttp:\n        \"\"\"Generate a new AuthorizedHttp object with the given credentials.\"\"\"\n        new_http = AuthorizedHttp(http.credentials, http=httplib2.Http())\n        return new_http\n\n    def wait_for_operation(self, operation: dict, max_polls: int=MAX_POLLS, poll_interval: int=POLL_INTERVAL) -> dict:\n        \"\"\"Poll for compute zone operation until finished.\"\"\"\n        logger.info(f\"wait_for_compute_zone_operation: Waiting for operation {operation['name']} to finish...\")\n        for _ in range(max_polls):\n            result = self.resource.zoneOperations().get(project=self.project_id, operation=operation['name'], zone=self.availability_zone).execute(http=self.get_new_authorized_http(self.resource._http))\n            if 'error' in result:\n                raise Exception(result['error'])\n            if result['status'] == 'DONE':\n                logger.info(f\"wait_for_compute_zone_operation: Operation {operation['name']} finished.\")\n                break\n            time.sleep(poll_interval)\n        return result\n\n    def list_instances(self, label_filters: Optional[dict]=None, is_terminated: bool=False) -> List[GCPComputeNode]:\n        label_filters = label_filters or {}\n        if label_filters:\n            label_filter_expr = '(' + ' AND '.join(['(labels.{key} = {value})'.format(key=key, value=value) for key, value in label_filters.items()]) + ')'\n        else:\n            label_filter_expr = ''\n        statuses = GCPComputeNode.TERMINATED_STATUSES if is_terminated else GCPComputeNode.NON_TERMINATED_STATUSES\n        instance_state_filter_expr = '(' + ' OR '.join(['(status = {status})'.format(status=status) for status in statuses]) + ')'\n        cluster_name_filter_expr = '(labels.{key} = {value})'.format(key=TAG_RAY_CLUSTER_NAME, value=self.cluster_name)\n        tpu_negation_filter_expr = '(NOT labels.{label}:*)'.format(label='tpu_cores')\n        not_empty_filters = [f for f in [label_filter_expr, instance_state_filter_expr, cluster_name_filter_expr, tpu_negation_filter_expr] if f]\n        filter_expr = ' AND '.join(not_empty_filters)\n        response = self.resource.instances().list(project=self.project_id, zone=self.availability_zone, filter=filter_expr).execute(http=self.get_new_authorized_http(self.resource._http))\n        instances = response.get('items', [])\n        return [GCPComputeNode(i, self) for i in instances]\n\n    def get_instance(self, node_id: str) -> GCPComputeNode:\n        instance = self.resource.instances().get(project=self.project_id, zone=self.availability_zone, instance=node_id).execute()\n        return GCPComputeNode(instance, self)\n\n    def set_labels(self, node: GCPComputeNode, labels: dict, wait_for_operation: bool=True) -> dict:\n        body = {'labels': dict(node['labels'], **labels), 'labelFingerprint': node['labelFingerprint']}\n        node_id = node['name']\n        operation = self.resource.instances().setLabels(project=self.project_id, zone=self.availability_zone, instance=node_id, body=body).execute(http=self.get_new_authorized_http(self.resource._http))\n        if wait_for_operation:\n            result = self.wait_for_operation(operation)\n        else:\n            result = operation\n        return result\n\n    def _convert_resources_to_urls(self, configuration_dict: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Ensures that resources are in their full URL form.\n\n        GCP expects machineType and acceleratorType to be a full URL (e.g.\n        `zones/us-west1/machineTypes/n1-standard-2`) instead of just the\n        type (`n1-standard-2`)\n\n        Args:\n            configuration_dict: Dict of options that will be passed to GCP\n        Returns:\n            Input dictionary, but with possibly expanding `machineType` and\n                `acceleratorType`.\n        \"\"\"\n        configuration_dict = deepcopy(configuration_dict)\n        existing_machine_type = configuration_dict['machineType']\n        if not re.search('.*/machineTypes/.*', existing_machine_type):\n            configuration_dict['machineType'] = 'zones/{zone}/machineTypes/{machine_type}'.format(zone=self.availability_zone, machine_type=configuration_dict['machineType'])\n        for accelerator in configuration_dict.get('guestAccelerators', []):\n            gpu_type = accelerator['acceleratorType']\n            if not re.search('.*/acceleratorTypes/.*', gpu_type):\n                accelerator['acceleratorType'] = 'projects/{project}/zones/{zone}/acceleratorTypes/{accelerator}'.format(project=self.project_id, zone=self.availability_zone, accelerator=gpu_type)\n        return configuration_dict\n\n    def create_instance(self, base_config: dict, labels: dict, wait_for_operation: bool=True) -> Tuple[dict, str]:\n        config = self._convert_resources_to_urls(base_config)\n        config.pop('networkConfig', None)\n        name = _generate_node_name(labels, GCPNodeType.COMPUTE.value)\n        labels = dict(config.get('labels', {}), **labels)\n        config.update({'labels': dict(labels, **{TAG_RAY_CLUSTER_NAME: self.cluster_name}), 'name': name})\n        source_instance_template = config.pop('sourceInstanceTemplate', None)\n        operation = self.resource.instances().insert(project=self.project_id, zone=self.availability_zone, sourceInstanceTemplate=source_instance_template, body=config).execute(http=self.get_new_authorized_http(self.resource._http))\n        if wait_for_operation:\n            result = self.wait_for_operation(operation)\n        else:\n            result = operation\n        return (result, name)\n\n    def delete_instance(self, node_id: str, wait_for_operation: bool=True) -> dict:\n        operation = self.resource.instances().delete(project=self.project_id, zone=self.availability_zone, instance=node_id).execute()\n        if wait_for_operation:\n            result = self.wait_for_operation(operation)\n        else:\n            result = operation\n        return result\n\n    def stop_instance(self, node_id: str, wait_for_operation: bool=True) -> dict:\n        operation = self.resource.instances().stop(project=self.project_id, zone=self.availability_zone, instance=node_id).execute()\n        if wait_for_operation:\n            result = self.wait_for_operation(operation)\n        else:\n            result = operation\n        return result\n\n    def start_instance(self, node_id: str, wait_for_operation: bool=True) -> dict:\n        operation = self.resource.instances().start(project=self.project_id, zone=self.availability_zone, instance=node_id).execute(http=self.get_new_authorized_http(self.resource._http))\n        if wait_for_operation:\n            result = self.wait_for_operation(operation)\n        else:\n            result = operation\n        return result\n\nNow, implement the following class. Do not explain the code. The given class skeleton is as follows:\n\nclass BochaAISearchRetriever:\n    '''BochaAI retriever that converts search results into TextualMemoryItem objects'''\n\n    def __init__(self, access_key: str, embedder: OllamaEmbedder, reader: BaseMemReader, max_results: int=20):\n        '''\n        Initialize BochaAI Search retriever.\n        Args:\n            access_key: BochaAI API key\n            embedder: Embedder instance for generating embeddings\n            reader: MemReader instance for processing internet content\n            max_results: Maximum number of search results to retrieve\n        '''\n        pass\n\n    def retrieve_from_internet(self, query: str, top_k: int=10, parsed_goal=None, info=None) -> list[TextualMemoryItem]:\n        '''\n        Default internet retrieval (Web Search).\n        This keeps consistent API with Xinyu and Google retrievers.\n        Args:\n            query: Search query\n            top_k: Number of results to retrieve\n            parsed_goal: Parsed task goal (optional)\n            info (dict): Metadata for memory consumption tracking\n        Returns:\n            List of TextualMemoryItem\n        '''\n        pass\n\n    def retrieve_from_web(self, query: str, top_k: int=10, parsed_goal=None, info=None) -> list[TextualMemoryItem]:\n        '''Explicitly retrieve using Bocha Web Search.'''\n        pass\n\n    def retrieve_from_ai(self, query: str, top_k: int=10, parsed_goal=None, info=None) -> list[TextualMemoryItem]:\n        '''Explicitly retrieve using Bocha AI Search.'''\n        pass\n\n    def _convert_to_mem_items(self, search_results: list[dict], query: str, parsed_goal=None, info=None):\n        '''Convert API search results into TextualMemoryItem objects.'''\n        pass\n\n    def _process_result(self, result: dict, query: str, parsed_goal: str, info: None) -> list[TextualMemoryItem]:\n        '''Process one Bocha search result into TextualMemoryItem.'''\n        pass"
  }
]