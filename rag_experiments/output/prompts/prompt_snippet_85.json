[
  {
    "role": "assistant",
    "content": "You are an expert Python programmer who can correctly implement complete Python classes based on the provided class skeleton."
  },
  {
    "role": "user",
    "content": "For your understanding, following are some (skeleton, code) examples:\n\nExample skeleton:\n\n\nclass PCAM(VisionDataset):\n    '''`PCAM Dataset   <https://github.com/basveeling/pcam>`_.\n    The PatchCamelyon dataset is a binary classification dataset with 327,680\n    color images (96px x 96px), extracted from histopathologic scans of lymph node\n    sections. Each image is annotated with a binary label indicating presence of\n    metastatic tissue.\n    This dataset requires the ``h5py`` package which you can install with ``pip install h5py``.\n    Args:\n         root (str or ``pathlib.Path``): Root directory of the dataset.\n         split (string, optional): The dataset split, supports ``\"train\"`` (default), ``\"test\"`` or ``\"val\"``.\n         transform (callable, optional): A function/transform that takes in a PIL image and returns a transformed\n             version. E.g, ``transforms.RandomCrop``.\n         target_transform (callable, optional): A function/transform that takes in the target and transforms it.\n         download (bool, optional): If True, downloads the dataset from the internet and puts it into ``root/pcam``. If\n             dataset is already downloaded, it is not downloaded again.\n             .. warning::\n                To download the dataset `gdown <https://github.com/wkentaro/gdown>`_ is required.\n    '''\n\n    def __init__(self, root: Union[str, pathlib.Path], split: str='train', transform: Optional[Callable]=None, target_transform: Optional[Callable]=None, download: bool=False):\n        pass\n\n    def __len__(self) -> int:\n        pass\n\n    def __getitem__(self, idx: int) -> tuple[Any, Any]:\n        pass\n\n    def _check_exists(self) -> bool:\n        pass\n\n    def _download(self) -> None:\n        pass\nCorresponding class implementation:\n\nfrom typing import Any, Callable, Optional, Union\nimport pathlib\nfrom .vision import VisionDataset\nfrom PIL import Image\nfrom .utils import _decompress, download_file_from_google_drive, verify_str_arg\n\nclass PCAM(VisionDataset):\n    \"\"\"`PCAM Dataset   <https://github.com/basveeling/pcam>`_.\n\n    The PatchCamelyon dataset is a binary classification dataset with 327,680\n    color images (96px x 96px), extracted from histopathologic scans of lymph node\n    sections. Each image is annotated with a binary label indicating presence of\n    metastatic tissue.\n\n    This dataset requires the ``h5py`` package which you can install with ``pip install h5py``.\n\n    Args:\n         root (str or ``pathlib.Path``): Root directory of the dataset.\n         split (string, optional): The dataset split, supports ``\"train\"`` (default), ``\"test\"`` or ``\"val\"``.\n         transform (callable, optional): A function/transform that takes in a PIL image and returns a transformed\n             version. E.g, ``transforms.RandomCrop``.\n         target_transform (callable, optional): A function/transform that takes in the target and transforms it.\n         download (bool, optional): If True, downloads the dataset from the internet and puts it into ``root/pcam``. If\n             dataset is already downloaded, it is not downloaded again.\n\n             .. warning::\n\n                To download the dataset `gdown <https://github.com/wkentaro/gdown>`_ is required.\n    \"\"\"\n    _FILES = {'train': {'images': ('camelyonpatch_level_2_split_train_x.h5', '1Ka0XfEMiwgCYPdTI-vv6eUElOBnKFKQ2', '1571f514728f59376b705fc836ff4b63'), 'targets': ('camelyonpatch_level_2_split_train_y.h5', '1269yhu3pZDP8UYFQs-NYs3FPwuK-nGSG', '35c2d7259d906cfc8143347bb8e05be7')}, 'test': {'images': ('camelyonpatch_level_2_split_test_x.h5', '1qV65ZqZvWzuIVthK8eVDhIwrbnsJdbg_', 'd8c2d60d490dbd479f8199bdfa0cf6ec'), 'targets': ('camelyonpatch_level_2_split_test_y.h5', '17BHrSrwWKjYsOgTMmoqrIjDy6Fa2o_gP', '60a7035772fbdb7f34eb86d4420cf66a')}, 'val': {'images': ('camelyonpatch_level_2_split_valid_x.h5', '1hgshYGWK8V-eGRy8LToWJJgDU_rXWVJ3', 'd5b63470df7cfa627aeec8b9dc0c066e'), 'targets': ('camelyonpatch_level_2_split_valid_y.h5', '1bH8ZRbhSVAhScTS0p9-ZzGnX91cHT3uO', '2b85f58b927af9964a4c15b8f7e8f179')}}\n\n    def __init__(self, root: Union[str, pathlib.Path], split: str='train', transform: Optional[Callable]=None, target_transform: Optional[Callable]=None, download: bool=False):\n        try:\n            import h5py\n            self.h5py = h5py\n        except ImportError:\n            raise RuntimeError('h5py is not found. This dataset needs to have h5py installed: please run pip install h5py')\n        self._split = verify_str_arg(split, 'split', ('train', 'test', 'val'))\n        super().__init__(root, transform=transform, target_transform=target_transform)\n        self._base_folder = pathlib.Path(self.root) / 'pcam'\n        if download:\n            self._download()\n        if not self._check_exists():\n            raise RuntimeError('Dataset not found. You can use download=True to download it')\n\n    def __len__(self) -> int:\n        images_file = self._FILES[self._split]['images'][0]\n        with self.h5py.File(self._base_folder / images_file) as images_data:\n            return images_data['x'].shape[0]\n\n    def __getitem__(self, idx: int) -> tuple[Any, Any]:\n        images_file = self._FILES[self._split]['images'][0]\n        with self.h5py.File(self._base_folder / images_file) as images_data:\n            image = Image.fromarray(images_data['x'][idx]).convert('RGB')\n        targets_file = self._FILES[self._split]['targets'][0]\n        with self.h5py.File(self._base_folder / targets_file) as targets_data:\n            target = int(targets_data['y'][idx, 0, 0, 0])\n        if self.transform:\n            image = self.transform(image)\n        if self.target_transform:\n            target = self.target_transform(target)\n        return (image, target)\n\n    def _check_exists(self) -> bool:\n        images_file = self._FILES[self._split]['images'][0]\n        targets_file = self._FILES[self._split]['targets'][0]\n        return all((self._base_folder.joinpath(h5_file).exists() for h5_file in (images_file, targets_file)))\n\n    def _download(self) -> None:\n        if self._check_exists():\n            return\n        for file_name, file_id, md5 in self._FILES[self._split].values():\n            archive_name = file_name + '.gz'\n            download_file_from_google_drive(file_id, str(self._base_folder), filename=archive_name, md5=md5)\n            _decompress(str(self._base_folder / archive_name))\n\nExample skeleton:\n\n\nclass VAO:\n    '''\n    Represents a vertex array object.\n    This is a wrapper class over ``moderngl.VertexArray`` to provide helper method.\n    The main purpose is to provide render methods taking a program as parameter.\n    The class will auto detect the programs attributes and add padding when needed\n    to match the vertex object.\n    A new vertexbuffer object is created and stored internally for each unique\n    shader program used.\n    A secondary purpose is to provide an alternate way to build vertexbuffers\n    This can be practical when loading or creating various geometry.\n    There is no requirements to use this class, but most methods in the\n    system creating vertexbuffers will return this type. You can obtain\n    a single vertexbuffer instance by calling :py:meth:`VAO.instance`\n    method if you prefer to work directly on moderngl instances.\n    '''\n\n    def __init__(self, name='', mode=moderngl.TRIANGLES):\n        '''\n        Create and empty VAO\n        Keyword Args:\n            name (str): The name for debug purposes\n            mode (int): Default draw mode\n        '''\n        pass\n\n    def render(self, program: moderngl.Program, mode=None, vertices=-1, first=0, instances=1):\n        '''\n        Render the VAO.\n        Args:\n            program: The ``moderngl.Program``\n        Keyword Args:\n            mode: Override the draw mode (``TRIANGLES`` etc)\n            vertices (int): The number of vertices to transform\n            first (int): The index of the first vertex to start with\n            instances (int): The number of instances\n        '''\n        pass\n\n    def render_indirect(self, program: moderngl.Program, buffer, mode=None, count=-1, *, first=0):\n        '''\n        The render primitive (mode) must be the same as the input primitive of the GeometryShader.\n        The draw commands are 5 integers: (count, instanceCount, firstIndex, baseVertex, baseInstance).\n        Args:\n            program: The ``moderngl.Program``\n            buffer: The ``moderngl.Buffer`` containing indirect draw commands\n        Keyword Args:\n            mode (int): By default :py:data:`TRIANGLES` will be used.\n            count (int): The number of draws.\n            first (int): The index of the first indirect draw command.\n        '''\n        pass\n\n    def transform(self, program: moderngl.Program, buffer: moderngl.Buffer, mode=None, vertices=-1, first=0, instances=1):\n        '''\n        Transform vertices. Stores the output in a single buffer.\n        Args:\n            program: The ``moderngl.Program``\n            buffer: The ``moderngl.buffer`` to store the output\n        Keyword Args:\n            mode: Draw mode (for example ``moderngl.POINTS``)\n            vertices (int): The number of vertices to transform\n            first (int): The index of the first vertex to start with\n            instances (int): The number of instances\n        '''\n        pass\n\n    def buffer(self, buffer, buffer_format: str, attribute_names, per_instance=False):\n        '''\n        Register a buffer/vbo for the VAO. This can be called multiple times.\n        adding multiple buffers (interleaved or not)\n        Args:\n            buffer: The buffer data. Can be ``numpy.array``, ``moderngl.Buffer`` or ``bytes``.\n            buffer_format (str): The format of the buffer. (eg. ``3f 3f`` for interleaved positions and normals).\n            attribute_names: A list of attribute names this buffer should map to.\n        Keyword Args:\n            per_instance (bool): Is this buffer per instance data for instanced rendering?\n        Returns:\n            The ``moderngl.Buffer`` instance object. This is handy when providing ``bytes`` and ``numpy.array``.\n        '''\n        pass\n\n    def index_buffer(self, buffer, index_element_size=4):\n        '''\n        Set the index buffer for this VAO\n        Args:\n            buffer: ``moderngl.Buffer``, ``numpy.array`` or ``bytes``\n        Keyword Args:\n            index_element_size (int): Byte size of each element. 1, 2 or 4\n        '''\n        pass\n\n    def instance(self, program: moderngl.Program) -> moderngl.VertexArray:\n        '''\n        Obtain the ``moderngl.VertexArray`` instance for the program.\n        The instance is only created once and cached internally.\n        Returns: ``moderngl.VertexArray`` instance\n        '''\n        pass\n\n    def release(self, buffer=True):\n        '''\n        Destroy the vao object\n        Keyword Args:\n            buffers (bool): also release buffers\n        '''\n        pass\nCorresponding class implementation:\n\nimport numpy\nimport moderngl\nfrom demosys import context\n\nclass VAO:\n    \"\"\"\n    Represents a vertex array object.\n    This is a wrapper class over ``moderngl.VertexArray`` to provide helper method.\n\n    The main purpose is to provide render methods taking a program as parameter.\n    The class will auto detect the programs attributes and add padding when needed\n    to match the vertex object.\n    A new vertexbuffer object is created and stored internally for each unique\n    shader program used.\n\n    A secondary purpose is to provide an alternate way to build vertexbuffers\n    This can be practical when loading or creating various geometry.\n\n    There is no requirements to use this class, but most methods in the\n    system creating vertexbuffers will return this type. You can obtain\n    a single vertexbuffer instance by calling :py:meth:`VAO.instance`\n    method if you prefer to work directly on moderngl instances.\n    \"\"\"\n\n    def __init__(self, name='', mode=moderngl.TRIANGLES):\n        \"\"\"\n        Create and empty VAO\n\n        Keyword Args:\n            name (str): The name for debug purposes\n            mode (int): Default draw mode\n        \"\"\"\n        self.ctx = context.ctx()\n        self.name = name\n        self.mode = mode\n        try:\n            DRAW_MODES[self.mode]\n        except KeyError:\n            raise VAOError('Invalid draw mode. Options are {}'.format(DRAW_MODES.values()))\n        self.buffers = []\n        self._index_buffer = None\n        self._index_element_size = None\n        self.vertex_count = 0\n        self.vaos = {}\n\n    def render(self, program: moderngl.Program, mode=None, vertices=-1, first=0, instances=1):\n        \"\"\"\n        Render the VAO.\n\n        Args:\n            program: The ``moderngl.Program``\n\n        Keyword Args:\n            mode: Override the draw mode (``TRIANGLES`` etc)\n            vertices (int): The number of vertices to transform\n            first (int): The index of the first vertex to start with\n            instances (int): The number of instances\n        \"\"\"\n        vao = self.instance(program)\n        if mode is None:\n            mode = self.mode\n        vao.render(mode, vertices=vertices, first=first, instances=instances)\n\n    def render_indirect(self, program: moderngl.Program, buffer, mode=None, count=-1, *, first=0):\n        \"\"\"\n        The render primitive (mode) must be the same as the input primitive of the GeometryShader.\n        The draw commands are 5 integers: (count, instanceCount, firstIndex, baseVertex, baseInstance).\n\n        Args:\n            program: The ``moderngl.Program``\n            buffer: The ``moderngl.Buffer`` containing indirect draw commands\n\n        Keyword Args:\n            mode (int): By default :py:data:`TRIANGLES` will be used.\n            count (int): The number of draws.\n            first (int): The index of the first indirect draw command.\n        \"\"\"\n        vao = self.instance(program)\n        if mode is None:\n            mode = self.mode\n        vao.render_indirect(buffer, mode=mode, count=count, first=first)\n\n    def transform(self, program: moderngl.Program, buffer: moderngl.Buffer, mode=None, vertices=-1, first=0, instances=1):\n        \"\"\"\n        Transform vertices. Stores the output in a single buffer.\n\n        Args:\n            program: The ``moderngl.Program``\n            buffer: The ``moderngl.buffer`` to store the output\n\n        Keyword Args:\n            mode: Draw mode (for example ``moderngl.POINTS``)\n            vertices (int): The number of vertices to transform\n            first (int): The index of the first vertex to start with\n            instances (int): The number of instances\n        \"\"\"\n        vao = self.instance(program)\n        if mode is None:\n            mode = self.mode\n        vao.transform(buffer, mode=mode, vertices=vertices, first=first, instances=instances)\n\n    def buffer(self, buffer, buffer_format: str, attribute_names, per_instance=False):\n        \"\"\"\n        Register a buffer/vbo for the VAO. This can be called multiple times.\n        adding multiple buffers (interleaved or not)\n\n        Args:\n            buffer: The buffer data. Can be ``numpy.array``, ``moderngl.Buffer`` or ``bytes``.\n            buffer_format (str): The format of the buffer. (eg. ``3f 3f`` for interleaved positions and normals).\n            attribute_names: A list of attribute names this buffer should map to.\n\n        Keyword Args:\n            per_instance (bool): Is this buffer per instance data for instanced rendering?\n\n        Returns:\n            The ``moderngl.Buffer`` instance object. This is handy when providing ``bytes`` and ``numpy.array``.\n        \"\"\"\n        if not isinstance(attribute_names, list):\n            attribute_names = [attribute_names]\n        if not type(buffer) in [moderngl.Buffer, numpy.ndarray, bytes]:\n            raise VAOError('buffer parameter must be a moderngl.Buffer, numpy.ndarray or bytes instance(not {})'.format(type(buffer)))\n        if isinstance(buffer, numpy.ndarray):\n            buffer = self.ctx.buffer(buffer.tobytes())\n        if isinstance(buffer, bytes):\n            buffer = self.ctx.buffer(data=buffer)\n        formats = buffer_format.split()\n        if len(formats) != len(attribute_names):\n            raise VAOError(\"Format '{}' does not describe attributes {}\".format(buffer_format, attribute_names))\n        self.buffers.append(BufferInfo(buffer, buffer_format, attribute_names, per_instance=per_instance))\n        self.vertex_count = self.buffers[-1].vertices\n        return buffer\n\n    def index_buffer(self, buffer, index_element_size=4):\n        \"\"\"\n        Set the index buffer for this VAO\n\n        Args:\n            buffer: ``moderngl.Buffer``, ``numpy.array`` or ``bytes``\n\n        Keyword Args:\n            index_element_size (int): Byte size of each element. 1, 2 or 4\n        \"\"\"\n        if not type(buffer) in [moderngl.Buffer, numpy.ndarray, bytes]:\n            raise VAOError('buffer parameter must be a moderngl.Buffer, numpy.ndarray or bytes instance')\n        if isinstance(buffer, numpy.ndarray):\n            buffer = self.ctx.buffer(buffer.tobytes())\n        if isinstance(buffer, bytes):\n            buffer = self.ctx.buffer(data=buffer)\n        self._index_buffer = buffer\n        self._index_element_size = index_element_size\n\n    def instance(self, program: moderngl.Program) -> moderngl.VertexArray:\n        \"\"\"\n        Obtain the ``moderngl.VertexArray`` instance for the program.\n        The instance is only created once and cached internally.\n\n        Returns: ``moderngl.VertexArray`` instance\n        \"\"\"\n        vao = self.vaos.get(program.glo)\n        if vao:\n            return vao\n        program_attributes = [name for name, attr in program._members.items() if isinstance(attr, moderngl.Attribute)]\n        for attrib_name in program_attributes:\n            if attrib_name.startswith('gl_'):\n                continue\n            if not sum((buffer.has_attribute(attrib_name) for buffer in self.buffers)):\n                raise VAOError(\"VAO {} doesn't have attribute {} for program {}\".format(self.name, attrib_name, program.name))\n        vao_content = []\n        for buffer in self.buffers:\n            content = buffer.content(program_attributes)\n            if content:\n                vao_content.append(content)\n        if program_attributes:\n            for attrib_name in program_attributes:\n                if attrib_name.startswith('gl_'):\n                    continue\n                raise VAOError('Did not find a buffer mapping for {}'.format([n for n in program_attributes]))\n        if self._index_buffer:\n            vao = context.ctx().vertex_array(program, vao_content, self._index_buffer, self._index_element_size)\n        else:\n            vao = context.ctx().vertex_array(program, vao_content)\n        self.vaos[program.glo] = vao\n        return vao\n\n    def release(self, buffer=True):\n        \"\"\"\n        Destroy the vao object\n\n        Keyword Args:\n            buffers (bool): also release buffers\n        \"\"\"\n        for key, vao in self.vaos:\n            vao.release()\n        if buffer:\n            for buff in self.buffers:\n                buff.buffer.release()\n            if self._index_buffer:\n                self._index_buffer.release()\n\nNow, implement the following class. Do not explain the code. The given class skeleton is as follows:\n\nclass Format:\n    '''\n    A class for formatting image annotations for object detection, instance segmentation, and pose estimation tasks.\n    This class standardizes image and instance annotations to be used by the `collate_fn` in PyTorch DataLoader.\n    Attributes:\n        bbox_format (str): Format for bounding boxes. Options are 'xywh' or 'xyxy'.\n        normalize (bool): Whether to normalize bounding boxes.\n        return_mask (bool): Whether to return instance masks for segmentation.\n        return_keypoint (bool): Whether to return keypoints for pose estimation.\n        return_obb (bool): Whether to return oriented bounding boxes.\n        mask_ratio (int): Downsample ratio for masks.\n        mask_overlap (bool): Whether to overlap masks.\n        batch_idx (bool): Whether to keep batch indexes.\n        bgr (float): The probability to return BGR images.\n    Methods:\n        __call__: Formats labels dictionary with image, classes, bounding boxes, and optionally masks and keypoints.\n        _format_img: Converts image from Numpy array to PyTorch tensor.\n        _format_segments: Converts polygon points to bitmap masks.\n    Examples:\n        >>> formatter = Format(bbox_format=\"xywh\", normalize=True, return_mask=True)\n        >>> formatted_labels = formatter(labels)\n        >>> img = formatted_labels[\"img\"]\n        >>> bboxes = formatted_labels[\"bboxes\"]\n        >>> masks = formatted_labels[\"masks\"]\n    '''\n\n    def __init__(self, bbox_format='xywh', normalize=True, return_mask=False, return_keypoint=False, return_obb=False, mask_ratio=4, mask_overlap=True, batch_idx=True, bgr=0.0):\n        '''\n        Initializes the Format class with given parameters for image and instance annotation formatting.\n        This class standardizes image and instance annotations for object detection, instance segmentation, and pose\n        estimation tasks, preparing them for use in PyTorch DataLoader's `collate_fn`.\n        Args:\n            bbox_format (str): Format for bounding boxes. Options are 'xywh', 'xyxy', etc.\n            normalize (bool): Whether to normalize bounding boxes to [0,1].\n            return_mask (bool): If True, returns instance masks for segmentation tasks.\n            return_keypoint (bool): If True, returns keypoints for pose estimation tasks.\n            return_obb (bool): If True, returns oriented bounding boxes.\n            mask_ratio (int): Downsample ratio for masks.\n            mask_overlap (bool): If True, allows mask overlap.\n            batch_idx (bool): If True, keeps batch indexes.\n            bgr (float): Probability of returning BGR images instead of RGB.\n        Attributes:\n            bbox_format (str): Format for bounding boxes.\n            normalize (bool): Whether bounding boxes are normalized.\n            return_mask (bool): Whether to return instance masks.\n            return_keypoint (bool): Whether to return keypoints.\n            return_obb (bool): Whether to return oriented bounding boxes.\n            mask_ratio (int): Downsample ratio for masks.\n            mask_overlap (bool): Whether masks can overlap.\n            batch_idx (bool): Whether to keep batch indexes.\n            bgr (float): The probability to return BGR images.\n        Examples:\n            >>> format = Format(bbox_format=\"xyxy\", return_mask=True, return_keypoint=False)\n            >>> print(format.bbox_format)\n            xyxy\n        '''\n        pass\n\n    def __call__(self, labels):\n        '''\n        Formats image annotations for object detection, instance segmentation, and pose estimation tasks.\n        This method standardizes the image and instance annotations to be used by the `collate_fn` in PyTorch\n        DataLoader. It processes the input labels dictionary, converting annotations to the specified format and\n        applying normalization if required.\n        Args:\n            labels (Dict): A dictionary containing image and annotation data with the following keys:\n                - 'img': The input image as a numpy array.\n                - 'cls': Class labels for instances.\n                - 'instances': An Instances object containing bounding boxes, segments, and keypoints.\n        Returns:\n            (Dict): A dictionary with formatted data, including:\n                - 'img': Formatted image tensor.\n                - 'cls': Class label's tensor.\n                - 'bboxes': Bounding boxes tensor in the specified format.\n                - 'masks': Instance masks tensor (if return_mask is True).\n                - 'keypoints': Keypoints tensor (if return_keypoint is True).\n                - 'batch_idx': Batch index tensor (if batch_idx is True).\n        Examples:\n            >>> formatter = Format(bbox_format=\"xywh\", normalize=True, return_mask=True)\n            >>> labels = {\"img\": np.random.rand(640, 640, 3), \"cls\": np.array([0, 1]), \"instances\": Instances(...)}\n            >>> formatted_labels = formatter(labels)\n            >>> print(formatted_labels.keys())\n        '''\n        pass\n\n    def _format_img(self, img):\n        '''\n        Formats an image for YOLO from a Numpy array to a PyTorch tensor.\n        This function performs the following operations:\n        1. Ensures the image has 3 dimensions (adds a channel dimension if needed).\n        2. Transposes the image from HWC to CHW format.\n        3. Optionally flips the color channels from RGB to BGR.\n        4. Converts the image to a contiguous array.\n        5. Converts the Numpy array to a PyTorch tensor.\n        Args:\n            img (np.ndarray): Input image as a Numpy array with shape (H, W, C) or (H, W).\n        Returns:\n            (torch.Tensor): Formatted image as a PyTorch tensor with shape (C, H, W).\n        Examples:\n            >>> import numpy as np\n            >>> img = np.random.rand(100, 100, 3)\n            >>> formatted_img = self._format_img(img)\n            >>> print(formatted_img.shape)\n            torch.Size([3, 100, 100])\n        '''\n        pass\n\n    def _format_segments(self, instances, cls, w, h):\n        '''\n        Converts polygon segments to bitmap masks.\n        Args:\n            instances (Instances): Object containing segment information.\n            cls (numpy.ndarray): Class labels for each instance.\n            w (int): Width of the image.\n            h (int): Height of the image.\n        Returns:\n            masks (numpy.ndarray): Bitmap masks with shape (N, H, W) or (1, H, W) if mask_overlap is True.\n            instances (Instances): Updated instances object with sorted segments if mask_overlap is True.\n            cls (numpy.ndarray): Updated class labels, sorted if mask_overlap is True.\n        Notes:\n            - If self.mask_overlap is True, masks are overlapped and sorted by area.\n            - If self.mask_overlap is False, each mask is represented separately.\n            - Masks are downsampled according to self.mask_ratio.\n        '''\n        pass"
  }
]