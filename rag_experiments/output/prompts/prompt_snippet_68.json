[
  {
    "role": "assistant",
    "content": "You are an expert Python programmer who can correctly implement complete Python classes based on the provided class skeleton."
  },
  {
    "role": "user",
    "content": "For your understanding, following are some (skeleton, code) examples:\n\nExample skeleton:\n\n\nclass JumpStartMetadataBaseFields(JumpStartDataHolderType):\n    '''Data class JumpStart metadata base fields that can be overridden.'''\n\n    def __init__(self, fields: Dict[str, Any], is_hub_content: Optional[bool]=False):\n        '''Initializes a JumpStartMetadataFields object.\n        Args:\n            fields (Dict[str, Any]): Dictionary representation of metadata fields.\n        '''\n        pass\n\n    def from_json(self, json_obj: Dict[str, Any]) -> None:\n        '''Sets fields in object based on json of header.\n        Args:\n            json_obj (Dict[str, Any]): Dictionary representation of spec.\n        '''\n        pass\n\n    def to_json(self) -> Dict[str, Any]:\n        '''Returns json representation of JumpStartMetadataBaseFields object.'''\n        pass\n\n    def set_hub_content_type(self, hub_content_type: HubContentType) -> None:\n        '''Sets the hub content type.'''\n        pass\nCorresponding class implementation:\n\nfrom typing import Any, Callable, Dict, List, Optional, Set, Union\nfrom copy import deepcopy\nfrom sagemaker.jumpstart.hub.parser_utils import camel_to_snake, walk_and_apply_json\n\nclass JumpStartMetadataBaseFields(JumpStartDataHolderType):\n    \"\"\"Data class JumpStart metadata base fields that can be overridden.\"\"\"\n    __slots__ = ['model_id', 'url', 'version', 'min_sdk_version', 'model_types', 'capabilities', 'incremental_training_supported', 'hosting_ecr_specs', 'hosting_ecr_uri', 'hosting_artifact_uri', 'hosting_artifact_key', 'hosting_script_key', 'training_supported', 'training_ecr_specs', 'training_ecr_uri', 'training_artifact_key', 'training_script_key', 'hyperparameters', 'inference_environment_variables', 'inference_vulnerable', 'inference_dependencies', 'inference_vulnerabilities', 'training_vulnerable', 'training_dependencies', 'training_vulnerabilities', 'deprecated', 'usage_info_message', 'deprecated_message', 'deprecate_warn_message', 'default_inference_instance_type', 'supported_inference_instance_types', 'dynamic_container_deployment_supported', 'hosting_resource_requirements', 'default_training_instance_type', 'supported_training_instance_types', 'metrics', 'training_prepacked_script_key', 'training_prepacked_script_version', 'hosting_prepacked_artifact_key', 'hosting_prepacked_artifact_version', 'model_kwargs', 'deploy_kwargs', 'estimator_kwargs', 'fit_kwargs', 'predictor_specs', 'inference_volume_size', 'training_volume_size', 'inference_enable_network_isolation', 'training_enable_network_isolation', 'resource_name_base', 'hosting_eula_key', 'hosting_model_package_arns', 'training_model_package_artifact_uris', 'hosting_use_script_uri', 'hosting_instance_type_variants', 'training_instance_type_variants', 'default_payloads', 'gated_bucket', 'model_subscription_link', 'hosting_additional_data_sources', 'hosting_neuron_model_id', 'hosting_neuron_model_version', 'hub_content_type', '_is_hub_content', 'default_training_dataset_key', 'default_training_dataset_uri']\n    _non_serializable_slots = ['_is_hub_content']\n\n    def __init__(self, fields: Dict[str, Any], is_hub_content: Optional[bool]=False):\n        \"\"\"Initializes a JumpStartMetadataFields object.\n\n        Args:\n            fields (Dict[str, Any]): Dictionary representation of metadata fields.\n        \"\"\"\n        self._is_hub_content = is_hub_content\n        self.from_json(fields)\n\n    def from_json(self, json_obj: Dict[str, Any]) -> None:\n        \"\"\"Sets fields in object based on json of header.\n\n        Args:\n            json_obj (Dict[str, Any]): Dictionary representation of spec.\n        \"\"\"\n        if self._is_hub_content:\n            json_obj = walk_and_apply_json(json_obj, camel_to_snake)\n        self.model_id: str = json_obj.get('model_id')\n        self.url: str = json_obj.get('url')\n        self.version: str = json_obj.get('version')\n        self.min_sdk_version: str = json_obj.get('min_sdk_version')\n        self.incremental_training_supported: bool = bool(json_obj.get('incremental_training_supported', False))\n        if self._is_hub_content:\n            self.capabilities: Optional[List[str]] = json_obj.get('capabilities')\n            self.model_types: Optional[List[str]] = json_obj.get('model_types')\n            self.hosting_ecr_uri: Optional[str] = json_obj.get('hosting_ecr_uri')\n            self._non_serializable_slots.append('hosting_ecr_specs')\n        else:\n            self.hosting_ecr_specs: Optional[JumpStartECRSpecs] = JumpStartECRSpecs(json_obj['hosting_ecr_specs'], is_hub_content=self._is_hub_content) if 'hosting_ecr_specs' in json_obj else None\n            self._non_serializable_slots.append('hosting_ecr_uri')\n        self.hosting_artifact_key: Optional[str] = json_obj.get('hosting_artifact_key')\n        self.hosting_artifact_uri: Optional[str] = json_obj.get('hosting_artifact_uri')\n        self.hosting_script_key: Optional[str] = json_obj.get('hosting_script_key')\n        self.training_supported: Optional[bool] = bool(json_obj.get('training_supported', False))\n        self.inference_environment_variables = [JumpStartEnvironmentVariable(env_variable, is_hub_content=self._is_hub_content) for env_variable in json_obj.get('inference_environment_variables', [])]\n        self.inference_vulnerable: bool = bool(json_obj.get('inference_vulnerable', False))\n        self.inference_dependencies: List[str] = json_obj.get('inference_dependencies', [])\n        self.inference_vulnerabilities: List[str] = json_obj.get('inference_vulnerabilities', [])\n        self.training_vulnerable: bool = bool(json_obj.get('training_vulnerable', False))\n        self.training_dependencies: List[str] = json_obj.get('training_dependencies', [])\n        self.training_vulnerabilities: List[str] = json_obj.get('training_vulnerabilities', [])\n        self.deprecated: bool = bool(json_obj.get('deprecated', False))\n        self.deprecated_message: Optional[str] = json_obj.get('deprecated_message')\n        self.deprecate_warn_message: Optional[str] = json_obj.get('deprecate_warn_message')\n        self.usage_info_message: Optional[str] = json_obj.get('usage_info_message')\n        self.default_inference_instance_type: Optional[str] = json_obj.get('default_inference_instance_type')\n        self.default_training_instance_type: Optional[str] = json_obj.get('default_training_instance_type')\n        self.supported_inference_instance_types: Optional[List[str]] = json_obj.get('supported_inference_instance_types')\n        self.supported_training_instance_types: Optional[List[str]] = json_obj.get('supported_training_instance_types')\n        self.dynamic_container_deployment_supported: Optional[bool] = bool(json_obj.get('dynamic_container_deployment_supported'))\n        self.hosting_resource_requirements: Optional[Dict[str, int]] = json_obj.get('hosting_resource_requirements', None)\n        self.metrics: Optional[List[Dict[str, str]]] = json_obj.get('metrics', None)\n        self.training_prepacked_script_key: Optional[str] = json_obj.get('training_prepacked_script_key', None)\n        self.hosting_prepacked_artifact_key: Optional[str] = json_obj.get('hosting_prepacked_artifact_key', None)\n        if self._is_hub_content:\n            self.training_prepacked_script_version: Optional[str] = json_obj.get('training_prepacked_script_version')\n            self.hosting_prepacked_artifact_version: Optional[str] = json_obj.get('hosting_prepacked_artifact_version')\n        self.model_kwargs = deepcopy(json_obj.get('model_kwargs', {}))\n        self.deploy_kwargs = deepcopy(json_obj.get('deploy_kwargs', {}))\n        self.predictor_specs: Optional[JumpStartPredictorSpecs] = JumpStartPredictorSpecs(json_obj.get('predictor_specs'), is_hub_content=self._is_hub_content) if json_obj.get('predictor_specs') else None\n        self.default_payloads: Optional[Dict[str, JumpStartSerializablePayload]] = {alias: JumpStartSerializablePayload(payload, is_hub_content=self._is_hub_content) for alias, payload in json_obj['default_payloads'].items()} if json_obj.get('default_payloads') else None\n        self.gated_bucket = json_obj.get('gated_bucket', False)\n        self.inference_volume_size: Optional[int] = json_obj.get('inference_volume_size')\n        self.inference_enable_network_isolation: bool = json_obj.get('inference_enable_network_isolation', False)\n        self.resource_name_base: bool = json_obj.get('resource_name_base')\n        self.hosting_eula_key: Optional[str] = json_obj.get('hosting_eula_key')\n        model_package_arns = json_obj.get('hosting_model_package_arns')\n        self.hosting_model_package_arns: Optional[Dict] = model_package_arns if model_package_arns is not None else {}\n        self.hosting_use_script_uri: bool = json_obj.get('hosting_use_script_uri', True)\n        self.hosting_instance_type_variants: Optional[JumpStartInstanceTypeVariants] = JumpStartInstanceTypeVariants(json_obj['hosting_instance_type_variants'], self._is_hub_content) if json_obj.get('hosting_instance_type_variants') else None\n        self.hosting_additional_data_sources: Optional[JumpStartAdditionalDataSources] = JumpStartAdditionalDataSources(json_obj['hosting_additional_data_sources']) if json_obj.get('hosting_additional_data_sources') else None\n        self.hosting_neuron_model_id: Optional[str] = json_obj.get('hosting_neuron_model_id')\n        self.hosting_neuron_model_version: Optional[str] = json_obj.get('hosting_neuron_model_version')\n        if self.training_supported:\n            if self._is_hub_content:\n                self.training_ecr_uri: Optional[str] = json_obj.get('training_ecr_uri')\n                self._non_serializable_slots.append('training_ecr_specs')\n            else:\n                self.training_ecr_specs: Optional[JumpStartECRSpecs] = JumpStartECRSpecs(json_obj['training_ecr_specs']) if 'training_ecr_specs' in json_obj else None\n                self._non_serializable_slots.append('training_ecr_uri')\n            self.training_artifact_key: str = json_obj['training_artifact_key']\n            self.training_script_key: str = json_obj['training_script_key']\n            hyperparameters: Any = json_obj.get('hyperparameters')\n            self.hyperparameters: List[JumpStartHyperparameter] = []\n            if hyperparameters is not None:\n                self.hyperparameters.extend([JumpStartHyperparameter(hyperparameter, is_hub_content=self._is_hub_content) for hyperparameter in hyperparameters])\n            self.estimator_kwargs = deepcopy(json_obj.get('estimator_kwargs', {}))\n            self.fit_kwargs = deepcopy(json_obj.get('fit_kwargs', {}))\n            self.training_volume_size: Optional[int] = json_obj.get('training_volume_size')\n            self.training_enable_network_isolation: bool = json_obj.get('training_enable_network_isolation', False)\n            self.training_model_package_artifact_uris: Optional[Dict] = json_obj.get('training_model_package_artifact_uris')\n            self.training_instance_type_variants: Optional[JumpStartInstanceTypeVariants] = JumpStartInstanceTypeVariants(json_obj['training_instance_type_variants'], is_hub_content=self._is_hub_content) if json_obj.get('training_instance_type_variants') else None\n        self.model_subscription_link = json_obj.get('model_subscription_link')\n        self.default_training_dataset_key: Optional[str] = json_obj.get('default_training_dataset_key')\n        self.default_training_dataset_uri: Optional[str] = json_obj.get('default_training_dataset_uri')\n\n    def to_json(self) -> Dict[str, Any]:\n        \"\"\"Returns json representation of JumpStartMetadataBaseFields object.\"\"\"\n        json_obj = {}\n        for att in self.__slots__:\n            if hasattr(self, att) and att not in getattr(self, '_non_serializable_slots', []):\n                cur_val = getattr(self, att)\n                if issubclass(type(cur_val), JumpStartDataHolderType):\n                    json_obj[att] = cur_val.to_json()\n                elif isinstance(cur_val, list):\n                    json_obj[att] = []\n                    for obj in cur_val:\n                        if issubclass(type(obj), JumpStartDataHolderType):\n                            json_obj[att].append(obj.to_json())\n                        else:\n                            json_obj[att].append(obj)\n                elif isinstance(cur_val, dict):\n                    json_obj[att] = {}\n                    for key, val in cur_val.items():\n                        if issubclass(type(val), JumpStartDataHolderType):\n                            json_obj[att][key] = val.to_json()\n                        else:\n                            json_obj[att][key] = val\n                else:\n                    json_obj[att] = cur_val\n        return json_obj\n\n    def set_hub_content_type(self, hub_content_type: HubContentType) -> None:\n        \"\"\"Sets the hub content type.\"\"\"\n        if self._is_hub_content:\n            self.hub_content_type = hub_content_type\n\nExample skeleton:\n\n\nclass State:\n    '''State class that allows the reading and writing of state to a given\n    path. Input and output state transformations can be supplied in read_fn and\n    write_fn respectively. The input state transformation takes in a string\n    while the output transformation outputs a string. If run inside a GitHub\n    Action, the saved state file could be committed to GitHub so that on next\n    run the state is available in the repository.\n    Args:\n        path (str): Path to save state file\n        read_fn (Callable[[str], Any]): Input state transformation. Defaults to lambda x: x.\n        write_fn: Callable[[Any], str]: Output state transformation. Defaults to lambda x: x.\n    '''\n\n    def __init__(self, path: str, read_fn: Callable[[str], Any]=lambda x: x, write_fn: Callable[[Any], str]=lambda x: x) -> None:\n        pass\n\n    def __enter__(self) -> 'State':\n        '''Allow usage of with.\n        Returns:\n            State: SavedState object\n        '''\n        pass\n\n    def __exit__(self, exc_type: Any, exc_value: Any, traceback: Any) -> None:\n        '''Allow usage of with.\n        Args:\n            exc_type (Any): Exception type\n            exc_value (Any): Exception value\n            traceback (Any): Traceback\n        Returns:\n            None\n        '''\n        pass\n\n    def read(self) -> Any:\n        '''Read state from file\n        Returns:\n            Any: State\n        '''\n        pass\n\n    def write(self) -> None:\n        '''Write state to file\n        Returns:\n            None\n        '''\n        pass\n\n    def get(self) -> Any:\n        '''Get the state\n        Returns:\n            Any: State\n        '''\n        pass\n\n    def set(self, state: Any):\n        '''Set the state\n        Args:\n            state (Any): State\n        Returns:\n            None\n        '''\n        pass\n    @staticmethod\n    def dates_str_to_country_date_dict(dates_str: str) -> Dict:\n        '''Convert a comma separated string of key=date string pairs eg.\n        \"default=2017-01-01,afg=2019-01-01\" to a dictionary of key date\n        mappings eg.\n        {\"default\": 2017-01-01 as datetime, \"afg\": 2019-01-01 as datetime}\n        Args:\n            dates_str (str): Comma separated string of key=date string pairs\n        Returns:\n            Dict: Dictionary of key date mappings\n        '''\n        pass\n    @staticmethod\n    def country_date_dict_to_dates_str(country_date_dict: Dict) -> str:\n        '''Convert a dictionary of key date mappings eg.\n        {\"default\": 2017-01-01 as datetime, \"afg\": 2019-01-01 as datetime}\n        to a comma separated string of key=date string pairs eg.\n        \"default=2017-01-01,afg=2019-01-01\"\n        Args:\n            country_date_dict (Dict): Dictionary of key date mappings\n        Returns:\n            str: Comma separated string of key=date string pairs\n        '''\n        pass\nCorresponding class implementation:\n\nfrom typing import Any, Callable, Dict\nfrom hdx.utilities.loader import load_text\nfrom hdx.utilities.dateparse import iso_string_from_datetime, parse_date\nfrom hdx.utilities.saver import save_text\n\nclass State:\n    \"\"\"State class that allows the reading and writing of state to a given\n    path. Input and output state transformations can be supplied in read_fn and\n    write_fn respectively. The input state transformation takes in a string\n    while the output transformation outputs a string. If run inside a GitHub\n    Action, the saved state file could be committed to GitHub so that on next\n    run the state is available in the repository.\n\n    Args:\n        path (str): Path to save state file\n        read_fn (Callable[[str], Any]): Input state transformation. Defaults to lambda x: x.\n        write_fn: Callable[[Any], str]: Output state transformation. Defaults to lambda x: x.\n    \"\"\"\n\n    def __init__(self, path: str, read_fn: Callable[[str], Any]=lambda x: x, write_fn: Callable[[Any], str]=lambda x: x) -> None:\n        self.path = path\n        self.read_fn = read_fn\n        self.write_fn = write_fn\n        self.state = self.read()\n\n    def __enter__(self) -> 'State':\n        \"\"\"Allow usage of with.\n\n        Returns:\n            State: SavedState object\n        \"\"\"\n        return self\n\n    def __exit__(self, exc_type: Any, exc_value: Any, traceback: Any) -> None:\n        \"\"\"Allow usage of with.\n\n        Args:\n            exc_type (Any): Exception type\n            exc_value (Any): Exception value\n            traceback (Any): Traceback\n\n        Returns:\n            None\n        \"\"\"\n        self.write()\n\n    def read(self) -> Any:\n        \"\"\"Read state from file\n\n        Returns:\n            Any: State\n        \"\"\"\n        value = self.read_fn(load_text(self.path))\n        logger.info(f'State read from {self.path} = {value}')\n        return value\n\n    def write(self) -> None:\n        \"\"\"Write state to file\n\n        Returns:\n            None\n        \"\"\"\n        logger.info(f'State written to {self.path} = {self.state}')\n        save_text(self.write_fn(self.state), self.path)\n\n    def get(self) -> Any:\n        \"\"\"Get the state\n\n        Returns:\n            Any: State\n        \"\"\"\n        return self.state\n\n    def set(self, state: Any):\n        \"\"\"Set the state\n\n        Args:\n            state (Any): State\n\n        Returns:\n            None\n        \"\"\"\n        self.state = state\n\n    @staticmethod\n    def dates_str_to_country_date_dict(dates_str: str) -> Dict:\n        \"\"\"Convert a comma separated string of key=date string pairs eg.\n        \"default=2017-01-01,afg=2019-01-01\" to a dictionary of key date\n        mappings eg.\n        {\"default\": 2017-01-01 as datetime, \"afg\": 2019-01-01 as datetime}\n\n        Args:\n            dates_str (str): Comma separated string of key=date string pairs\n\n        Returns:\n            Dict: Dictionary of key date mappings\n        \"\"\"\n        result = {}\n        for keyvalue in dates_str.split(','):\n            key, value = keyvalue.split('=')\n            result[key] = parse_date(value)\n        return result\n\n    @staticmethod\n    def country_date_dict_to_dates_str(country_date_dict: Dict) -> str:\n        \"\"\"Convert a dictionary of key date mappings eg.\n        {\"default\": 2017-01-01 as datetime, \"afg\": 2019-01-01 as datetime}\n        to a comma separated string of key=date string pairs eg.\n        \"default=2017-01-01,afg=2019-01-01\"\n\n        Args:\n            country_date_dict (Dict): Dictionary of key date mappings\n\n        Returns:\n            str: Comma separated string of key=date string pairs\n        \"\"\"\n        strlist = []\n        for key, value in country_date_dict.items():\n            valstr = iso_string_from_datetime(value)\n            strlist.append(f'{key}={valstr}')\n        return ','.join(strlist)\n\nNow, implement the following class. Do not explain the code. The given class skeleton is as follows:\n\nclass AgentState:\n    '''Represents an Agent's stateful information outside of context provided to a model.\n    Provides a key-value store for agent state with JSON serialization validation and persistence support.\n    Key features:\n    - JSON serialization validation on assignment\n    - Get/set/delete operations\n    '''\n\n    def __init__(self, initial_state: Optional[Dict[str, Any]]=None):\n        '''Initialize AgentState.'''\n        pass\n\n    def set(self, key: str, value: Any) -> None:\n        '''Set a value in the state.\n        Args:\n            key: The key to store the value under\n            value: The value to store (must be JSON serializable)\n        Raises:\n            ValueError: If key is invalid, or if value is not JSON serializable\n        '''\n        pass\n\n    def get(self, key: Optional[str]=None) -> Any:\n        '''Get a value or entire state.\n        Args:\n            key: The key to retrieve (if None, returns entire state object)\n        Returns:\n            The stored value, entire state dict, or None if not found\n        '''\n        pass\n\n    def delete(self, key: str) -> None:\n        '''Delete a specific key from the state.\n        Args:\n            key: The key to delete\n        '''\n        pass\n\n    def _validate_key(self, key: str) -> None:\n        '''Validate that a key is valid.\n        Args:\n            key: The key to validate\n        Raises:\n            ValueError: If key is invalid\n        '''\n        pass\n\n    def _validate_json_serializable(self, value: Any) -> None:\n        '''Validate that a value is JSON serializable.\n        Args:\n            value: The value to validate\n        Raises:\n            ValueError: If value is not JSON serializable\n        '''\n        pass"
  }
]