[
  {
    "role": "assistant",
    "content": "You are an expert Python programmer who can correctly implement complete Python classes based on the provided class skeleton."
  },
  {
    "role": "user",
    "content": "For your understanding, following are some (skeleton, code) examples:\n\nExample skeleton:\n\n\nclass DataTable(BaseModel):\n    '''\n    Data table class. Prepares and holds data and configuration\n    for either a table or a violin plot.\n    '''\n\n    def is_empty(self) -> bool:\n        '''\n        Check if the table is empty.\n        '''\n        pass\n    @staticmethod\n    def create(data: Dict[SectionKey, SectionT], table_id: str, table_anchor: Anchor, pconfig: TableConfig, headers: Dict[SectionKey, Dict[ColumnKey, ColumnDict]]) -> 'DataTable':\n        '''Prepare data for use in a table or plot'''\n        pass\n\n    def get_headers_in_order(self, keep_hidden: bool=True) -> List[Tuple[int, ColumnKey, ColumnMeta]]:\n        '''\n        Gets the headers in the order they want to be displayed.\n        Returns a list of triplets: (bucket_idx, key, header_info)\n        '''\n        pass\n\n    def merge(self, new_dt: 'DataTable'):\n        '''\n        Extend the existing DataTable with new data.\n        Sections are matched by their column keys rather than their position in the list.\n        This allows for merging sections even if they appear in different order.\n        New samples and columns are added at the end, while existing sample/column combinations\n        are overwritten with new data.\n        '''\n        pass\n\n    def _rebuild_headers_in_order(self) -> None:\n        '''\n        Rebuild the headers_in_order dictionary based on current sections and columns.\n        '''\n        pass\nCorresponding class implementation:\n\nfrom multiqc.types import Anchor, ColumnKey, SampleGroup, SampleName, SectionKey\nfrom typing import Any, Callable, Dict, List, Mapping, NewType, Optional, Sequence, Set, Tuple, TypedDict, Union, cast\nfrom pydantic import BaseModel, Field\nfrom collections import defaultdict\nfrom multiqc import config, report\n\nclass DataTable(BaseModel):\n    \"\"\"\n    Data table class. Prepares and holds data and configuration\n    for either a table or a violin plot.\n    \"\"\"\n    id: str\n    anchor: Anchor\n    pconfig: TableConfig\n    section_by_id: Dict[SectionKey, TableSection]\n    headers_in_order: Dict[float, List[Tuple[int, ColumnKey]]]\n\n    def is_empty(self) -> bool:\n        \"\"\"\n        Check if the table is empty.\n        \"\"\"\n        return not self.section_by_id or not any((section.rows_by_sgroup.values() for section in self.section_by_id.values()))\n\n    @staticmethod\n    def create(data: Dict[SectionKey, SectionT], table_id: str, table_anchor: Anchor, pconfig: TableConfig, headers: Dict[SectionKey, Dict[ColumnKey, ColumnDict]]) -> 'DataTable':\n        \"\"\"Prepare data for use in a table or plot\"\"\"\n        if table_anchor in config.custom_plot_config:\n            for k, v in config.custom_plot_config[table_anchor].items():\n                if isinstance(k, str) and k in pconfig.__dict__:\n                    setattr(pconfig, k, v)\n        input_section_key: SectionKey\n        input_section: SectionT\n        input_group: GroupT\n        unified_sections__with_nulls: Dict[SectionKey, Dict[SampleGroup, List[InputRow]]] = {}\n        for input_section_key, input_section in data.items():\n            rows_by_group: Dict[SampleGroup, List[InputRow]] = {}\n            for g_name, input_group in input_section.items():\n                g_name = SampleGroup(str(g_name))\n                if isinstance(input_group, dict):\n                    rows_by_group[g_name] = [InputRow(sample=SampleName(g_name), data=input_group)]\n                elif isinstance(input_group, list):\n                    rows_by_group[g_name] = input_group\n                else:\n                    assert isinstance(input_group, InputRow)\n                    rows_by_group[g_name] = [input_group]\n            unified_sections__with_nulls[input_section_key] = rows_by_group\n        del data\n        sections: Dict[SectionKey, TableSection] = {}\n        for sec_idx, (section_key, rows_by_sname__with_nulls) in enumerate(unified_sections__with_nulls.items()):\n            header_by_key: Union[Dict[ColumnKey, ColumnDict], Dict[str, ColumnDict]] = headers.get(SectionKey(section_key)) or dict()\n            if not header_by_key:\n                pconfig.only_defined_headers = False\n            column_by_key: Dict[ColumnKey, ColumnMeta] = dict()\n            col_dict_by_key_copy: Dict[ColumnKey, ColumnDict] = _get_or_create_headers(rows_by_sname__with_nulls, header_by_key, pconfig)\n            for col_key, col_dict in col_dict_by_key_copy.items():\n                column_by_key[col_key] = ColumnMeta.create(col_dict=col_dict, col_key=col_key, sec_idx=sec_idx, pconfig=pconfig, table_anchor=table_anchor)\n            section = TableSection(column_by_key=column_by_key)\n            for g_name, group_rows__with_nulls in rows_by_sname__with_nulls.items():\n                for input_row in group_rows__with_nulls:\n                    row = Row(sample=input_row.sample)\n                    for col_key, optional_val in input_row.data.items():\n                        if col_key not in column_by_key:\n                            continue\n                        if optional_val is None or str(optional_val).strip() == '':\n                            continue\n                        val_obj = _process_and_format_value(optional_val, column_by_key[col_key], parse_numeric=pconfig.parse_numeric)\n                        row.data[col_key] = val_obj\n                    if row.data:\n                        section.rows_by_sgroup[g_name].append(row)\n            section.rows_by_sgroup = {sname: rows for sname, rows in section.rows_by_sgroup.items() if rows}\n            for col_key, column in column_by_key.items():\n                _determine_dmin_and_dmax(column, col_key, section.rows_by_sgroup)\n            sections[section_key] = section\n        del unified_sections__with_nulls\n        shared_keys: Dict[str, Dict[str, Union[int, float]]] = _collect_shared_keys(sections)\n        headers_in_order: Dict[float, List[Tuple[int, ColumnKey]]] = defaultdict(list)\n        for sec_idx, section in enumerate(sections.values()):\n            for col_key, column in section.column_by_key.items():\n                if column.shared_key is not None:\n                    column.dmax = shared_keys[column.shared_key].get('dmax')\n                    column.dmin = shared_keys[column.shared_key].get('dmin')\n                headers_in_order[column.placement].append((sec_idx, col_key))\n        for section in sections.values():\n            for column in section.column_by_key.values():\n                column.modify = None\n                if not isinstance(column.format, str):\n                    column.format = None\n        return DataTable(id=table_id, anchor=table_anchor, section_by_id=sections, headers_in_order=headers_in_order, pconfig=pconfig)\n\n    def get_headers_in_order(self, keep_hidden: bool=True) -> List[Tuple[int, ColumnKey, ColumnMeta]]:\n        \"\"\"\n        Gets the headers in the order they want to be displayed.\n        Returns a list of triplets: (bucket_idx, key, header_info)\n        \"\"\"\n        res: List[Tuple[int, ColumnKey, ColumnMeta]] = list()\n        placement: float\n        for placement in sorted(self.headers_in_order.keys()):\n            for section_idx, col_key in self.headers_in_order[placement]:\n                if keep_hidden or not list(self.section_by_id.values())[section_idx].column_by_key[col_key].hidden:\n                    res.append((section_idx, col_key, list(self.section_by_id.values())[section_idx].column_by_key[col_key]))\n        return res\n\n    def merge(self, new_dt: 'DataTable'):\n        \"\"\"\n        Extend the existing DataTable with new data.\n\n        Sections are matched by their column keys rather than their position in the list.\n        This allows for merging sections even if they appear in different order.\n\n        New samples and columns are added at the end, while existing sample/column combinations\n        are overwritten with new data.\n        \"\"\"\n        for section_id, new_section in new_dt.section_by_id.items():\n            if section_id in self.section_by_id:\n                section = self.section_by_id[section_id]\n                for col_key, new_col_meta in new_section.column_by_key.items():\n                    if col_key in section.column_by_key:\n                        existing_col = section.column_by_key[col_key]\n                        for field_name, field_value in new_col_meta.model_dump().items():\n                            setattr(existing_col, field_name, field_value)\n                    else:\n                        section.column_by_key[col_key] = new_col_meta\n                for group_name, new_rows in new_section.rows_by_sgroup.items():\n                    existing_rows = section.rows_by_sgroup.get(group_name, [])\n                    existing_samples = {row.sample for row in existing_rows}\n                    for new_row in new_rows:\n                        if new_row.sample in existing_samples:\n                            for i, row in enumerate(existing_rows):\n                                if row.sample == new_row.sample:\n                                    row.data.update(new_row.data)\n                                    existing_rows[i] = row\n                                    break\n                        else:\n                            existing_rows.append(new_row)\n                    section.rows_by_sgroup[group_name] = existing_rows\n                for col_key, column in section.column_by_key.items():\n                    _determine_dmin_and_dmax(column, col_key, section.rows_by_sgroup)\n            else:\n                self.section_by_id[section_id] = new_section\n        self._rebuild_headers_in_order()\n\n    def _rebuild_headers_in_order(self) -> None:\n        \"\"\"\n        Rebuild the headers_in_order dictionary based on current sections and columns.\n        \"\"\"\n        self.headers_in_order = defaultdict(list)\n        for sec_idx, section in enumerate(self.section_by_id.values()):\n            for col_key, column in section.column_by_key.items():\n                self.headers_in_order[column.placement].append((sec_idx, col_key))\n\nExample skeleton:\n\n\nclass MultithreadedJobExecutor(JobExecutor):\n    '''\n    Experimental multi-threaded CWL executor.\n    Does simple resource accounting, will not start a job unless it\n    has cores / ram available, but does not make any attempt to\n    optimize usage.\n    '''\n\n    def __init__(self) -> None:\n        '''Initialize.'''\n        pass\n\n    def select_resources(self, request: dict[str, Union[int, float]], runtime_context: RuntimeContext) -> dict[str, Union[int, float]]:\n        '''Naïve check for available cpu cores and memory.'''\n        pass\n\n    def _runner(self, job: Union[JobBase, WorkflowJob, CallbackJob, ExpressionJob], runtime_context: RuntimeContext, TMPDIR_LOCK: threading.Lock) -> None:\n        '''Job running thread.'''\n        pass\n\n    def run_job(self, job: Optional[JobsType], runtime_context: RuntimeContext) -> None:\n        '''Execute a single Job in a separate thread.'''\n        pass\n\n    def wait_for_next_completion(self, runtime_context: RuntimeContext) -> None:\n        '''Wait for jobs to finish.'''\n        pass\n\n    def run_jobs(self, process: Process, job_order_object: CWLObjectType, logger: logging.Logger, runtime_context: RuntimeContext) -> None:\n        pass\nCorresponding class implementation:\n\nfrom .task_queue import TaskQueue\nimport logging\nfrom .errors import WorkflowException\nfrom .context import RuntimeContext, getdefault\nfrom .loghandler import _logger\nimport threading\nfrom .command_line_tool import CallbackJob, ExpressionJob\nfrom .process import Process, cleanIntermediate, relocateOutputs\nfrom .workflow_job import WorkflowJob, WorkflowJobStep\nimport math\nfrom typing import Optional, Union, cast\nfrom .job import JobBase\nimport psutil\nfrom .cuda import cuda_version_and_device_count\nfrom .utils import CWLObjectType, JobsType\nimport functools\n\nclass MultithreadedJobExecutor(JobExecutor):\n    \"\"\"\n    Experimental multi-threaded CWL executor.\n\n    Does simple resource accounting, will not start a job unless it\n    has cores / ram available, but does not make any attempt to\n    optimize usage.\n    \"\"\"\n\n    def __init__(self) -> None:\n        \"\"\"Initialize.\"\"\"\n        super().__init__()\n        self.exceptions: list[WorkflowException] = []\n        self.pending_jobs: list[JobsType] = []\n        self.pending_jobs_lock = threading.Lock()\n        self.max_ram = int(psutil.virtual_memory().available / 2 ** 20)\n        self.max_cores = float(psutil.cpu_count() or 1)\n        self.max_cuda = cuda_version_and_device_count()[1]\n        self.allocated_ram = float(0)\n        self.allocated_cores = float(0)\n        self.allocated_cuda: int = 0\n\n    def select_resources(self, request: dict[str, Union[int, float]], runtime_context: RuntimeContext) -> dict[str, Union[int, float]]:\n        \"\"\"Naïve check for available cpu cores and memory.\"\"\"\n        result: dict[str, Union[int, float]] = {}\n        maxrsc = {'cores': self.max_cores, 'ram': self.max_ram}\n        resources_types = {'cores', 'ram'}\n        if 'cudaDeviceCountMin' in request or 'cudaDeviceCountMax' in request:\n            maxrsc['cudaDeviceCount'] = self.max_cuda\n            resources_types.add('cudaDeviceCount')\n        for rsc in resources_types:\n            rsc_min = request[rsc + 'Min']\n            if rsc_min > maxrsc[rsc]:\n                raise WorkflowException(f'Requested at least {rsc_min} {rsc} but only {maxrsc[rsc]} available')\n            rsc_max = request[rsc + 'Max']\n            if rsc_max < maxrsc[rsc]:\n                result[rsc] = math.ceil(rsc_max)\n            else:\n                result[rsc] = maxrsc[rsc]\n        result['tmpdirSize'] = math.ceil(request['tmpdirMin'])\n        result['outdirSize'] = math.ceil(request['outdirMin'])\n        return result\n\n    def _runner(self, job: Union[JobBase, WorkflowJob, CallbackJob, ExpressionJob], runtime_context: RuntimeContext, TMPDIR_LOCK: threading.Lock) -> None:\n        \"\"\"Job running thread.\"\"\"\n        try:\n            _logger.debug('job: {}, runtime_context: {}, TMPDIR_LOCK: {}'.format(job, runtime_context, TMPDIR_LOCK))\n            job.run(runtime_context, TMPDIR_LOCK)\n        except WorkflowException as err:\n            _logger.exception(f'Got workflow error: {err}')\n            self.exceptions.append(err)\n        except Exception as err:\n            _logger.exception(f'Got workflow error: {err}')\n            wf_exc = WorkflowException(str(err))\n            wf_exc.__cause__ = err\n            wf_exc.__suppress_context__ = True\n            self.exceptions.append(wf_exc)\n        finally:\n            if runtime_context.workflow_eval_lock:\n                with runtime_context.workflow_eval_lock:\n                    if isinstance(job, JobBase):\n                        ram = job.builder.resources['ram']\n                        self.allocated_ram -= ram\n                        cores = job.builder.resources['cores']\n                        self.allocated_cores -= cores\n                        cudaDevices: int = cast(int, job.builder.resources.get('cudaDeviceCount', 0))\n                        self.allocated_cuda -= cudaDevices\n                    runtime_context.workflow_eval_lock.notify_all()\n\n    def run_job(self, job: Optional[JobsType], runtime_context: RuntimeContext) -> None:\n        \"\"\"Execute a single Job in a separate thread.\"\"\"\n        if job is not None:\n            with self.pending_jobs_lock:\n                self.pending_jobs.append(job)\n        with self.pending_jobs_lock:\n            n = 0\n            while n + 1 <= len(self.pending_jobs):\n                job = self.pending_jobs[n]\n                if isinstance(job, JobBase):\n                    ram = job.builder.resources['ram']\n                    cores = job.builder.resources['cores']\n                    cudaDevices = cast(int, job.builder.resources.get('cudaDeviceCount', 0))\n                    if ram > self.max_ram or cores > self.max_cores or cudaDevices > self.max_cuda:\n                        _logger.error('Job \"%s\" cannot be run, requests more resources (%s) than available on this host (already allocated ram is %d, allocated cores is %d, allocated CUDA is %d, max ram %d, max cores %d, max CUDA %d).', job.name, job.builder.resources, self.allocated_ram, self.allocated_cores, self.allocated_cuda, self.max_ram, self.max_cores, self.max_cuda)\n                        self.pending_jobs.remove(job)\n                        return\n                    if self.allocated_ram + ram > self.max_ram or self.allocated_cores + cores > self.max_cores or self.allocated_cuda + cudaDevices > self.max_cuda:\n                        _logger.debug('Job \"%s\" cannot run yet, resources (%s) are not available (already allocated ram is %d, allocated cores is %d, allocated CUDA devices is %d, max ram %d, max cores %d, max CUDA %d).', job.name, job.builder.resources, self.allocated_ram, self.allocated_cores, self.allocated_cuda, self.max_ram, self.max_cores, self.max_cuda)\n                        n += 1\n                        continue\n                if isinstance(job, JobBase):\n                    ram = job.builder.resources['ram']\n                    self.allocated_ram += ram\n                    cores = job.builder.resources['cores']\n                    self.allocated_cores += cores\n                    cuda = cast(int, job.builder.resources.get('cudaDevices', 0))\n                    self.allocated_cuda += cuda\n                self.taskqueue.add(functools.partial(self._runner, job, runtime_context, TMPDIR_LOCK), runtime_context.workflow_eval_lock)\n                self.pending_jobs.remove(job)\n\n    def wait_for_next_completion(self, runtime_context: RuntimeContext) -> None:\n        \"\"\"Wait for jobs to finish.\"\"\"\n        if runtime_context.workflow_eval_lock is not None:\n            runtime_context.workflow_eval_lock.wait(timeout=3)\n        if self.exceptions:\n            raise self.exceptions[0]\n\n    def run_jobs(self, process: Process, job_order_object: CWLObjectType, logger: logging.Logger, runtime_context: RuntimeContext) -> None:\n        self.taskqueue: TaskQueue = TaskQueue(threading.Lock(), int(math.ceil(self.max_cores)))\n        try:\n            jobiter = process.job(job_order_object, self.output_callback, runtime_context)\n            if runtime_context.workflow_eval_lock is None:\n                raise WorkflowException('runtimeContext.workflow_eval_lock must not be None')\n            runtime_context.workflow_eval_lock.acquire()\n            for job in jobiter:\n                if job is not None:\n                    if isinstance(job, JobBase):\n                        job.builder = runtime_context.builder or job.builder\n                        if job.outdir is not None:\n                            self.output_dirs.add(job.outdir)\n                self.run_job(job, runtime_context)\n                if job is None:\n                    if self.taskqueue.in_flight > 0:\n                        self.wait_for_next_completion(runtime_context)\n                    else:\n                        logger.error('Workflow cannot make any more progress.')\n                        break\n            self.run_job(None, runtime_context)\n            while self.taskqueue.in_flight > 0:\n                self.wait_for_next_completion(runtime_context)\n                self.run_job(None, runtime_context)\n            runtime_context.workflow_eval_lock.release()\n        finally:\n            self.taskqueue.drain()\n            self.taskqueue.join()\n\nNow, implement the following class. Do not explain the code. The given class skeleton is as follows:\n\nclass ToolSelector:\n    '''\n    Primary interface for tool selection across single-agent and multi-agent scenarios.\n    Use `select_tools(task_description, num_agents=None, overlap=False, limit=5)` to pick or partition tools.\n    Override `select_tools` to implement custom selection strategies.\n    '''\n\n    def __init__(self, tools: List[Dict[str, Any]]):\n        '''\n        Initialize with available tools.\n        Args:\n            tools: List of tool definitions from ToolManager\n        '''\n        pass\n\n    def _select_for_task(self, task_description: str, limit: int=5) -> List[Dict[str, Any]]:\n        '''\n        Internal single-agent tool selection logic.\n        '''\n        pass\n\n    def _partition_tools_for_multi_agent(self, num_agents: int, overlap: bool=False, task_description: Optional[str]=None) -> List[List[Dict[str, Any]]]:\n        '''\n        Internal multi-agent tool partitioning logic.\n        '''\n        pass\n\n    def select_by_names(self, tool_names: List[str]) -> List[Any]:\n        '''Select tools by their names (case-insensitive).'''\n        pass\n\n    def filter_by_roles(self, role_patterns: Dict[str, List[str]]) -> Dict[str, List[Any]]:\n        '''Filter tools for each role based on name patterns.'''\n        pass\n\n    def filter_by_keywords(self, keywords: List[str], match_all: bool=False) -> List[Any]:\n        '''\n        Filter tools that match specified keywords in name or description.\n        Args:\n            keywords: List of keywords to match\n            match_all: If True, tools must match all keywords. If False, match any keyword.\n        Returns:\n            List of tools matching the criteria\n        '''\n        pass\n\n    def select_tools(self, task_description: str, num_agents: Optional[int]=None, overlap: bool=False, limit: int=5) -> Any:\n        '''\n        Unified public interface for tool selection.\n        - Single-agent (num_agents None or <=1): returns a flat list of top tools.\n        - Multi-agent (num_agents >1): returns a list of tool lists, one per agent.\n        Override this method to implement any custom logic.\n        '''\n        pass"
  }
]