[
  {
    "role": "assistant",
    "content": "You are an expert Python programmer who can correctly implement complete Python classes based on the provided class skeleton."
  },
  {
    "role": "user",
    "content": "For your understanding, following are some (skeleton, code) examples:\n\nExample skeleton:\n\n\nclass FivetranClient:\n    '''This class exposes methods on top of the Fivetran REST API.'''\n\n    def __init__(self, api_key: str, api_secret: str, request_max_retries: int, request_retry_delay: float, disable_schedule_on_trigger: bool):\n        pass\n    @property\n    def _auth(self) -> HTTPBasicAuth:\n        pass\n    @property\n    @cached_method\n    def _log(self) -> logging.Logger:\n        pass\n    @property\n    def api_base_url(self) -> str:\n        pass\n    @property\n    def api_connector_url(self) -> str:\n        pass\n\n    def _make_connector_request(self, method: str, endpoint: str, data: Optional[str]=None) -> Mapping[str, Any]:\n        pass\n\n    def _make_and_handle_request(self, method: str, endpoint: str, data: Optional[str]=None, params: Optional[Mapping[str, Any]]=None) -> Mapping[str, Any]:\n        '''Creates, sends and handles a request to the desired Fivetran API endpoint.\n        Args:\n            method (str): The http method to use for this request (e.g. \"POST\", \"GET\", \"PATCH\").\n            endpoint (str): The Fivetran API endpoint to send this request to.\n            data (Optional[str]): JSON-formatted data string to be included in the request.\n            params (Optional[Dict[str, Any]]): JSON-formatted query params to be included in the request.\n        Returns:\n            Dict[str, Any]: Parsed json data from the response to this request.\n        '''\n        pass\n\n    def _make_request(self, method: str, endpoint: str, data: Optional[str]=None, params: Optional[Mapping[str, Any]]=None) -> requests.Response:\n        '''Creates and sends a request to the desired Fivetran API endpoint.\n        Args:\n            method (str): The http method to use for this request (e.g. \"POST\", \"GET\", \"PATCH\").\n            endpoint (str): The Fivetran API endpoint to send this request to.\n            data (Optional[str]): JSON-formatted data string to be included in the request.\n            params (Optional[Dict[str, Any]]): JSON-formatted query params to be included in the request.\n        Returns:\n            Optional[requests.Response]: The `requests.Response` object for the request.\n        '''\n        pass\n\n    def get_connector_details(self, connector_id: str) -> Mapping[str, Any]:\n        '''Gets details about a given connector from the Fivetran API.\n        Args:\n            connector_id (str): The Fivetran Connector ID. You can retrieve this value from the\n                \"Setup\" tab of a given connector in the Fivetran UI.\n        Returns:\n            Dict[str, Any]: Parsed json data from the response to this request.\n        '''\n        pass\n\n    def list_connectors_for_group(self, group_id: str) -> Sequence[Mapping[str, Any]]:\n        '''Fetches a list of all connectors for a given group from the Fivetran API.\n        Args:\n            group_id (str): The Fivetran Group ID.\n        Returns:\n            List[Dict[str, Any]]: A List of parsed json data from the response to this request.\n        '''\n        pass\n\n    def get_schema_config_for_connector(self, connector_id: str, raise_on_not_found_error: bool=True) -> Mapping[str, Any]:\n        '''Fetches the connector schema config for a given connector from the Fivetran API.\n        Args:\n            connector_id (str): The Fivetran Connector ID.\n            raise_on_not_found_error (bool):\n                Whether to raise an exception if a 404 error is encountered. Defaults to True.\n        Returns:\n            Dict[str, Any]: Parsed json data from the response to this request.\n        '''\n        pass\n\n    def get_destination_details(self, destination_id: str) -> Mapping[str, Any]:\n        '''Fetches details about a given destination from the Fivetran API.\n        Args:\n            destination_id (str): The Fivetran Destination ID.\n        Returns:\n            Dict[str, Any]: Parsed json data from the response to this request.\n        '''\n        pass\n\n    def get_groups(self) -> Mapping[str, Any]:\n        '''Fetches all groups from the Fivetran API.\n        Returns:\n            Dict[str, Any]: Parsed json data from the response to this request.\n        '''\n        pass\n\n    def update_schedule_type_for_connector(self, connector_id: str, schedule_type: str) -> Mapping[str, Any]:\n        '''Updates the schedule type property of the connector to either \"auto\" or \"manual\".\n        Args:\n            connector_id (str): The Fivetran Connector ID. You can retrieve this value from the\n                \"Setup\" tab of a given connector in the Fivetran UI.\n            schedule_type (str): Either \"auto\" (to turn the schedule on) or \"manual\" (to\n                turn it off).\n        Returns:\n            Dict[str, Any]: Parsed json data representing the API response.\n        '''\n        pass\n\n    def get_columns_config_for_table(self, connector_id: str, schema_name: str, table_name: str) -> Mapping[str, Any]:\n        '''Fetches the source table columns config for a given table from the Fivetran API.\n        Args:\n            connector_id (str): The Fivetran Connector ID.\n            schema_name (str): The Fivetran Schema name.\n            table_name (str): The Fivetran Table name.\n        Returns:\n            Dict[str, Any]: Parsed json data from the response to this request.\n        '''\n        pass\n\n    def start_sync(self, connector_id: str) -> None:\n        '''Initiates a sync of a Fivetran connector.\n        Args:\n            connector_id (str): The Fivetran Connector ID. You can retrieve this value from the\n                \"Setup\" tab of a given connector in the Fivetran UI.\n        '''\n        pass\n\n    def start_resync(self, connector_id: str, resync_parameters: Optional[Mapping[str, Sequence[str]]]=None) -> None:\n        '''Initiates a historical sync of all data for multiple schema tables within a Fivetran connector.\n        Args:\n            connector_id (str): The Fivetran Connector ID. You can retrieve this value from the\n                \"Setup\" tab of a given connector in the Fivetran UI.\n            resync_parameters (Optional[Dict[str, List[str]]]): Optional resync parameters to send to the Fivetran API.\n                An example payload can be found here: https://fivetran.com/docs/rest-api/connectors#request_7\n        '''\n        pass\n\n    def _start_sync(self, request_fn: Callable[[], Mapping[str, Any]], connector_id: str) -> None:\n        pass\n\n    def poll_sync(self, connector_id: str, previous_sync_completed_at: datetime, poll_interval: float=DEFAULT_POLL_INTERVAL, poll_timeout: Optional[float]=None) -> Mapping[str, Any]:\n        '''Given a Fivetran connector and the timestamp at which the previous sync completed, poll\n        until the next sync completes.\n        The previous sync completion time is necessary because the only way to tell when a sync\n        completes is when this value changes.\n        Args:\n            connector_id (str): The Fivetran Connector ID. You can retrieve this value from the\n                \"Setup\" tab of a given connector in the Fivetran UI.\n            previous_sync_completed_at (datetime.datetime): The datetime of the previous completed sync\n                (successful or otherwise) for this connector, prior to running this method.\n            poll_interval (float): The time (in seconds) that will be waited between successive polls.\n            poll_timeout (float): The maximum time that will wait before this operation is timed\n                out. By default, this will never time out.\n        Returns:\n            Dict[str, Any]: Parsed json data representing the API response.\n        '''\n        pass\n\n    def sync_and_poll(self, connector_id: str, poll_interval: float=DEFAULT_POLL_INTERVAL, poll_timeout: Optional[float]=None) -> Optional[FivetranOutput]:\n        '''Initializes a sync operation for the given connector, and polls until it completes.\n        Args:\n            connector_id (str): The Fivetran Connector ID. You can retrieve this value from the\n                \"Setup\" tab of a given connector in the Fivetran UI.\n            poll_interval (float): The time (in seconds) that will be waited between successive polls.\n            poll_timeout (float): The maximum time that will wait before this operation is timed\n                out. By default, this will never time out.\n        Returns:\n            Optional[FivetranOutput]:\n                Returns a :py:class:`~FivetranOutput` object containing details\n                about the connector and the tables it synced. If the connector is not synced, None is returned.\n        '''\n        pass\n\n    def resync_and_poll(self, connector_id: str, poll_interval: float=DEFAULT_POLL_INTERVAL, poll_timeout: Optional[float]=None, resync_parameters: Optional[Mapping[str, Sequence[str]]]=None) -> Optional[FivetranOutput]:\n        '''Initializes a historical resync operation for the given connector, and polls until it completes.\n        Args:\n            connector_id (str): The Fivetran Connector ID. You can retrieve this value from the\n                \"Setup\" tab of a given connector in the Fivetran UI.\n            resync_parameters (Dict[str, List[str]]): The payload to send to the Fivetran API.\n                This should be a dictionary with schema names as the keys and a list of tables\n                to resync as the values.\n            poll_interval (float): The time (in seconds) that will be waited between successive polls.\n            poll_timeout (float): The maximum time that will wait before this operation is timed\n                out. By default, this will never time out.\n        Returns:\n            Optional[FivetranOutput]:\n                Returns a :py:class:`~FivetranOutput` object containing details\n                about the connector and the tables it synced. If the connector is not synced, None is returned.\n        '''\n        pass\n\n    def _sync_and_poll(self, sync_fn: Callable, connector_id: str, poll_interval: float=DEFAULT_POLL_INTERVAL, poll_timeout: Optional[float]=None) -> Optional[FivetranOutput]:\n        pass\nCorresponding class implementation:\n\nimport time\nimport logging\nfrom dagster_fivetran.translator import ConnectorSelectorFn, DagsterFivetranTranslator, FivetranConnector, FivetranConnectorScheduleType, FivetranConnectorTableProps, FivetranDestination, FivetranMetadataSet, FivetranSchemaConfig, FivetranWorkspaceData\nfrom collections.abc import Mapping, Sequence\nimport os\nfrom datetime import datetime, timedelta\nfrom requests.auth import HTTPBasicAuth\nfrom functools import cached_property, partial\nimport json\nimport requests\nfrom dagster import AssetExecutionContext, AssetMaterialization, Definitions, Failure, InitResourceContext, MaterializeResult, MetadataValue, __version__, _check as check, get_dagster_logger, resource\nfrom dagster._utils.cached_method import cached_method\nfrom dagster_fivetran.types import FivetranOutput\nfrom typing import Any, Callable, Optional, Union\nfrom requests.exceptions import RequestException\n\nclass FivetranClient:\n    \"\"\"This class exposes methods on top of the Fivetran REST API.\"\"\"\n\n    def __init__(self, api_key: str, api_secret: str, request_max_retries: int, request_retry_delay: float, disable_schedule_on_trigger: bool):\n        self.api_key = api_key\n        self.api_secret = api_secret\n        self.request_max_retries = request_max_retries\n        self.request_retry_delay = request_retry_delay\n        self.disable_schedule_on_trigger = disable_schedule_on_trigger\n\n    @property\n    def _auth(self) -> HTTPBasicAuth:\n        return HTTPBasicAuth(self.api_key, self.api_secret)\n\n    @property\n    @cached_method\n    def _log(self) -> logging.Logger:\n        return get_dagster_logger()\n\n    @property\n    def api_base_url(self) -> str:\n        return f'{FIVETRAN_API_BASE}/{FIVETRAN_API_VERSION}'\n\n    @property\n    def api_connector_url(self) -> str:\n        return f'{self.api_base_url}/{FIVETRAN_CONNECTOR_ENDPOINT}'\n\n    def _make_connector_request(self, method: str, endpoint: str, data: Optional[str]=None) -> Mapping[str, Any]:\n        return self._make_and_handle_request(method, f'{FIVETRAN_CONNECTOR_ENDPOINT}/{endpoint}', data)\n\n    def _make_and_handle_request(self, method: str, endpoint: str, data: Optional[str]=None, params: Optional[Mapping[str, Any]]=None) -> Mapping[str, Any]:\n        \"\"\"Creates, sends and handles a request to the desired Fivetran API endpoint.\n\n        Args:\n            method (str): The http method to use for this request (e.g. \"POST\", \"GET\", \"PATCH\").\n            endpoint (str): The Fivetran API endpoint to send this request to.\n            data (Optional[str]): JSON-formatted data string to be included in the request.\n            params (Optional[Dict[str, Any]]): JSON-formatted query params to be included in the request.\n\n        Returns:\n            Dict[str, Any]: Parsed json data from the response to this request.\n        \"\"\"\n        response = self._make_request(method=method, endpoint=endpoint, data=data, params=params)\n        try:\n            response.raise_for_status()\n            resp_dict = response.json()\n            return resp_dict['data'] if 'data' in resp_dict else resp_dict\n        except RequestException as e:\n            raise Failure(f'Max retries ({self.request_max_retries}) exceeded with url: {response.url}. Caused by {e}')\n\n    def _make_request(self, method: str, endpoint: str, data: Optional[str]=None, params: Optional[Mapping[str, Any]]=None) -> requests.Response:\n        \"\"\"Creates and sends a request to the desired Fivetran API endpoint.\n\n        Args:\n            method (str): The http method to use for this request (e.g. \"POST\", \"GET\", \"PATCH\").\n            endpoint (str): The Fivetran API endpoint to send this request to.\n            data (Optional[str]): JSON-formatted data string to be included in the request.\n            params (Optional[Dict[str, Any]]): JSON-formatted query params to be included in the request.\n\n        Returns:\n            Optional[requests.Response]: The `requests.Response` object for the request.\n        \"\"\"\n        url = f'{self.api_base_url}/{endpoint}'\n        headers = {'User-Agent': f'dagster-fivetran/{__version__}', 'Content-Type': 'application/json;version=2'}\n        num_retries = 0\n        while True:\n            try:\n                response = requests.request(method=method, url=url, headers=headers, auth=self._auth, data=data, params=params, timeout=int(os.getenv('DAGSTER_FIVETRAN_API_REQUEST_TIMEOUT', '60')))\n                response.raise_for_status()\n                return response\n            except RequestException as e:\n                self._log.error('Request to Fivetran API failed: %s', e)\n                if num_retries == self.request_max_retries:\n                    return response\n                num_retries += 1\n                time.sleep(self.request_retry_delay)\n\n    def get_connector_details(self, connector_id: str) -> Mapping[str, Any]:\n        \"\"\"Gets details about a given connector from the Fivetran API.\n\n        Args:\n            connector_id (str): The Fivetran Connector ID. You can retrieve this value from the\n                \"Setup\" tab of a given connector in the Fivetran UI.\n\n        Returns:\n            Dict[str, Any]: Parsed json data from the response to this request.\n        \"\"\"\n        return self._make_connector_request(method='GET', endpoint=connector_id)\n\n    def list_connectors_for_group(self, group_id: str) -> Sequence[Mapping[str, Any]]:\n        \"\"\"Fetches a list of all connectors for a given group from the Fivetran API.\n\n        Args:\n            group_id (str): The Fivetran Group ID.\n\n        Returns:\n            List[Dict[str, Any]]: A List of parsed json data from the response to this request.\n        \"\"\"\n        results = []\n        cursor = None\n        while True:\n            data = self._make_and_handle_request(method='GET', endpoint=f'groups/{group_id}/connectors', params={'limit': DAGSTER_FIVETRAN_LIST_CONNECTIONS_FOR_GROUP_INDIVIDUAL_REQUEST_LIMIT, **({'cursor': cursor} if cursor else {})})\n            connectors = data['items']\n            cursor = data.get('nextCursor')\n            results.extend(connectors)\n            if not cursor:\n                break\n        return results\n\n    def get_schema_config_for_connector(self, connector_id: str, raise_on_not_found_error: bool=True) -> Mapping[str, Any]:\n        \"\"\"Fetches the connector schema config for a given connector from the Fivetran API.\n\n        Args:\n            connector_id (str): The Fivetran Connector ID.\n            raise_on_not_found_error (bool):\n                Whether to raise an exception if a 404 error is encountered. Defaults to True.\n\n        Returns:\n            Dict[str, Any]: Parsed json data from the response to this request.\n        \"\"\"\n        response = self._make_request('GET', f'connectors/{connector_id}/schemas')\n        try:\n            response.raise_for_status()\n            resp_dict = response.json()\n            return resp_dict['data'] if 'data' in resp_dict else resp_dict\n        except RequestException as e:\n            if not raise_on_not_found_error and e.response is not None and (e.response.status_code == 404):\n                self._log.warning(f'Schema config was not found for connector with ID {connector_id}.')\n                return {}\n            else:\n                raise Failure(f'Max retries ({self.request_max_retries}) exceeded with url: {response.url}. Caused by {e}')\n\n    def get_destination_details(self, destination_id: str) -> Mapping[str, Any]:\n        \"\"\"Fetches details about a given destination from the Fivetran API.\n\n        Args:\n            destination_id (str): The Fivetran Destination ID.\n\n        Returns:\n            Dict[str, Any]: Parsed json data from the response to this request.\n        \"\"\"\n        return self._make_and_handle_request('GET', f'destinations/{destination_id}')\n\n    def get_groups(self) -> Mapping[str, Any]:\n        \"\"\"Fetches all groups from the Fivetran API.\n\n        Returns:\n            Dict[str, Any]: Parsed json data from the response to this request.\n        \"\"\"\n        return self._make_and_handle_request('GET', 'groups')\n\n    def update_schedule_type_for_connector(self, connector_id: str, schedule_type: str) -> Mapping[str, Any]:\n        \"\"\"Updates the schedule type property of the connector to either \"auto\" or \"manual\".\n\n        Args:\n            connector_id (str): The Fivetran Connector ID. You can retrieve this value from the\n                \"Setup\" tab of a given connector in the Fivetran UI.\n            schedule_type (str): Either \"auto\" (to turn the schedule on) or \"manual\" (to\n                turn it off).\n\n        Returns:\n            Dict[str, Any]: Parsed json data representing the API response.\n        \"\"\"\n        schedule_types = {s for s in FivetranConnectorScheduleType}\n        if schedule_type not in schedule_types:\n            check.failed(f\"The schedule_type for connector {connector_id} must be in {schedule_types}: got '{schedule_type}'\")\n        return self._make_connector_request(method='PATCH', endpoint=connector_id, data=json.dumps({'schedule_type': schedule_type}))\n\n    def get_columns_config_for_table(self, connector_id: str, schema_name: str, table_name: str) -> Mapping[str, Any]:\n        \"\"\"Fetches the source table columns config for a given table from the Fivetran API.\n\n        Args:\n            connector_id (str): The Fivetran Connector ID.\n            schema_name (str): The Fivetran Schema name.\n            table_name (str): The Fivetran Table name.\n\n        Returns:\n            Dict[str, Any]: Parsed json data from the response to this request.\n        \"\"\"\n        return self._make_connector_request(method='GET', endpoint=f'{connector_id}/schemas/{schema_name}/tables/{table_name}/columns')\n\n    def start_sync(self, connector_id: str) -> None:\n        \"\"\"Initiates a sync of a Fivetran connector.\n\n        Args:\n            connector_id (str): The Fivetran Connector ID. You can retrieve this value from the\n                \"Setup\" tab of a given connector in the Fivetran UI.\n\n        \"\"\"\n        request_fn = partial(self._make_connector_request, method='POST', endpoint=f'{connector_id}/force')\n        self._start_sync(request_fn=request_fn, connector_id=connector_id)\n\n    def start_resync(self, connector_id: str, resync_parameters: Optional[Mapping[str, Sequence[str]]]=None) -> None:\n        \"\"\"Initiates a historical sync of all data for multiple schema tables within a Fivetran connector.\n\n        Args:\n            connector_id (str): The Fivetran Connector ID. You can retrieve this value from the\n                \"Setup\" tab of a given connector in the Fivetran UI.\n            resync_parameters (Optional[Dict[str, List[str]]]): Optional resync parameters to send to the Fivetran API.\n                An example payload can be found here: https://fivetran.com/docs/rest-api/connectors#request_7\n        \"\"\"\n        request_fn = partial(self._make_connector_request, method='POST', endpoint=f'{connector_id}/schemas/tables/resync' if resync_parameters is not None else f'{connector_id}/resync', data=json.dumps(resync_parameters) if resync_parameters is not None else None)\n        self._start_sync(request_fn=request_fn, connector_id=connector_id)\n\n    def _start_sync(self, request_fn: Callable[[], Mapping[str, Any]], connector_id: str) -> None:\n        connector = FivetranConnector.from_connector_details(connector_details=self.get_connector_details(connector_id))\n        connector.validate_syncable()\n        if self.disable_schedule_on_trigger:\n            self._log.info(f'Disabling Fivetran sync schedule for connector {connector_id}.')\n            self.update_schedule_type_for_connector(connector_id, 'manual')\n        request_fn()\n        self._log.info(f'Sync initialized for connector {connector_id}. View this sync in the Fivetran UI: ' + connector.url)\n\n    def poll_sync(self, connector_id: str, previous_sync_completed_at: datetime, poll_interval: float=DEFAULT_POLL_INTERVAL, poll_timeout: Optional[float]=None) -> Mapping[str, Any]:\n        \"\"\"Given a Fivetran connector and the timestamp at which the previous sync completed, poll\n        until the next sync completes.\n\n        The previous sync completion time is necessary because the only way to tell when a sync\n        completes is when this value changes.\n\n        Args:\n            connector_id (str): The Fivetran Connector ID. You can retrieve this value from the\n                \"Setup\" tab of a given connector in the Fivetran UI.\n            previous_sync_completed_at (datetime.datetime): The datetime of the previous completed sync\n                (successful or otherwise) for this connector, prior to running this method.\n            poll_interval (float): The time (in seconds) that will be waited between successive polls.\n            poll_timeout (float): The maximum time that will wait before this operation is timed\n                out. By default, this will never time out.\n\n        Returns:\n            Dict[str, Any]: Parsed json data representing the API response.\n        \"\"\"\n        poll_start = datetime.now()\n        while True:\n            connector_details = self.get_connector_details(connector_id)\n            connector = FivetranConnector.from_connector_details(connector_details=connector_details)\n            self._log.info(f\"Polled '{connector_id}'. Status: [{connector.sync_state}]\")\n            if connector.last_sync_completed_at > previous_sync_completed_at:\n                break\n            if poll_timeout and datetime.now() > poll_start + timedelta(seconds=poll_timeout):\n                raise Failure(f\"Sync for connector '{connector_id}' timed out after {datetime.now() - poll_start}.\")\n            time.sleep(poll_interval)\n        if not connector.is_last_sync_successful:\n            raise Failure(f\"Sync for connector '{connector_id}' failed!\", metadata={'connector_details': MetadataValue.json(connector_details), 'log_url': MetadataValue.url(connector.url)})\n        return connector_details\n\n    def sync_and_poll(self, connector_id: str, poll_interval: float=DEFAULT_POLL_INTERVAL, poll_timeout: Optional[float]=None) -> Optional[FivetranOutput]:\n        \"\"\"Initializes a sync operation for the given connector, and polls until it completes.\n\n        Args:\n            connector_id (str): The Fivetran Connector ID. You can retrieve this value from the\n                \"Setup\" tab of a given connector in the Fivetran UI.\n            poll_interval (float): The time (in seconds) that will be waited between successive polls.\n            poll_timeout (float): The maximum time that will wait before this operation is timed\n                out. By default, this will never time out.\n\n        Returns:\n            Optional[FivetranOutput]:\n                Returns a :py:class:`~FivetranOutput` object containing details\n                about the connector and the tables it synced. If the connector is not synced, None is returned.\n        \"\"\"\n        return self._sync_and_poll(sync_fn=self.start_sync, connector_id=connector_id, poll_interval=poll_interval, poll_timeout=poll_timeout)\n\n    def resync_and_poll(self, connector_id: str, poll_interval: float=DEFAULT_POLL_INTERVAL, poll_timeout: Optional[float]=None, resync_parameters: Optional[Mapping[str, Sequence[str]]]=None) -> Optional[FivetranOutput]:\n        \"\"\"Initializes a historical resync operation for the given connector, and polls until it completes.\n\n        Args:\n            connector_id (str): The Fivetran Connector ID. You can retrieve this value from the\n                \"Setup\" tab of a given connector in the Fivetran UI.\n            resync_parameters (Dict[str, List[str]]): The payload to send to the Fivetran API.\n                This should be a dictionary with schema names as the keys and a list of tables\n                to resync as the values.\n            poll_interval (float): The time (in seconds) that will be waited between successive polls.\n            poll_timeout (float): The maximum time that will wait before this operation is timed\n                out. By default, this will never time out.\n\n        Returns:\n            Optional[FivetranOutput]:\n                Returns a :py:class:`~FivetranOutput` object containing details\n                about the connector and the tables it synced. If the connector is not synced, None is returned.\n        \"\"\"\n        return self._sync_and_poll(sync_fn=partial(self.start_resync, resync_parameters=resync_parameters), connector_id=connector_id, poll_interval=poll_interval, poll_timeout=poll_timeout)\n\n    def _sync_and_poll(self, sync_fn: Callable, connector_id: str, poll_interval: float=DEFAULT_POLL_INTERVAL, poll_timeout: Optional[float]=None) -> Optional[FivetranOutput]:\n        schema_config_details = self.get_schema_config_for_connector(connector_id)\n        connector = FivetranConnector.from_connector_details(connector_details=self.get_connector_details(connector_id))\n        if connector.paused:\n            self._log.warning(f'Cannot sync connector {connector.name} with ID {connector.id} because the connector is paused. Make sure the connector is enabled before syncing it.')\n            return None\n        sync_fn(connector_id=connector_id)\n        final_details = self.poll_sync(connector_id=connector_id, previous_sync_completed_at=connector.last_sync_completed_at, poll_interval=poll_interval, poll_timeout=poll_timeout)\n        return FivetranOutput(connector_details=final_details, schema_config=schema_config_details)\n\nExample skeleton:\n\n\nclass ExasolHook(DbApiHook):\n    '''\n    Interact with Exasol.\n    You can specify the pyexasol ``compression``, ``encryption``, ``json_lib``\n    and ``client_name``  parameters in the extra field of your connection\n    as ``{\"compression\": True, \"json_lib\": \"rapidjson\", etc}``.\n    See `pyexasol reference\n    <https://github.com/badoo/pyexasol/blob/master/docs/REFERENCE.md#connect>`_\n    for more details.\n    '''\n\n    def __init__(self, *args, sqlalchemy_scheme: str | None=None, **kwargs) -> None:\n        pass\n\n    def get_conn(self) -> ExaConnection:\n        pass\n    @property\n    def sqlalchemy_scheme(self) -> str:\n        '''Sqlalchemy scheme either from constructor, connection extras or default.'''\n        pass\n    @property\n    def sqlalchemy_url(self) -> URL:\n        '''\n        Return a Sqlalchemy.engine.URL object from the connection.\n        :return: the extracted sqlalchemy.engine.URL object.\n        '''\n        pass\n\n    def get_uri(self) -> str:\n        '''\n        Extract the URI from the connection.\n        :return: the extracted uri.\n        '''\n        pass\n\n    def _get_pandas_df(self, sql, parameters: Iterable | Mapping[str, Any] | None=None, **kwargs) -> pd.DataFrame:\n        '''\n        Execute the SQL and return a Pandas dataframe.\n        :param sql: The sql statement to be executed (str) or a list of\n            sql statements to execute.\n        :param parameters: The parameters to render the SQL query with.\n        Other keyword arguments are all forwarded into\n        ``pyexasol.ExaConnection.export_to_pandas``.\n        '''\n        pass\n    @deprecated(reason='Replaced by function `get_df`.', category=AirflowProviderDeprecationWarning, action='ignore')\n    def get_pandas_df(self, sql, parameters: list | tuple | Mapping[str, Any] | None=None, **kwargs) -> pd.DataFrame:\n        '''\n        Execute the sql and returns a pandas dataframe.\n        :param sql: the sql statement to be executed (str) or a list of sql statements to execute\n        :param parameters: The parameters to render the SQL query with.\n        :param kwargs: (optional) passed into pandas.io.sql.read_sql method\n        '''\n        pass\n\n    def _get_polars_df(self, sql, parameters: list | tuple | Mapping[str, Any] | None=None, **kwargs):\n        pass\n\n    def get_records(self, sql: str | list[str], parameters: Iterable | Mapping[str, Any] | None=None) -> list[dict | tuple[Any, ...]]:\n        '''\n        Execute the SQL and return a set of records.\n        :param sql: the sql statement to be executed (str) or a list of\n            sql statements to execute\n        :param parameters: The parameters to render the SQL query with.\n        '''\n        pass\n\n    def get_first(self, sql: str | list[str], parameters: Iterable | Mapping[str, Any] | None=None) -> Any:\n        '''\n        Execute the SQL and return the first resulting row.\n        :param sql: the sql statement to be executed (str) or a list of\n            sql statements to execute\n        :param parameters: The parameters to render the SQL query with.\n        '''\n        pass\n\n    def export_to_file(self, filename: str, query_or_table: str, query_params: dict | None=None, export_params: dict | None=None) -> None:\n        '''\n        Export data to a file.\n        :param filename: Path to the file to which the data has to be exported\n        :param query_or_table: the sql statement to be executed or table name to export\n        :param query_params: Query parameters passed to underlying ``export_to_file``\n            method of :class:`~pyexasol.connection.ExaConnection`.\n        :param export_params: Extra parameters passed to underlying ``export_to_file``\n            method of :class:`~pyexasol.connection.ExaConnection`.\n        '''\n        pass\n    @staticmethod\n    def get_description(statement: ExaStatement) -> Sequence[Sequence]:\n        '''\n        Get description; copied implementation from DB2-API wrapper.\n        For more info, see\n        https://github.com/exasol/pyexasol/blob/master/docs/DBAPI_COMPAT.md#db-api-20-wrapper\n        :param statement: Exasol statement\n        :return: description sequence of t\n        '''\n        pass\n    @overload\n    def run(self, sql: str | Iterable[str], autocommit: bool=..., parameters: Iterable | Mapping[str, Any] | None=..., handler: None=..., split_statements: bool=..., return_last: bool=...) -> None:\n        pass\n    @overload\n    def run(self, sql: str | Iterable[str], autocommit: bool=..., parameters: Iterable | Mapping[str, Any] | None=..., handler: None=..., split_statements: bool=..., return_last: bool=...) -> None:\n        pass\n    def run(self, sql: str | Iterable[str], autocommit: bool=..., parameters: Iterable | Mapping[str, Any] | None=..., handler: None=..., split_statements: bool=..., return_last: bool=...) -> None:\n        '''\n        Run a command or a list of commands.\n        Pass a list of SQL statements to the SQL parameter to get them to\n        execute sequentially.\n        :param sql: the sql statement to be executed (str) or a list of\n            sql statements to execute\n        :param autocommit: What to set the connection's autocommit setting to\n            before executing the query.\n        :param parameters: The parameters to render the SQL query with.\n        :param handler: The result handler which is called with the result of each statement.\n        :param split_statements: Whether to split a single SQL string into statements and run separately\n        :param return_last: Whether to return result for only last statement or for all after split\n        :return: return only result of the LAST SQL expression if handler was provided.\n        '''\n        pass\n\n    def set_autocommit(self, conn, autocommit: bool) -> None:\n        '''\n        Set the autocommit flag on the connection.\n        :param conn: Connection to set autocommit setting to.\n        :param autocommit: The autocommit setting to set.\n        '''\n        pass\n\n    def get_autocommit(self, conn) -> bool:\n        '''\n        Get autocommit setting for the provided connection.\n        :param conn: Connection to get autocommit setting from.\n        :return: connection autocommit setting. True if ``autocommit`` is set\n            to True on the connection. False if it is either not set, set to\n            False, or the connection does not support auto-commit.\n        '''\n        pass\n    @staticmethod\n    def _serialize_cell(cell, conn=None) -> Any:\n        '''\n        Override to disable cell serialization.\n        Exasol will adapt all arguments to the ``execute()`` method internally,\n        hence we return cell without any conversion.\n        :param cell: The cell to insert into the table\n        :param conn: The database connection\n        :return: The cell\n        '''\n        pass\nCorresponding class implementation:\n\nimport pyexasol\nfrom collections.abc import Callable, Iterable, Mapping, Sequence\nfrom pyexasol import ExaConnection, ExaStatement\nfrom typing import TYPE_CHECKING, Any, TypeVar, overload\nfrom airflow.providers.common.sql.hooks.handlers import return_single_query_results\nfrom airflow.providers.common.sql.hooks.sql import DbApiHook\nfrom deprecated import deprecated\nfrom sqlalchemy.engine import URL\nfrom airflow.exceptions import AirflowProviderDeprecationWarning\nfrom contextlib import closing\n\nclass ExasolHook(DbApiHook):\n    \"\"\"\n    Interact with Exasol.\n\n    You can specify the pyexasol ``compression``, ``encryption``, ``json_lib``\n    and ``client_name``  parameters in the extra field of your connection\n    as ``{\"compression\": True, \"json_lib\": \"rapidjson\", etc}``.\n\n    See `pyexasol reference\n    <https://github.com/badoo/pyexasol/blob/master/docs/REFERENCE.md#connect>`_\n    for more details.\n    \"\"\"\n    conn_name_attr = 'exasol_conn_id'\n    default_conn_name = 'exasol_default'\n    conn_type = 'exasol'\n    hook_name = 'Exasol'\n    supports_autocommit = True\n    DEFAULT_SQLALCHEMY_SCHEME = 'exa+websocket'\n\n    def __init__(self, *args, sqlalchemy_scheme: str | None=None, **kwargs) -> None:\n        super().__init__(*args, **kwargs)\n        self.schema = kwargs.pop('schema', None)\n        self._sqlalchemy_scheme = sqlalchemy_scheme\n\n    def get_conn(self) -> ExaConnection:\n        conn = self.get_connection(self.get_conn_id())\n        conn_args = {'dsn': f'{conn.host}:{conn.port}', 'user': conn.login, 'password': conn.password, 'schema': self.schema or conn.schema}\n        for arg_name, arg_val in conn.extra_dejson.items():\n            if arg_name in ['compression', 'encryption', 'json_lib', 'client_name']:\n                conn_args[arg_name] = arg_val\n        conn = pyexasol.connect(**conn_args)\n        return conn\n\n    @property\n    def sqlalchemy_scheme(self) -> str:\n        \"\"\"Sqlalchemy scheme either from constructor, connection extras or default.\"\"\"\n        extra_scheme = self.connection is not None and self.connection_extra_lower.get('sqlalchemy_scheme')\n        sqlalchemy_scheme = self._sqlalchemy_scheme or extra_scheme or self.DEFAULT_SQLALCHEMY_SCHEME\n        if sqlalchemy_scheme not in ['exa+websocket', 'exa+pyodbc', 'exa+turbodbc']:\n            raise ValueError(f\"sqlalchemy_scheme in connection extra should be one of 'exa+websocket', 'exa+pyodbc' or 'exa+turbodbc', but got '{sqlalchemy_scheme}'. See https://github.com/exasol/sqlalchemy-exasol?tab=readme-ov-file#using-sqlalchemy-with-exasol-db for more details.\")\n        return sqlalchemy_scheme\n\n    @property\n    def sqlalchemy_url(self) -> URL:\n        \"\"\"\n        Return a Sqlalchemy.engine.URL object from the connection.\n\n        :return: the extracted sqlalchemy.engine.URL object.\n        \"\"\"\n        connection = self.connection\n        query = connection.extra_dejson\n        query = {k: v for k, v in query.items() if k.lower() != 'sqlalchemy_scheme'}\n        return URL.create(drivername=self.sqlalchemy_scheme, username=connection.login, password=connection.password, host=connection.host, port=connection.port, database=self.schema or connection.schema, query=query)\n\n    def get_uri(self) -> str:\n        \"\"\"\n        Extract the URI from the connection.\n\n        :return: the extracted uri.\n        \"\"\"\n        return self.sqlalchemy_url.render_as_string(hide_password=False)\n\n    def _get_pandas_df(self, sql, parameters: Iterable | Mapping[str, Any] | None=None, **kwargs) -> pd.DataFrame:\n        \"\"\"\n        Execute the SQL and return a Pandas dataframe.\n\n        :param sql: The sql statement to be executed (str) or a list of\n            sql statements to execute.\n        :param parameters: The parameters to render the SQL query with.\n\n        Other keyword arguments are all forwarded into\n        ``pyexasol.ExaConnection.export_to_pandas``.\n        \"\"\"\n        with closing(self.get_conn()) as conn:\n            df = conn.export_to_pandas(sql, query_params=parameters, **kwargs)\n            return df\n\n    @deprecated(reason='Replaced by function `get_df`.', category=AirflowProviderDeprecationWarning, action='ignore')\n    def get_pandas_df(self, sql, parameters: list | tuple | Mapping[str, Any] | None=None, **kwargs) -> pd.DataFrame:\n        \"\"\"\n        Execute the sql and returns a pandas dataframe.\n\n        :param sql: the sql statement to be executed (str) or a list of sql statements to execute\n        :param parameters: The parameters to render the SQL query with.\n        :param kwargs: (optional) passed into pandas.io.sql.read_sql method\n        \"\"\"\n        return self._get_pandas_df(sql, parameters, **kwargs)\n\n    def _get_polars_df(self, sql, parameters: list | tuple | Mapping[str, Any] | None=None, **kwargs):\n        raise NotImplementedError('Polars is not supported for Exasol')\n\n    def get_records(self, sql: str | list[str], parameters: Iterable | Mapping[str, Any] | None=None) -> list[dict | tuple[Any, ...]]:\n        \"\"\"\n        Execute the SQL and return a set of records.\n\n        :param sql: the sql statement to be executed (str) or a list of\n            sql statements to execute\n        :param parameters: The parameters to render the SQL query with.\n        \"\"\"\n        with closing(self.get_conn()) as conn, closing(conn.execute(sql, parameters)) as cur:\n            return cur.fetchall()\n\n    def get_first(self, sql: str | list[str], parameters: Iterable | Mapping[str, Any] | None=None) -> Any:\n        \"\"\"\n        Execute the SQL and return the first resulting row.\n\n        :param sql: the sql statement to be executed (str) or a list of\n            sql statements to execute\n        :param parameters: The parameters to render the SQL query with.\n        \"\"\"\n        with closing(self.get_conn()) as conn, closing(conn.execute(sql, parameters)) as cur:\n            return cur.fetchone()\n\n    def export_to_file(self, filename: str, query_or_table: str, query_params: dict | None=None, export_params: dict | None=None) -> None:\n        \"\"\"\n        Export data to a file.\n\n        :param filename: Path to the file to which the data has to be exported\n        :param query_or_table: the sql statement to be executed or table name to export\n        :param query_params: Query parameters passed to underlying ``export_to_file``\n            method of :class:`~pyexasol.connection.ExaConnection`.\n        :param export_params: Extra parameters passed to underlying ``export_to_file``\n            method of :class:`~pyexasol.connection.ExaConnection`.\n        \"\"\"\n        self.log.info('Getting data from exasol')\n        with closing(self.get_conn()) as conn:\n            conn.export_to_file(dst=filename, query_or_table=query_or_table, query_params=query_params, export_params=export_params)\n        self.log.info('Data saved to %s', filename)\n\n    @staticmethod\n    def get_description(statement: ExaStatement) -> Sequence[Sequence]:\n        \"\"\"\n        Get description; copied implementation from DB2-API wrapper.\n\n        For more info, see\n        https://github.com/exasol/pyexasol/blob/master/docs/DBAPI_COMPAT.md#db-api-20-wrapper\n\n        :param statement: Exasol statement\n        :return: description sequence of t\n        \"\"\"\n        cols = []\n        for k, v in statement.columns().items():\n            cols.append((k, v.get('type', None), v.get('size', None), v.get('size', None), v.get('precision', None), v.get('scale', None), True))\n        return cols\n\n    @overload\n    def run(self, sql: str | Iterable[str], autocommit: bool=..., parameters: Iterable | Mapping[str, Any] | None=..., handler: None=..., split_statements: bool=..., return_last: bool=...) -> None:\n        ...\n\n    @overload\n    def run(self, sql: str | Iterable[str], autocommit: bool=..., parameters: Iterable | Mapping[str, Any] | None=..., handler: Callable[[Any], T]=..., split_statements: bool=..., return_last: bool=...) -> tuple | list[tuple] | list[list[tuple] | tuple] | None:\n        ...\n\n    def run(self, sql: str | Iterable[str], autocommit: bool=False, parameters: Iterable | Mapping[str, Any] | None=None, handler: Callable[[Any], T] | None=None, split_statements: bool=False, return_last: bool=True) -> tuple | list[tuple] | list[list[tuple] | tuple] | None:\n        \"\"\"\n        Run a command or a list of commands.\n\n        Pass a list of SQL statements to the SQL parameter to get them to\n        execute sequentially.\n\n        :param sql: the sql statement to be executed (str) or a list of\n            sql statements to execute\n        :param autocommit: What to set the connection's autocommit setting to\n            before executing the query.\n        :param parameters: The parameters to render the SQL query with.\n        :param handler: The result handler which is called with the result of each statement.\n        :param split_statements: Whether to split a single SQL string into statements and run separately\n        :param return_last: Whether to return result for only last statement or for all after split\n        :return: return only result of the LAST SQL expression if handler was provided.\n        \"\"\"\n        self.descriptions = []\n        if isinstance(sql, str):\n            if split_statements:\n                sql_list: Iterable[str] = self.split_sql_string(sql)\n            else:\n                statement = self.strip_sql_string(sql)\n                sql_list = [statement] if statement.strip() else []\n        else:\n            sql_list = sql\n        if sql_list:\n            self.log.debug('Executing following statements against Exasol DB: %s', list(sql_list))\n        else:\n            raise ValueError('List of SQL statements is empty')\n        _last_result = None\n        with closing(self.get_conn()) as conn:\n            self.set_autocommit(conn, autocommit)\n            results = []\n            for sql_statement in sql_list:\n                self.log.info('Running statement: %s, parameters: %s', sql_statement, parameters)\n                with closing(conn.execute(sql_statement, parameters)) as exa_statement:\n                    if handler is not None:\n                        result = self._make_common_data_structure(handler(exa_statement))\n                        if return_single_query_results(sql, return_last, split_statements):\n                            _last_result = result\n                            _last_columns = self.get_description(exa_statement)\n                        else:\n                            results.append(result)\n                            self.descriptions.append(self.get_description(exa_statement))\n                    self.log.info('Rows affected: %s', exa_statement.rowcount())\n            if not self.get_autocommit(conn):\n                conn.commit()\n        if handler is None:\n            return None\n        if return_single_query_results(sql, return_last, split_statements):\n            self.descriptions = [_last_columns]\n            return _last_result\n        return results\n\n    def set_autocommit(self, conn, autocommit: bool) -> None:\n        \"\"\"\n        Set the autocommit flag on the connection.\n\n        :param conn: Connection to set autocommit setting to.\n        :param autocommit: The autocommit setting to set.\n        \"\"\"\n        if not self.supports_autocommit and autocommit:\n            self.log.warning(\"%s connection doesn't support autocommit but autocommit activated.\", self.get_conn_id())\n        conn.set_autocommit(autocommit)\n\n    def get_autocommit(self, conn) -> bool:\n        \"\"\"\n        Get autocommit setting for the provided connection.\n\n        :param conn: Connection to get autocommit setting from.\n        :return: connection autocommit setting. True if ``autocommit`` is set\n            to True on the connection. False if it is either not set, set to\n            False, or the connection does not support auto-commit.\n        \"\"\"\n        autocommit = conn.attr.get('autocommit')\n        if autocommit is None:\n            autocommit = super().get_autocommit(conn)\n        return autocommit\n\n    @staticmethod\n    def _serialize_cell(cell, conn=None) -> Any:\n        \"\"\"\n        Override to disable cell serialization.\n\n        Exasol will adapt all arguments to the ``execute()`` method internally,\n        hence we return cell without any conversion.\n\n        :param cell: The cell to insert into the table\n        :param conn: The database connection\n        :return: The cell\n        \"\"\"\n        return cell\n\nNow, implement the following class. Do not explain the code. The given class skeleton is as follows:\n\nclass OptionService:\n    '''选项生成服务类'''\n\n    def __init__(self):\n        '''初始化选项生成服务'''\n        pass\n\n    def generate_options(self, conversation_history: List[Dict[str, str]], character_config: Dict[str, Any], user_query: str) -> List[str]:\n        '''\n        生成对话选项\n        Args:\n            conversation_history: 对话历史记录\n            character_config: 角色配置\n            user_query: 用户最后的查询\n        Returns:\n            生成的选项列表（最多3个）\n        Raises:\n            APIError: 当API调用失败时\n        '''\n        pass\n\n    def _build_user_prompt(self, conversation_history: List[Dict[str, str]], character_config: Dict[str, Any], user_query: str) -> str:\n        '''\n        构建用户提示词\n        Args:\n            conversation_history: 对话历史记录\n            character_config: 角色配置\n            user_query: 用户最后的查询\n        Returns:\n            构建的用户提示词\n        '''\n        pass"
  }
]