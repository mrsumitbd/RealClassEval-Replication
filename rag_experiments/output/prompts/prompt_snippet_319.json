[
  {
    "role": "assistant",
    "content": "You are an expert Python programmer who can correctly implement complete Python classes based on the provided class skeleton."
  },
  {
    "role": "user",
    "content": "For your understanding, following are some (skeleton, code) examples:\n\nExample skeleton:\n\n\nclass MultithreadedJobExecutor(JobExecutor):\n    '''\n    Experimental multi-threaded CWL executor.\n    Does simple resource accounting, will not start a job unless it\n    has cores / ram available, but does not make any attempt to\n    optimize usage.\n    '''\n\n    def __init__(self) -> None:\n        '''Initialize.'''\n        pass\n\n    def select_resources(self, request: dict[str, Union[int, float]], runtime_context: RuntimeContext) -> dict[str, Union[int, float]]:\n        '''Naïve check for available cpu cores and memory.'''\n        pass\n\n    def _runner(self, job: Union[JobBase, WorkflowJob, CallbackJob, ExpressionJob], runtime_context: RuntimeContext, TMPDIR_LOCK: threading.Lock) -> None:\n        '''Job running thread.'''\n        pass\n\n    def run_job(self, job: Optional[JobsType], runtime_context: RuntimeContext) -> None:\n        '''Execute a single Job in a separate thread.'''\n        pass\n\n    def wait_for_next_completion(self, runtime_context: RuntimeContext) -> None:\n        '''Wait for jobs to finish.'''\n        pass\n\n    def run_jobs(self, process: Process, job_order_object: CWLObjectType, logger: logging.Logger, runtime_context: RuntimeContext) -> None:\n        pass\nCorresponding class implementation:\n\nfrom .task_queue import TaskQueue\nimport logging\nfrom .errors import WorkflowException\nfrom .context import RuntimeContext, getdefault\nfrom .loghandler import _logger\nimport threading\nfrom .command_line_tool import CallbackJob, ExpressionJob\nfrom .process import Process, cleanIntermediate, relocateOutputs\nfrom .workflow_job import WorkflowJob, WorkflowJobStep\nimport math\nfrom typing import Optional, Union, cast\nfrom .job import JobBase\nimport psutil\nfrom .cuda import cuda_version_and_device_count\nfrom .utils import CWLObjectType, JobsType\nimport functools\n\nclass MultithreadedJobExecutor(JobExecutor):\n    \"\"\"\n    Experimental multi-threaded CWL executor.\n\n    Does simple resource accounting, will not start a job unless it\n    has cores / ram available, but does not make any attempt to\n    optimize usage.\n    \"\"\"\n\n    def __init__(self) -> None:\n        \"\"\"Initialize.\"\"\"\n        super().__init__()\n        self.exceptions: list[WorkflowException] = []\n        self.pending_jobs: list[JobsType] = []\n        self.pending_jobs_lock = threading.Lock()\n        self.max_ram = int(psutil.virtual_memory().available / 2 ** 20)\n        self.max_cores = float(psutil.cpu_count() or 1)\n        self.max_cuda = cuda_version_and_device_count()[1]\n        self.allocated_ram = float(0)\n        self.allocated_cores = float(0)\n        self.allocated_cuda: int = 0\n\n    def select_resources(self, request: dict[str, Union[int, float]], runtime_context: RuntimeContext) -> dict[str, Union[int, float]]:\n        \"\"\"Naïve check for available cpu cores and memory.\"\"\"\n        result: dict[str, Union[int, float]] = {}\n        maxrsc = {'cores': self.max_cores, 'ram': self.max_ram}\n        resources_types = {'cores', 'ram'}\n        if 'cudaDeviceCountMin' in request or 'cudaDeviceCountMax' in request:\n            maxrsc['cudaDeviceCount'] = self.max_cuda\n            resources_types.add('cudaDeviceCount')\n        for rsc in resources_types:\n            rsc_min = request[rsc + 'Min']\n            if rsc_min > maxrsc[rsc]:\n                raise WorkflowException(f'Requested at least {rsc_min} {rsc} but only {maxrsc[rsc]} available')\n            rsc_max = request[rsc + 'Max']\n            if rsc_max < maxrsc[rsc]:\n                result[rsc] = math.ceil(rsc_max)\n            else:\n                result[rsc] = maxrsc[rsc]\n        result['tmpdirSize'] = math.ceil(request['tmpdirMin'])\n        result['outdirSize'] = math.ceil(request['outdirMin'])\n        return result\n\n    def _runner(self, job: Union[JobBase, WorkflowJob, CallbackJob, ExpressionJob], runtime_context: RuntimeContext, TMPDIR_LOCK: threading.Lock) -> None:\n        \"\"\"Job running thread.\"\"\"\n        try:\n            _logger.debug('job: {}, runtime_context: {}, TMPDIR_LOCK: {}'.format(job, runtime_context, TMPDIR_LOCK))\n            job.run(runtime_context, TMPDIR_LOCK)\n        except WorkflowException as err:\n            _logger.exception(f'Got workflow error: {err}')\n            self.exceptions.append(err)\n        except Exception as err:\n            _logger.exception(f'Got workflow error: {err}')\n            wf_exc = WorkflowException(str(err))\n            wf_exc.__cause__ = err\n            wf_exc.__suppress_context__ = True\n            self.exceptions.append(wf_exc)\n        finally:\n            if runtime_context.workflow_eval_lock:\n                with runtime_context.workflow_eval_lock:\n                    if isinstance(job, JobBase):\n                        ram = job.builder.resources['ram']\n                        self.allocated_ram -= ram\n                        cores = job.builder.resources['cores']\n                        self.allocated_cores -= cores\n                        cudaDevices: int = cast(int, job.builder.resources.get('cudaDeviceCount', 0))\n                        self.allocated_cuda -= cudaDevices\n                    runtime_context.workflow_eval_lock.notify_all()\n\n    def run_job(self, job: Optional[JobsType], runtime_context: RuntimeContext) -> None:\n        \"\"\"Execute a single Job in a separate thread.\"\"\"\n        if job is not None:\n            with self.pending_jobs_lock:\n                self.pending_jobs.append(job)\n        with self.pending_jobs_lock:\n            n = 0\n            while n + 1 <= len(self.pending_jobs):\n                job = self.pending_jobs[n]\n                if isinstance(job, JobBase):\n                    ram = job.builder.resources['ram']\n                    cores = job.builder.resources['cores']\n                    cudaDevices = cast(int, job.builder.resources.get('cudaDeviceCount', 0))\n                    if ram > self.max_ram or cores > self.max_cores or cudaDevices > self.max_cuda:\n                        _logger.error('Job \"%s\" cannot be run, requests more resources (%s) than available on this host (already allocated ram is %d, allocated cores is %d, allocated CUDA is %d, max ram %d, max cores %d, max CUDA %d).', job.name, job.builder.resources, self.allocated_ram, self.allocated_cores, self.allocated_cuda, self.max_ram, self.max_cores, self.max_cuda)\n                        self.pending_jobs.remove(job)\n                        return\n                    if self.allocated_ram + ram > self.max_ram or self.allocated_cores + cores > self.max_cores or self.allocated_cuda + cudaDevices > self.max_cuda:\n                        _logger.debug('Job \"%s\" cannot run yet, resources (%s) are not available (already allocated ram is %d, allocated cores is %d, allocated CUDA devices is %d, max ram %d, max cores %d, max CUDA %d).', job.name, job.builder.resources, self.allocated_ram, self.allocated_cores, self.allocated_cuda, self.max_ram, self.max_cores, self.max_cuda)\n                        n += 1\n                        continue\n                if isinstance(job, JobBase):\n                    ram = job.builder.resources['ram']\n                    self.allocated_ram += ram\n                    cores = job.builder.resources['cores']\n                    self.allocated_cores += cores\n                    cuda = cast(int, job.builder.resources.get('cudaDevices', 0))\n                    self.allocated_cuda += cuda\n                self.taskqueue.add(functools.partial(self._runner, job, runtime_context, TMPDIR_LOCK), runtime_context.workflow_eval_lock)\n                self.pending_jobs.remove(job)\n\n    def wait_for_next_completion(self, runtime_context: RuntimeContext) -> None:\n        \"\"\"Wait for jobs to finish.\"\"\"\n        if runtime_context.workflow_eval_lock is not None:\n            runtime_context.workflow_eval_lock.wait(timeout=3)\n        if self.exceptions:\n            raise self.exceptions[0]\n\n    def run_jobs(self, process: Process, job_order_object: CWLObjectType, logger: logging.Logger, runtime_context: RuntimeContext) -> None:\n        self.taskqueue: TaskQueue = TaskQueue(threading.Lock(), int(math.ceil(self.max_cores)))\n        try:\n            jobiter = process.job(job_order_object, self.output_callback, runtime_context)\n            if runtime_context.workflow_eval_lock is None:\n                raise WorkflowException('runtimeContext.workflow_eval_lock must not be None')\n            runtime_context.workflow_eval_lock.acquire()\n            for job in jobiter:\n                if job is not None:\n                    if isinstance(job, JobBase):\n                        job.builder = runtime_context.builder or job.builder\n                        if job.outdir is not None:\n                            self.output_dirs.add(job.outdir)\n                self.run_job(job, runtime_context)\n                if job is None:\n                    if self.taskqueue.in_flight > 0:\n                        self.wait_for_next_completion(runtime_context)\n                    else:\n                        logger.error('Workflow cannot make any more progress.')\n                        break\n            self.run_job(None, runtime_context)\n            while self.taskqueue.in_flight > 0:\n                self.wait_for_next_completion(runtime_context)\n                self.run_job(None, runtime_context)\n            runtime_context.workflow_eval_lock.release()\n        finally:\n            self.taskqueue.drain()\n            self.taskqueue.join()\n\nExample skeleton:\n\n\nclass Step:\n    '''State machine for executing generic actions related to stacks.\n    Attributes:\n        fn: Function to run to execute the step.\n            This function will be ran multiple times until the step is \"done\".\n        last_updated: Time when the step was last updated.\n        logger: Logger for logging messages about the step.\n        stack: the stack associated with this step\n        status: The status of step.\n        watch_func: Function that will be called to \"tail\" the step action.\n    '''\n\n    def __init__(self, stack: Stack, *, fn: Callable[..., Any] | None=None, watch_func: Callable[..., Any] | None=None) -> None:\n        '''Instantiate class.\n        Args:\n            stack: The stack associated\n                with this step\n            fn: Function to run to execute the step.\n                This function will be ran multiple times until the step is \"done\".\n            watch_func: Function that will be called to \"tail\" the step action.\n        '''\n        pass\n\n    def run(self) -> bool:\n        '''Run this step until it has completed or been skipped.'''\n        pass\n\n    def _run_once(self) -> Status:\n        '''Run a step exactly once.'''\n        pass\n    @property\n    def name(self) -> str:\n        '''Name of the step.\n        This is equal to the name of the stack it operates on.\n        '''\n        pass\n    @property\n    def requires(self) -> set[str]:\n        '''Return a list of step names this step depends on.'''\n        pass\n    @property\n    def required_by(self) -> set[str]:\n        '''Return a list of step names that depend on this step.'''\n        pass\n    @property\n    def completed(self) -> bool:\n        '''Return True if the step is in a COMPLETE state.'''\n        pass\n    @property\n    def skipped(self) -> bool:\n        '''Return True if the step is in a SKIPPED state.'''\n        pass\n    @property\n    def failed(self) -> bool:\n        '''Return True if the step is in a FAILED state.'''\n        pass\n    @property\n    def done(self) -> bool:\n        '''Return True if the step is finished.\n        To be ``True``, status must be either COMPLETE, SKIPPED or FAILED)\n        '''\n        pass\n    @property\n    def ok(self) -> bool:\n        '''Return True if the step is finished (either COMPLETE or SKIPPED).'''\n        pass\n    @property\n    def submitted(self) -> bool:\n        '''Return True if the step is SUBMITTED, COMPLETE, or SKIPPED.'''\n        pass\n\n    def set_status(self, status: Status) -> None:\n        '''Set the current step's status.\n        Args:\n            status: The status to set the step to.\n        '''\n        pass\n    def completed(self) -> bool:\n        '''Shortcut for ``set_status(COMPLETE)``.'''\n        pass\n\n    def log_step(self) -> None:\n        '''Construct a log message for a set and log it to the UI.'''\n        pass\n    def skipped(self) -> bool:\n        '''Shortcut for ``set_status(SKIPPED)``.'''\n        pass\n    def submitted(self) -> bool:\n        '''Shortcut for ``set_status(SUBMITTED)``.'''\n        pass\n    @classmethod\n    def from_stack_name(cls, stack_name: str, context: CfnginContext, requires: list[str] | set[str] | None=None, fn: Callable[..., Status] | None=None, watch_func: Callable[..., Any] | None=None) -> Step:\n        '''Create a step using only a stack name.\n        Args:\n            stack_name: Name of a CloudFormation stack.\n            context: Context object. Required to initialize a \"fake\"\n                :class:`runway.cfngin.stack.Stack`.\n            requires: Stacks that this stack depends on.\n            fn: The function to run to execute the step.\n                This function will be ran multiple times until the step is \"done\".\n            watch_func: an optional function that will be called to \"tail\" the\n                step action.\n        '''\n        pass\n    @classmethod\n    def from_persistent_graph(cls, graph_dict: dict[str, list[str]] | dict[str, set[str]] | OrderedDict[str, set[str]], context: CfnginContext, fn: Callable[..., Status] | None=None, watch_func: Callable[..., Any] | None=None) -> list[Step]:\n        '''Create a steps for a persistent graph dict.\n        Args:\n            graph_dict: A graph dict.\n            context: Context object. Required to initialize a \"fake\"\n                :class:`runway.cfngin.stack.Stack`.\n            requires: Stacks that this stack depends on.\n            fn: The function to run to execute the step.\n                This function will be ran multiple times until the step is \"done\".\n            watch_func: an optional function that will be called to \"tail\" the\n                step action.\n        '''\n        pass\n\n    def __repr__(self) -> str:\n        '''Object represented as a string.'''\n        pass\n\n    def __str__(self) -> str:\n        '''Object displayed as a string.'''\n        pass\nCorresponding class implementation:\n\nfrom .status import COMPLETE, FAILED, PENDING, SKIPPED, SUBMITTED, FailedStatus, SkippedStatus\nimport time\nfrom .ui import ui\nfrom .._logging import LogLevels, PrefixAdaptor\nimport threading\nfrom .exceptions import CancelExecution, GraphError, PersistentGraphLocked, PlanFailed\nfrom .stack import Stack\nfrom typing import TYPE_CHECKING, Any, Callable, NoReturn, TypeVar, overload\n\nclass Step:\n    \"\"\"State machine for executing generic actions related to stacks.\n\n    Attributes:\n        fn: Function to run to execute the step.\n            This function will be ran multiple times until the step is \"done\".\n        last_updated: Time when the step was last updated.\n        logger: Logger for logging messages about the step.\n        stack: the stack associated with this step\n        status: The status of step.\n        watch_func: Function that will be called to \"tail\" the step action.\n\n    \"\"\"\n    fn: Callable[..., Any] | None\n    last_updated: float\n    logger: PrefixAdaptor\n    stack: Stack\n    status: Status\n    watch_func: Callable[..., Any] | None\n\n    def __init__(self, stack: Stack, *, fn: Callable[..., Any] | None=None, watch_func: Callable[..., Any] | None=None) -> None:\n        \"\"\"Instantiate class.\n\n        Args:\n            stack: The stack associated\n                with this step\n            fn: Function to run to execute the step.\n                This function will be ran multiple times until the step is \"done\".\n            watch_func: Function that will be called to \"tail\" the step action.\n\n        \"\"\"\n        self.stack = stack\n        self.status = PENDING\n        self.last_updated = time.time()\n        self.logger = PrefixAdaptor(self.stack.name, LOGGER)\n        self.fn = fn\n        self.watch_func = watch_func\n\n    def run(self) -> bool:\n        \"\"\"Run this step until it has completed or been skipped.\"\"\"\n        stop_watcher = threading.Event()\n        watcher = None\n        if self.watch_func:\n            watcher = threading.Thread(target=self.watch_func, args=(self.stack, stop_watcher))\n            watcher.start()\n        try:\n            while not self.done:\n                self._run_once()\n        finally:\n            if watcher:\n                stop_watcher.set()\n                watcher.join()\n        return self.ok\n\n    def _run_once(self) -> Status:\n        \"\"\"Run a step exactly once.\"\"\"\n        if not self.fn:\n            raise TypeError('Step.fn must be type Callable[..., Status] not None')\n        try:\n            status = self.fn(self.stack, status=self.status)\n        except CancelExecution:\n            status = SkippedStatus('canceled execution')\n        except Exception as err:\n            LOGGER.exception(err)\n            status = FailedStatus(reason=str(err))\n        self.set_status(status)\n        return status\n\n    @property\n    def name(self) -> str:\n        \"\"\"Name of the step.\n\n        This is equal to the name of the stack it operates on.\n\n        \"\"\"\n        return self.stack.name\n\n    @property\n    def requires(self) -> set[str]:\n        \"\"\"Return a list of step names this step depends on.\"\"\"\n        return self.stack.requires\n\n    @property\n    def required_by(self) -> set[str]:\n        \"\"\"Return a list of step names that depend on this step.\"\"\"\n        return self.stack.required_by\n\n    @property\n    def completed(self) -> bool:\n        \"\"\"Return True if the step is in a COMPLETE state.\"\"\"\n        return self.status == COMPLETE\n\n    @property\n    def skipped(self) -> bool:\n        \"\"\"Return True if the step is in a SKIPPED state.\"\"\"\n        return self.status == SKIPPED\n\n    @property\n    def failed(self) -> bool:\n        \"\"\"Return True if the step is in a FAILED state.\"\"\"\n        return self.status == FAILED\n\n    @property\n    def done(self) -> bool:\n        \"\"\"Return True if the step is finished.\n\n        To be ``True``, status must be either COMPLETE, SKIPPED or FAILED)\n\n        \"\"\"\n        return self.completed or self.skipped or self.failed\n\n    @property\n    def ok(self) -> bool:\n        \"\"\"Return True if the step is finished (either COMPLETE or SKIPPED).\"\"\"\n        return self.completed or self.skipped\n\n    @property\n    def submitted(self) -> bool:\n        \"\"\"Return True if the step is SUBMITTED, COMPLETE, or SKIPPED.\"\"\"\n        return self.status >= SUBMITTED\n\n    def set_status(self, status: Status) -> None:\n        \"\"\"Set the current step's status.\n\n        Args:\n            status: The status to set the step to.\n\n        \"\"\"\n        if status is not self.status:\n            LOGGER.debug('setting %s state to %s...', self.stack.name, status.name)\n            self.status = status\n            self.last_updated = time.time()\n            if self.stack.logging:\n                self.log_step()\n\n    def complete(self) -> None:\n        \"\"\"Shortcut for ``set_status(COMPLETE)``.\"\"\"\n        self.set_status(COMPLETE)\n\n    def log_step(self) -> None:\n        \"\"\"Construct a log message for a set and log it to the UI.\"\"\"\n        msg = self.status.name\n        if self.status.reason:\n            msg += f' ({self.status.reason})'\n        if self.status.code == SUBMITTED.code:\n            ui.log(LogLevels.NOTICE, msg, logger=self.logger)\n        elif self.status.code == COMPLETE.code:\n            ui.log(LogLevels.SUCCESS, msg, logger=self.logger)\n        elif self.status.code == FAILED.code:\n            ui.log(LogLevels.ERROR, msg, logger=self.logger)\n        else:\n            ui.info(msg, logger=self.logger)\n\n    def skip(self) -> None:\n        \"\"\"Shortcut for ``set_status(SKIPPED)``.\"\"\"\n        self.set_status(SKIPPED)\n\n    def submit(self) -> None:\n        \"\"\"Shortcut for ``set_status(SUBMITTED)``.\"\"\"\n        self.set_status(SUBMITTED)\n\n    @classmethod\n    def from_stack_name(cls, stack_name: str, context: CfnginContext, requires: list[str] | set[str] | None=None, fn: Callable[..., Status] | None=None, watch_func: Callable[..., Any] | None=None) -> Step:\n        \"\"\"Create a step using only a stack name.\n\n        Args:\n            stack_name: Name of a CloudFormation stack.\n            context: Context object. Required to initialize a \"fake\"\n                :class:`runway.cfngin.stack.Stack`.\n            requires: Stacks that this stack depends on.\n            fn: The function to run to execute the step.\n                This function will be ran multiple times until the step is \"done\".\n            watch_func: an optional function that will be called to \"tail\" the\n                step action.\n\n        \"\"\"\n        from runway.config.models.cfngin import CfnginStackDefinitionModel\n        stack_def = CfnginStackDefinitionModel.model_construct(name=stack_name, requires=requires or [])\n        stack = Stack(stack_def, context)\n        return cls(stack, fn=fn, watch_func=watch_func)\n\n    @classmethod\n    def from_persistent_graph(cls, graph_dict: dict[str, list[str]] | dict[str, set[str]] | OrderedDict[str, set[str]], context: CfnginContext, fn: Callable[..., Status] | None=None, watch_func: Callable[..., Any] | None=None) -> list[Step]:\n        \"\"\"Create a steps for a persistent graph dict.\n\n        Args:\n            graph_dict: A graph dict.\n            context: Context object. Required to initialize a \"fake\"\n                :class:`runway.cfngin.stack.Stack`.\n            requires: Stacks that this stack depends on.\n            fn: The function to run to execute the step.\n                This function will be ran multiple times until the step is \"done\".\n            watch_func: an optional function that will be called to \"tail\" the\n                step action.\n\n        \"\"\"\n        return [cls.from_stack_name(name, context, requires, fn, watch_func) for name, requires in graph_dict.items()]\n\n    def __repr__(self) -> str:\n        \"\"\"Object represented as a string.\"\"\"\n        return f'<CFNgin.plan.Step:{self.stack.name}>'\n\n    def __str__(self) -> str:\n        \"\"\"Object displayed as a string.\"\"\"\n        return self.stack.name\n\nNow, implement the following class. Do not explain the code. The given class skeleton is as follows:\n\nclass TaskManager:\n    '''Manages background tasks using a thread pool.'''\n\n    def __init__(self, max_workers: Optional[int]=None):\n        '''Initializes the TaskManager and the thread pool executor.'''\n        pass\n\n    def _update_task(self, task_id: str, status: str, message: str, result: Optional[Any]=None):\n        '''Helper function to update the status of a task.'''\n        pass\n\n    def _task_done_callback(self, task_id: str, future: Future):\n        '''Callback function executed when a task completes.'''\n        pass\n\n    def run_task(self, target_function: Callable, *args: Any, **kwargs: Any) -> str:\n        '''\n        Submits a function to be run in the background.\n        Args:\n            target_function: The function to execute.\n            *args: Positional arguments for the target function.\n            **kwargs: Keyword arguments for the target function.\n        Returns:\n            The ID of the created task.\n        Raises:\n            RuntimeError: If shutdown has been initiated.\n        '''\n        pass\n\n    def get_task(self, task_id: str) -> Optional[Dict[str, Any]]:\n        '''\n        Retrieves the status of a task.\n        Args:\n            task_id: The ID of the task to retrieve.\n        Returns:\n            The task details or None if not found.\n        '''\n        pass\n\n    def shutdown(self):\n        '''Shuts down the thread pool and waits for all tasks to complete.'''\n        pass"
  }
]